{
  "history": [
    {
      "id": "1764054361145",
      "timestamp": 1764054361145,
      "score": "64.62",
      "results": [
        {
          "qNum": 1,
          "poolQNum": 291,
          "question": {
            "id": 1,
            "questionText": "A Developer must analyze performance issues with production-distributed applications written as AWS Lambda functions. These distributed Lambda applications invoke other components that make up the applications. How should the Developer identify and troubleshoot the root cause of the performance issues in production?",
            "questionImage": null,
            "options": [
              {
                "text": "Add logging statements to the Lambda functions, then use Amazon CloudWatch to view the logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Cloud Trail and then examine the logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS X-Ray, then examine the segments and errors.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Run Amazon Inspector agents and then analyze performance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 2,
          "poolQNum": 217,
          "question": {
            "id": 2,
            "questionText": "A Development team would like to migrate their existing application code from a GitHub repository to AWS CodeCommit. What needs to be created before they can migrate a cloned repository to CodeCommit over HTTPS?",
            "questionImage": null,
            "options": [
              {
                "text": "A GitHub secure authentication token.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A public and private SSH key file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A set of Git credentials generated from IAM.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An Amazon EC2 IAM role with CodeCommit permissions.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 3,
          "poolQNum": 212,
          "question": {
            "id": 3,
            "questionText": "An application is running on a cluster of Amazon EC2 instances. While trying to read objects stored within a single Amazon S3 bucket that are encrypted with server-side encryption with AWS KMS managed keys (SSE-KMS), the application receives the following error. Which combination of steps should be taken to prevent this failure? (Choose TWO)",
            "questionImage": "images/question212.jpg",
            "options": [
              {
                "text": "Contact AWS Support to request an AWS KMS rate limit increase.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Perform error retries with exponential backoff in the application code.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Contact AWS Support to request a S3 rate limit increase.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Import a customer master key (CMK) with a larger key size.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use more than one customer master key (CMK) to encrypt S3 data.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "2"
          ],
          "correctOptions": [
            "1",
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 4,
          "poolQNum": 148,
          "question": {
            "id": 4,
            "questionText": "A Developer needs to deploy an application running on AWS Fargate using Amazon ECS. The application has environment variables that must be passed to a container for the application to initialize. How should the environment variables be passed to the container?",
            "questionImage": null,
            "options": [
              {
                "text": "Define an array that includes the environment variables under the environment parameter within the service definition.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Define an array that includes the environment variables under the environment parameter within the task definition.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Define an array that includes the environment variables under the entryPoint parameter within the task definition.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Define an array that includes the environment variables under the entryPoint parameter within the service definition.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 5,
          "poolQNum": 237,
          "question": {
            "id": 5,
            "questionText": "When using a large Scan operation in DynamoDB, what technique can be used to minimize the impact of a scan on a table's provisioned throughput?",
            "questionImage": null,
            "options": [
              {
                "text": "Set a smaller page size for the scan.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use parallel scans.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Define a range index on the table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Prewarm the table by updating all items.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 6,
          "poolQNum": 349,
          "question": {
            "id": 6,
            "questionText": "A stock market monitoring application uses Amazon Kinesis for data ingestion. During simulated tests of peak data rates, the Kinesis stream cannot keep up with the incoming data. What step will allow Kinesis to accommodate the traffic during peak hours?",
            "questionImage": null,
            "options": [
              {
                "text": "Install the Kinesis Producer Library (KPL) for ingesting data into the stream.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Reduce the data retention period to allow for more data ingestion using `DecreaseStreamRetentionPeriod`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the shard count of the stream using `UpdateShardCount`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Ingest multiple records into the stream in a single call using `PutRecords`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 7,
          "poolQNum": 182,
          "question": {
            "id": 7,
            "questionText": "A Developer is publishing critical log data to a log group in Amazon CloudWatch Logs, which was created 2 months ago. The Developer must encrypt the log data using an AWS KMS customer master key (CMK) so future data can be encrypted to comply with the company's security policy. How can the Developer meet this requirement?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the CloudWatch Logs console and enable the encrypt feature on the log group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS CLI `create-log-group` command and specify the key Amazon Resource Name (ARN).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the KMS console and associate the CMK with the log group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS CLI `associate-kms-key` command and specify the key Amazon Resource Name (ARN)",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 8,
          "poolQNum": 398,
          "question": {
            "id": 8,
            "questionText": "A developer has an application that makes batch requests directly to Amazon DynamoDB by using the BatchGetItem low-level API operation. The responses frequently return values in the UnprocessedKeys element. Which actions should the developer take to increase the resiliency of the application when the batch response includes values in UnprocessedKeys? (Choose two.)",
            "questionImage": null,
            "options": [
              {
                "text": "Retry the batch operation immediately.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Retry the batch operation with exponential backoff and randomized delay.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Update the application to use an AWS software development kit (AWS SDK) to make the requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the provisioned read capacity of the DynamoDB tables that the operation accesses.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Increase the provisioned write capacity of the DynamoDB tables that the operation accesses.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2",
            "4"
          ],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 9,
          "poolQNum": 139,
          "question": {
            "id": 9,
            "questionText": "An IAM role is attached to an Amazon EC2 instance that explicitly denies access to all Amazon S3 API actions. The EC2 instance credentials file specifies the IAM access key and secret access key, which allow full administrative access. Given that multiple modes of IAM access are present for this EC2 instance, which of the following is correct?",
            "questionImage": null,
            "options": [
              {
                "text": "The EC2 instance will only be able to list the S3 buckets.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The EC2 instance will only be able to list the contents of one S3 bucket at a time.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The EC2 instance will be able to perform all actions on any S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The EC2 instance will not be able to perform any S3 action on any S3 bucket.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 10,
          "poolQNum": 355,
          "question": {
            "id": 10,
            "questionText": "AWS CodeBuild builds code for an application, creates the Docker image, pushes the image to Amazon Elastic Container Registry (Amazon ECR), and tags the image with a unique identifier. If the Developers already have AWS CLI configured on their workstations, how can the Docker images be pulled to the workstations?",
            "questionImage": null,
            "options": [
              {
                "text": "Run the following: `docker pull REPOSITORY URI : TAG`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Run the output of the following: `aws ecr get-login` and then run: `docker pull REPOSITORY URI : TAG`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Run the following: `aws ecr get-login` and then run: `docker pull REPOSITORY URI : TAG`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Run the output of the following: `aws ecr get-download-url-for-layer` and then run: `docker pull REPOSITORY URI : TAG`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 11,
          "poolQNum": 391,
          "question": {
            "id": 11,
            "questionText": "A developer wants to modify the following AWS Cloud Formation template to embed another CloudFormation stack (image). Which syntax should the developer add to the blank line of the CloudFormation template to meet this requirement?",
            "questionImage": "images/question391.jpg",
            "options": [
              {
                "text": "\"Type\" : \"AWS::CloudFormation::Stack\"",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "\"Mapping\" : \"AWS::CloudFormation::NestedStack\"",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "\"Type\" : \"AWS;:CloudFcrmation::NestedStack\"",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "\"Mapping\" : \"AWS::CloudFormation::Stack\"",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 12,
          "poolQNum": 15,
          "question": {
            "id": 12,
            "questionText": "A Developer is creating an application that needs to locate the public IPv4 address of the Amazon EC2 instance on which it runs. How can the application locate this information?",
            "questionImage": null,
            "options": [
              {
                "text": "Get the instance metadata by retrieving `http://169.254.169.254/latest/metadata/`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Get the instance user data by retrieving `http://169.254.169.254/latest/userdata/`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Get the application to run `IFCONFIG` to get the public IP address.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Get the application to run `IPCONFIG` to get the public IP address.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 13,
          "poolQNum": 116,
          "question": {
            "id": 13,
            "questionText": "A developer is creating an AWS Lambda function that generates a new file each time it runs. Each new file must be checked into an AWS CodeCommit repository hosted in the same AWS account. How should the developer accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "When the Lambda function starts, use the Git CLI to clone the repository. Check the new file into the cloned repository and push the change.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "After the new file is created in Lambda, use cURL to invoke the CodeCommit API. Send the file to the repository.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an AWS SDK to instantiate a CodeCommit client. Invoke the `put_file` method to add the file to the repository.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload the new to an Amazon S3 bucket. Create an AWS Step Function to accept S3 events. In the Step Function, add the new file to the repository.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 14,
          "poolQNum": 92,
          "question": {
            "id": 14,
            "questionText": "An application takes 40 seconds to process instructions received in an Amazon SQS message. Assuming the SQS queue is configured with the default `VisibilityTimeout` value, what is the BEST way, upon receiving a message, to ensure that no other instances can retrieve a message that has already been processed or is currently being processed?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the `ChangeMessageVisibility` API to increase the `VisibilityTimeout`, then use the `DeleteMessage` API to delete the message.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use the `DeleteMessage` API call to delete the message from the queue, then call `DeleteQueue` API to remove the queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `ChangeMessageVisibility` API to decrease the timeout value, then use the `DeleteMessage` API to delete the message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `DeleteMessageVisibility` API to cancel the `VisibilityTimeout`, then use the `DeleteMessage` API to delete the message.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 15,
          "poolQNum": 350,
          "question": {
            "id": 15,
            "questionText": "A company has an AWS CloudFormation template that is stored as a single file. The template is able to launch and create a full infrastructure stack. Which best practice would increase the maintainability of the template?",
            "questionImage": null,
            "options": [
              {
                "text": "Use nested stacks for common template patterns.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Embed credentials to prevent typos.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Remove mappings to decrease the number of variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use `AWS::Include` to reference publicly-hosted template files.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 16,
          "poolQNum": 258,
          "question": {
            "id": 16,
            "questionText": "An Amazon S3 bucket, `myawsbucket` is configured with website hosting in Tokyo region, what is the region-specific website endpoint?",
            "questionImage": null,
            "options": [
              {
                "text": "`www.myawsbucket.ap-northeast-1.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`myawsbucket.s3-website-ap-northeast-1.amazonaws.com`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`myawsbucket.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`myawsbucket.tokyo.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 17,
          "poolQNum": 101,
          "question": {
            "id": 17,
            "questionText": "An application stops working with the following error: `The specified bucket does not exist`. Where is the BEST place to start the root cause analysis?",
            "questionImage": null,
            "options": [
              {
                "text": "Check the Elastic Load Balancer logs for `DeleteBucket` requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Check the application logs in Amazon CloudWatch Logs for Amazon S3 `DeleteBucket` errors.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Check AWS X-Ray for Amazon S3 `DeleteBucket` alarms.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Check AWS CloudTrail for a `DeleteBucket` event.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 18,
          "poolQNum": 157,
          "question": {
            "id": 18,
            "questionText": "An application is experiencing performance issues based on increased demand. This increased demand is on read-only historical records pulled from an Amazon RDS-hosted database with custom views and queries. A Developer must improve performance without changing the database structure. Which approach will improve performance and MINIMIZE management overhead?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy Amazon DynamoDB, move all the data, and point to DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy Amazon ElastiCache for Redis and cache the data for the application.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Deploy Memcached on Amazon EC2 and cache the data for the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy Amazon DynamoDB Accelerator (DAX) on Amazon RDS to improve cache performance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 19,
          "poolQNum": 133,
          "question": {
            "id": 19,
            "questionText": "A developer is creating a script to automate the deployment process for a serverless application. The developer wants to use an existing AWS Serverless Application Model (AWS SAM) template for the application. What should the developer use for the project? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Call `aws cloudformation package` to create the deployment package. Call `aws cloudformation deploy` to deploy the package afterward.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Call `sam package` to create the deployment package. Call `sam deploy` to deploy the package afterward.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Call `aws s3 cp` to upload the AWS SAM template to Amazon S3. Call `aws lambda update-function-code` to create the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a `ZIP` package locally and call `aws serverlessrepo create-application` to create the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a `ZIP` package and upload it to Amazon S3. Call `aws cloudformation create-stack` to create the application.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2",
            "5"
          ],
          "correctOptions": [
            "1",
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 20,
          "poolQNum": 163,
          "question": {
            "id": 20,
            "questionText": "An application has the following requirements: Performance efficiency of seconds with up to a minute of latency. The data storage size may grow up to thousands of terabytes. Per-message sizes may vary between 100 KB and 100 MB. Data can be stored as key/value stores supporting eventual consistency. What is the MOST cost-effective AWS service to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon RDS (with a MySQL engine).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon ElastiCache.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 21,
          "poolQNum": 351,
          "question": {
            "id": 21,
            "questionText": "An on-premises application makes repeated calls to store files to Amazon S3. As usage of the application has increased, `LimitExceeded` errors are being logged. What should be changed to fix this error?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement exponential backoffs in the application.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Load balance the application to multiple servers.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Move the application to Amazon EC2.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a one second delay to each API call.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 22,
          "poolQNum": 96,
          "question": {
            "id": 22,
            "questionText": "A Developer is testing a Docker-based application that uses the AWS SDK to interact with Amazon DynamoDB. In the local development environment, the application has used IAM access keys. The application is now ready for deployment onto an ECS cluster. How should the application authenticate with AWS services in production?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure an ECS task IAM role for the application to use.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Refactor the application to call AWS STS `AssumeRole` based on an instance role.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure AWS access `key/secret` access key environment variables with new credentials.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure the credentials file with a new access `key/secret` access key.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 23,
          "poolQNum": 376,
          "question": {
            "id": 23,
            "questionText": "The Developer for a retail company must integrate a fraud detection solution into the order processing solution. The fraud detection solution takes between ten and thirty minutes to verify an order. At peak, the web site can receive one hundred orders per minute. What is the most scalable method to add the fraud detection solution to the order processing pipeline?",
            "questionImage": null,
            "options": [
              {
                "text": "Add all new orders to an Amazon SQS queue. Configure a fleet of 10 EC2 instances spanning multiple AZs with the fraud detection solution installed on them to pull orders from this queue. Update the order with a pass or fails status.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add all new orders to an SQS queue. Configure an Auto Scaling group that uses the queue depth metric as its unit of scale to launch a dynamically-sized fleet of EC2 instances spanning multiple AZs with the fraud detection solution installed on them to pull orders from this queue. Update the order with a pass or fails status.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add all new orders to an Amazon Kinesis Stream. Subscribe a Lambda function to automatically read batches of records from the Kinesis Stream. The Lambda function includes the fraud detection software and will update the order with a pass or fail status.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write all new orders to Amazon DynamoDB. Configure DynamoDB Streams to include all new orders. Subscribe a Lambda function to automatically read batches of records from the Kinesis Stream. The Lambda function includes the fraud detection software and will update the order with a pass or fail status.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 24,
          "poolQNum": 215,
          "question": {
            "id": 24,
            "questionText": "A company is creating a REST service using an Amazon API Gateway with AWS Lambda integration. The service must run different versions for testing purposes. What would be the BEST way to accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "Use an `x-Version` header to denote which version is being called and pass that header to the Lambda function(s).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an API Gateway Lambda authorizer to route API clients to the correct API version.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an API Gateway resource policy to isolate versions and provide context to the Lambda function(s).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the API versions as unique stages with unique endpoints and use stage variables to provide further context.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 25,
          "poolQNum": 49,
          "question": {
            "id": 25,
            "questionText": "An application on AWS is using third-party APIs. The Developer needs to monitor API errors in the code, and wants to receive notifications if failures go above a set threshold value. How can the Developer achieve these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Publish a custom metric on Amazon CloudWatch and use Amazon Simple Email Service (SES) for notification.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon CloudWatch API-error metric and use Amazon Simple Notification Service (SNS) for notification.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon CloudWatch API-error metric and use Amazon SES for notification.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Publish a custom metric on Amazon CloudWatch and use Amazon SNS for notification.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 26,
          "poolQNum": 183,
          "question": {
            "id": 26,
            "questionText": "A Developer has code running on Amazon EC2 instances that needs read-only access to an Amazon DynamoDB table. What is the MOST secure approach the Developer should take to accomplish this task?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a user access key for each EC2 instance with read-only access to DynamoDB. Place the keys in the code. Redeploy the code as keys rotate.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an IAM role with an AmazonDynamoDBReadOnlyAccess policy applied to the EC2 instances.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Run all code with only AWS account root user access keys to ensure maximum access to services.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an IAM role with Administrator access applied to the EC2 instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 27,
          "poolQNum": 9,
          "question": {
            "id": 27,
            "questionText": "A company is building a compute-intensive application that will run on a fleet of Amazon EC2 instances. The application uses attached Amazon EBS disks for storing data. The application will process sensitive information and all the data must be encrypted. What should a developer do to ensure the data is encrypted on disk without impacting performance?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure the Amazon EC2 instance fleet to use encrypted EBS volumes for storing data.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add logic to write all data to an encrypted Amazon S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a custom encryption algorithm to the application that will encrypt and decrypt all data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a new Amazon Machine Image (AMI) with an encrypted root volume and store the data to ephemeral disks.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 28,
          "poolQNum": 368,
          "question": {
            "id": 28,
            "questionText": "A development team is using AWS Elastic Beanstalk to deploy a two-tier application that consists of a load-balanced web tier and an Amazon RDS database tier in production. The team would like to separate the RDS instance from the Elastic Beanstalk. How can this be accomplished?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the Elastic Beanstalk CLI to disassociate the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS CLI to disassociate the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the deployment policy to disassociate the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Recreate a new Elastic Beanstalk environment without Amazon RDS.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 29,
          "poolQNum": 381,
          "question": {
            "id": 29,
            "questionText": "An existing serverless application processes uploaded image files. The process currently uses a single Lambda function that takes an image file, performs the processing, and stores the file in Amazon S3. Users of the application now require thumbnail generation of the images. Users want to avoid any impact to the time it takes to perform the image uploads. How can thumbnail generation be added to the application, meeting user requirements while minimizing changes to existing code?",
            "questionImage": null,
            "options": [
              {
                "text": "Change the existing Lambda function handling the uploads to create thumbnails at the time of upload. Have the function store both the image and thumbnail in Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a second Lambda function that handles thumbnail generation and storage. Change the existing Lambda function to invoke it asynchronously.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an S3 event notification with a Lambda function destination. Create a new Lambda function to generate and store thumbnails.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an S3 event notification to an SQS Queue. Create a scheduled Lambda function that processes the queue, and generates and stores thumbnails.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 30,
          "poolQNum": 238,
          "question": {
            "id": 30,
            "questionText": "How can you secure data at rest on an EBS volume?",
            "questionImage": null,
            "options": [
              {
                "text": "Attach the volume to an instance using EC2's SSL interface.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write the data randomly instead of sequentially.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an encrypted file system on top of the EBS volume.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Encrypt the volume using the S3 server-side encryption service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM policy that restricts read and write access to the volume.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 31,
          "poolQNum": 104,
          "question": {
            "id": 31,
            "questionText": "A company is building a stock trading application that requires sub-millisecond latency in processing trading requests. Amazon DynamoDB is used to store all the trading data that is used to process each request. After load testing the application, the development team found that due to data retrieval times, the latency requirement is not satisfied. Because of sudden high spikes in the number of requests, DynamoDB read capacity has to be significantly over-provisioned to avoid throttling. What steps should be taken to meet latency requirements and reduce the cost of running the application?",
            "questionImage": null,
            "options": [
              {
                "text": "Add Global Secondary Indexes for trading data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store trading data in Amazon S3 and use Transfer Acceleration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add retries with exponential back-off for DynamoDB queries.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use DynamoDB Accelerator to cache trading data.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 32,
          "poolQNum": 210,
          "question": {
            "id": 32,
            "questionText": "A company wants to implement authentication for its new REST service using Amazon API Gateway. To authenticate the calls, each request must include HTTP headers with a client ID and user ID. These credentials must be compared to authentication data in an Amazon DynamoDB table. What MUST the company do to implement this authentication in API Gateway?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement an AWS Lambda authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a model that requires the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the integration requests to require the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement an Amazon Cognito authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 33,
          "poolQNum": 334,
          "question": {
            "id": 33,
            "questionText": "In a move toward using microservices, a company's Management team has asked all Development teams to build their services so that API requests depend only on that service's data store. One team is building a Payments service which has its own database; the service needs data that originates in the Accounts database. Both are using Amazon DynamoDB. What approach will result in the simplest, decoupled, and reliable method to get near-real time updates from the Accounts database?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon Glue to perform frequent ETL updates from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache in Payments, with the cache updated by triggers in the Accounts database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Kinesis Data Firehose to deliver all changes from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon DynamoDB Streams to deliver all changes from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 34,
          "poolQNum": 112,
          "question": {
            "id": 34,
            "questionText": "A developer is testing an application that invokes an AWS Lambda function asynchronously. During the testing phase, the Lambda function fails to process after two retries. How can the developer troubleshoot the failure?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure AWS CloudTrail logging to investigate the invocation failures.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure Dead Letter Queues by sending events to Amazon SQS for investigatio.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure Amazon Simple Workflow Service to process any direct unprocessed events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure AWS Config to process any direct unprocessed events.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 35,
          "poolQNum": 151,
          "question": {
            "id": 35,
            "questionText": "A developer is writing an application that will process data delivered into an Amazon S3 bucket. The data is delivered approximately 10 times a day, and the developer expects the data will be processed in less than 1 minute, on average. How can the developer deploy and invoke the application with the lowest cost and lowest latency?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an Amazon CloudWatch alarm triggered by an S3 object upload.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an S3 event notification.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an Amazon CloudWatch scheduled event.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the application onto an Amazon EC2 instance and have it poll the S3 bucket for new objects.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 36,
          "poolQNum": 257,
          "question": {
            "id": 36,
            "questionText": "Company B provides an online image recognition service and utilizes SQS to decouple system components for scalability The SQS consumers poll the imaging queue as often as possible to keep end-to-end throughput as high as possible. However, Company B is realizing that polling in tight loops is burning CPU cycles and increasing costs with empty responses. How can Company B reduce the number of empty responses?",
            "questionImage": null,
            "options": [
              {
                "text": "Set the imaging queue visibility `Timeout` attribute to 20 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set the Imaging queue `ReceiveMessageWaitTimeSeconds` attribute to 20 seconds.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set the imaging queue `MessageRetentionPeriod` attribute to 20 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set the `DelaySeconds` parameter of a message to 20 seconds.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 37,
          "poolQNum": 395,
          "question": {
            "id": 37,
            "questionText": "A company is building a scalable data management solution by using AWS services to improve the speed and agility of development. The solution will ingest large volumes of data from various sources and will process this data through multiple business rules and transformations. The solution requires business rules to run in sequence and to handle reprocessing of data if errors occur when the business rules run. The company needs the solution to be scalable and to require the least possible maintenance. Which AWS service should the company use to manage and automate the orchestration of the data flows to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS Batch",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Step Functions",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Glue",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Lambda",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 38,
          "poolQNum": 289,
          "question": {
            "id": 38,
            "questionText": "A Developer is creating a template that uses AWS CloudFormation to deploy an application. This application is serverless and uses Amazon API Gateway, Amazon DynamoDB, and AWS Lambda. Which tool should the Developer use to define simplified syntax for expressing serverless resources?",
            "questionImage": null,
            "options": [
              {
                "text": "CloudFormation serverless intrinsic functions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS serverless express.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An AWS serverless application model.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "A CloudFormation serverless plugin.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 39,
          "poolQNum": 121,
          "question": {
            "id": 39,
            "questionText": "An application needs to encrypt data that is written to Amazon S3 where the keys are managed in an on-premises data center, and the encryption is handled by S3. Which type of encryption should be used?",
            "questionImage": null,
            "options": [
              {
                "text": "Use server-side encryption with Amazon S3-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use server-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use client-side encryption with customer master keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use server-side encryption with customer-provided keys.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 40,
          "poolQNum": 295,
          "question": {
            "id": 40,
            "questionText": "A Developer is investigating an issue whereby certain requests are passing through an Amazon API Gateway endpoint /MyAPI, but the requests do not reach the AWS Lambda function backing /MyAPI. The Developer found that a second Lambda function sometimes runs at maximum concurrency allowed for the given AWS account. How can the Developer address this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Manually reduce the concurrent execution limit at the account level.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add another API Gateway stage for /MyAPI, and shard the requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure the second Lambda function's concurrency execution limit.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Reduce the throttling limits in the API Gateway /MyAPI endpoint",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 41,
          "poolQNum": 382,
          "question": {
            "id": 41,
            "questionText": "A company is using Amazon API Gateway to manage access to a set of microservices implemented as AWS Lambda functions. Following a bug report, the company makes a minor breaking change to one of the APIs. In order to avoid impacting existing clients when the new API is deployed, the company wants to allow clients six months to migrate from v1 to v2. Which approach should the Developer use to handle this change?",
            "questionImage": null,
            "options": [
              {
                "text": "Update the underlying Lambda function and provide clients with the new Lambda invocation URL.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use API Gateway to automatically propagate the change to clients, specifying 180 days in the phased deployment parameter.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use API Gateway to deploy a new stage named v2 to the API and provide users with its URL.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Update the underlying Lambda function, create an Amazon CloudFront distribution with the updated Lambda function as its origin.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 42,
          "poolQNum": 20,
          "question": {
            "id": 42,
            "questionText": "A software company needs to make sure user-uploaded documents are securely stored in Amazon S3. The documents must be encrypted at rest in Amazon S3. The company does not want to manage the security infrastructure in-house, but the company still needs extra protection to ensure it has control over its encryption keys due to industry regulations. Which encryption strategy should a developer use to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Server-side encryption with Amazon S3 managed keys (SSE-S3).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with customer-provided encryption keys (SSE-C).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with AWS KMS managed keys (SSE-KMS).",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client-side encryption.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 43,
          "poolQNum": 147,
          "question": {
            "id": 43,
            "questionText": "A developer needs to manage AWS infrastructure as code and must be able to deploy multiple identical copies of the infrastructure, stage changes, and revert to previous versions. Which approach addresses these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Use cost allocation reports and AWS OpsWorks to deploy and manage the infrastructure.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudWatch metrics and alerts along with resource tagging to deploy and manage the infrastructure.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Elastic Beanstalk and AWS CodeCommit to deploy and manage the infrastructure.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CloudFormation and AWS CodeCommit to deploy and manage the infrastructure.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 44,
          "poolQNum": 26,
          "question": {
            "id": 44,
            "questionText": "A Developer is writing a REST service that will add items to a shopping list. The service is built on Amazon API Gateway with AWS Lambda integrations. The shopping list items are send as query string parameters in the method request. How should the Developer convert the query string parameters to arguments for the Lambda function?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable request validation.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Include the Amazon Resource Name (ARN) of the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the integration type.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a mapping template.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 45,
          "poolQNum": 263,
          "question": {
            "id": 45,
            "questionText": "You are providing AWS consulting services for a company developing a new mobile application that will be leveraging Amazon SNS Mobile Push for push notifications. In order to send direct notification messages to individual devices each device registration identifier or token needs to be registered with SNS; however the developers are not sure of the best way to do this. You advise them to:",
            "questionImage": null,
            "options": [
              {
                "text": "Bulk upload the device tokens contained in a CSV file via the AWS Management Console.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Let the push notification service (e.g. Amazon Device Messaging) handle the registration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement a token vending service to handle the registration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Call the `CreatePlatformEndPoint` API function to register multiple device tokens.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 46,
          "poolQNum": 244,
          "question": {
            "id": 46,
            "questionText": "Which DynamoDB limits can be raised by contacting AWS support? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "The number of hash keys per account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The maximum storage used per account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The number of tables per account.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The number of local secondary indexes per account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The number of provisioned throughput units per account.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "3",
            "5"
          ],
          "correctOptions": [
            "3",
            "5"
          ],
          "isCorrect": true
        },
        {
          "qNum": 47,
          "poolQNum": 277,
          "question": {
            "id": 47,
            "questionText": "A company runs an e-commerce website that uses Amazon DynamoDB where pricing for items is dynamically updated in real time. At any given time, multiple updates may occur simultaneously for pricing information on a particular product. This is causing the original editor's changes to be overwritten without a proper review process. Which DynamoDB write option should be selected to prevent this overwriting?",
            "questionImage": null,
            "options": [
              {
                "text": "Concurrent writes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Conditional writes.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Atomic writes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Batch writes.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 48,
          "poolQNum": 388,
          "question": {
            "id": 48,
            "questionText": "A company has an application that needs to get objects from an Amazon S3 bucket. The application runs on Amazon EC2 instances. All the objects in the S3 bucket are encrypted with an AWS Key Management Service (AWS KMS) customer managed key. The resources in the VPC do not have access to the internet and use a gateway VPC endpoint to access Amazon S3. The company discovers that the application is unable to get objects from the S3 bucket. Which factors could cause this issue? (Choose three.)",
            "questionImage": null,
            "options": [
              {
                "text": "The IAM instance profile that is attached to the EC2 instances does not allow the s3:ListBucket action for the S3 bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The IAM instance profile that is attached to the EC2 instances does not allow the s3:ListParts action for the S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The KMS key policy that encrypts the objects in the S3 bucket does not allow the kms:ListKeys action to the EC2 instance profile ARN.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The KMS key policy that encrypts the objects in the S3 bucket does not allow the kms:Decrypt action to the EC2 instance profile ARN.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The S3 bucket policy does not allow access from the gateway VPC endpoint.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The security group that is attached to the EC2 instances is missing an inbound rule from the S3 managed prefix list over port 443.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "4",
            "5"
          ],
          "correctOptions": [
            "1",
            "4",
            "5"
          ],
          "isCorrect": true
        },
        {
          "qNum": 49,
          "poolQNum": 47,
          "question": {
            "id": 49,
            "questionText": "A developer has written a multi-threaded application that is running on a fleet of Amazon EC2 instances. The operations team has requested a graphical method to monitor the number of running threads over time. What is the MOST efficient way to fulfill this request?",
            "questionImage": null,
            "options": [
              {
                "text": "Periodically send the thread count to AWS X-Ray segments, then generate a service graph on demand.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a custom Amazon CloudWatch metric and periodically perform a `PutMetricData` call with the current thread count.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Periodically log thread count data to Amazon S3. Use Amazon Kinesis to process the data into a graph.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Periodically write the current thread count to a table using Amazon DynarnoDB and use Amazon CloudFront to create a graph.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 50,
          "poolQNum": 41,
          "question": {
            "id": 50,
            "questionText": "A company stores all personally identifiable information (PII) in an Amazon DynamoDB table named PII in Account A. An application running on Amazon EC2 instances in Account B requires access to the PII table. An administrators in Account A created an IAM role named AccessPII with privileges to access the PII table, and made account B a trusted entity. Which combination of actional steps should Developers take to access the table? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Allow the EC2 IAM role the permission to assume the AccessPII role.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Allow the EC2 IAM role the permission to access the PII table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Include the AWS API in the application code logic to obtain temporary credentials from the EC2 IAM role to access the PII table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Include the `AssumeRole` API operation in the application code logic to obtain temporary credentials to access the PII table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Include the GetSessionToken API operation in the application code logic to obtain temporary credentials to access the PII table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2",
            "4"
          ],
          "correctOptions": [
            "1",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 51,
          "poolQNum": 367,
          "question": {
            "id": 51,
            "questionText": "An application needs to use the IP address of the client in its processing. The application has been moved into AWS and has been placed behind an Application Load Balancer (ALB). However, all the client IP addresses now appear to be the same. The application must maintain the ability to scale horizontally. Based on this scenario, what is the MOST cost-effective solution to this problem?",
            "questionImage": null,
            "options": [
              {
                "text": "Remove the application from the ALB. Delete the ALB and change Amazon Route 53 to direct traffic to the instance running the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Remove the application from the ALB. Create a Classic Load Balancer in its place. Direct traffic to the application using the HTTP protocol.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Alter the application code to inspect the `X-Forwarded-For` header. Ensure that the code can work properly if a list of IP addresses is passed in the header.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Alter the application code to inspect a custom header. Alter the client code to pass the IP address in the custom header.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 52,
          "poolQNum": 5,
          "question": {
            "id": 52,
            "questionText": "A Developer wants to upload data to Amazon S3 and must encrypt the data in transit. Which of the following solutions will accomplish this task? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Set up hardware VPN tunnels to a VPC and access S3 through a VPC endpoint.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set up Client-Side Encryption with an AWS KMS-Managed Customer Master Key.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set up Server-Side Encryption with AWS KMS-Managed Keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Transfer the data over an SSL connection.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set up Server-Side Encryption with S3-Managed Keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2",
            "4"
          ],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 53,
          "poolQNum": 328,
          "question": {
            "id": 53,
            "questionText": "A Developer has published an update to an application that is served to a global user base using Amazon CloudFront. After deploying the application, users are not able to see the updated changes. How can the Developer resolve this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Remove the origin from the CloudFront configuration and add it again.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disable forwarding of query strings and request headers from the CloudFront distribution configuration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Invalidate all the application objects from the edge caches.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Disable the CloudFront distribution and enable it again to update all the edge locations.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 54,
          "poolQNum": 95,
          "question": {
            "id": 54,
            "questionText": "A Developer has created an S3 bucket` s3://mycoolapp` and has enabled server across logging that points to the folder `s3://mycoolapp/logs`. The Developer moved 100 KB of Cascading Style Sheets (CSS) documents to the folder `s3://mycoolapp/css`, and then stopped work. When the developer came back a few days later, the bucket was 50 GB. What is the MOST likely cause of this situation?",
            "questionImage": null,
            "options": [
              {
                "text": "The CSS files were not compressed and S3 versioning was enabled.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "S3 replication was enabled on the bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Logging into the same bucket caused exponential log growth.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An S3 lifecycle policy has moved the entire CSS file to S3 Infrequent Access.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 55,
          "poolQNum": 297,
          "question": {
            "id": 55,
            "questionText": "A Developer created configuration specifications for an AWS Elastic Beanstalk application in a file named healthcheckurl.yaml in the `.ebextensions/directory` of their application source bundle. The file contains the following: After the application launches, the health check is not being run on the correct path, even though it is valid. What can be done to correct this configuration file?",
            "questionImage": "images/question297.jpeg",
            "options": [
              {
                "text": "Convert the file to JSON format.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rename the file to a `.config` extension.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Change the configuration section from `options_settings` to resources.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the namespace of the option settings to a custom namespace.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 56,
          "poolQNum": 241,
          "question": {
            "id": 56,
            "questionText": "A startup s photo-sharing site is deployed in a VPC. An ELB distributes web traffic across two subnets. ELB session stickiness is configured to use the AWS-generated session cookie, with a session TTL of 5 minutes. The webserver Auto Scaling Group is configured as: `min-size=4`, `max-size=4`, The startups preparing for a public launch, by running load-testing software installed on a single EC2 instance running in `us-west-2`. After 60 minutes of load-testing, the webserver logs show. Which recommendations can help ensure load-testing HTTP requests are evenly distributed across the four webservers? (Choose TWO)",
            "questionImage": "images/question241.jpg",
            "options": [
              {
                "text": "Launch and run the load-tester EC2 instance from `us-east-1` instead.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Re-configure the load-testing software to re-resolve DNS for each web request.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use a 3rd-party load-testing service which offers globally-distributed test clients.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure ELB and Auto Scaling to distribute across `us-west-2a` and `us-west-2c`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure ELB session stickiness to use the app-specific session cookie.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "3",
            "4"
          ],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 57,
          "poolQNum": 162,
          "question": {
            "id": 57,
            "questionText": "A Company runs continuous integration/continuous delivery (CI/CD) pipelines for its application on AWS CodePipeline. A Developer must write unit tests and run them as part of the pipelines before staging the artifacts for testing. How should the Developer incorporate unit tests as part of CI/CD pipelines?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a separate CodePipeline pipeline to run unit tests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the AWS CodeBuild specification to include a phase for running unit tests.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install the AWS CodeDeploy agent on an Amazon EC2 instance to run unit tests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a testing branch in AWS CodeCommit to run unit tests.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 58,
          "poolQNum": 259,
          "question": {
            "id": 58,
            "questionText": "You are inserting 1000 new items every second in a DynamoDB table. Once an hour these items are analyzed and then are no longer needed. You need to minimize provisioned throughput, storage, and API calls. Given these requirements, what is the most efficient way to manage these Items after the analysis?",
            "questionImage": null,
            "options": [
              {
                "text": "Retain the items in a single table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Delete items individually over a 24 hour period.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Delete the table and create a new table per hour.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a new table per hour.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 59,
          "poolQNum": 203,
          "question": {
            "id": 59,
            "questionText": "A Developer is storing sensitive data generated by an application in Amazon S3. The Developer wants to encrypt the data at rest. A company policy requires an audit trail of when the master key was used and by whom. Which encryption option will meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Server-side encryption with Amazon S3 managed keys (SSE-S3).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with AWS KMS managed keys (SSE-KMS).",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Server-side encryption with customer-provided keys (SSE-C).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with self-managed keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 60,
          "poolQNum": 177,
          "question": {
            "id": 60,
            "questionText": "A Developer decides to store highly secure data in Amazon S3 and wants to implement server-side encryption (SSE) with granular control of who can access the master key. Company policy requires that the master key be created, rotated, and disabled easily when needed, all for security reasons. Which solution should be used to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "SSE with Amazon S3 managed keys (SSE-S3).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SSE with AWS KMS managed keys (SSE-KMS).",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SSE with AWS Secrets Manager.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SSE with customer-provided encryption keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 61,
          "poolQNum": 228,
          "question": {
            "id": 61,
            "questionText": "Which of the following platforms are supported by Elastic Beanstalk? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Apache Tomcat.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": ".NET.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "IBM Websphere.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Oracle JBoss.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Jetty.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "2",
            "5"
          ],
          "correctOptions": [
            "1",
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 62,
          "poolQNum": 45,
          "question": {
            "id": 62,
            "questionText": "An application is running on an EC2 instance. The Developer wants to store an application metric in Amazon CloudWatch. What is the best practice for implementing this requirement?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the PUT Object API call to send data to an S3 bucket. Use an event notification to invoke a Lambda function to publish data to CloudWatch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Publish the metric data to an Amazon Kinesis Stream using a `PutRecord` API call. Subscribe a Lambda function that publishes data to CloudWatch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the CloudWatch `PutMetricData` API call to submit a custom metric to CloudWatch. Provide the required credentials to enable the API call.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the CloudWatch `PutMetricData` API call to submit a custom metric to CloudWatch. Launch the EC2 instance with the required IAM role to enable the API call.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 63,
          "poolQNum": 205,
          "question": {
            "id": 63,
            "questionText": "A company is developing a web application that allows its employees to upload a profile picture to a private Amazon S3 bucket. There is no size limit for the profile pictures, which should be displayed every time an employee logs in. For security reasons, the pictures cannot be publicly accessible. What is a viable long-term solution for this scenario?",
            "questionImage": null,
            "options": [
              {
                "text": "Generate a presigned URL when a picture is uploaded. Save the URL in an Amazon DynamoDB table. Return the URL to the browser when the employee logs in.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Save the picture's S3 key in an Amazon DynamoDB table. Create an Amazon S3 VPC endpoint to allow the employees to download pictures once they log in.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Encode a picture using base64. Save the base64 string in an Amazon DB table. Allow the browser to retrieve the string and convert it to a picture.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Save the picture's S3 key in an Amazon DynamoDB table. Use a function to generate a presigned URL every time an employee logs in. Return the URL to the browser.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 64,
          "poolQNum": 174,
          "question": {
            "id": 64,
            "questionText": "A Developer is building a serverless application using AWS Lambda and must create a REST API using an HTTP GET method. What needs to be defined to meet this requirement? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "A Lambda@Edge function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An Amazon API Gateway with a Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An exposed GET method in an Amazon API Gateway.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An exposed GET method in the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An exposed GET method in Amazon Route 53.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2",
            "3"
          ],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 65,
          "poolQNum": 363,
          "question": {
            "id": 65,
            "questionText": "An application runs on multiple EC2 instances behind an ELB. Where is the session data best written so that it can be served reliably across multiple requests?",
            "questionImage": null,
            "options": [
              {
                "text": "Write data to Amazon ElastiCache.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Write data to Amazon Elastic Block Store.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write data to Amazon EC2 Instance Store.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write data to the `root` filesystem.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        }
      ],
      "questionMap": {
        "1": 291,
        "2": 217,
        "3": 212,
        "4": 148,
        "5": 237,
        "6": 349,
        "7": 182,
        "8": 398,
        "9": 139,
        "10": 355,
        "11": 391,
        "12": 15,
        "13": 116,
        "14": 92,
        "15": 350,
        "16": 258,
        "17": 101,
        "18": 157,
        "19": 133,
        "20": 163,
        "21": 351,
        "22": 96,
        "23": 376,
        "24": 215,
        "25": 49,
        "26": 183,
        "27": 9,
        "28": 368,
        "29": 381,
        "30": 238,
        "31": 104,
        "32": 210,
        "33": 334,
        "34": 112,
        "35": 151,
        "36": 257,
        "37": 395,
        "38": 289,
        "39": 121,
        "40": 295,
        "41": 382,
        "42": 20,
        "43": 147,
        "44": 26,
        "45": 263,
        "46": 244,
        "47": 277,
        "48": 388,
        "49": 47,
        "50": 41,
        "51": 367,
        "52": 5,
        "53": 328,
        "54": 95,
        "55": 297,
        "56": 241,
        "57": 162,
        "58": 259,
        "59": 203,
        "60": 177,
        "61": 228,
        "62": 45,
        "63": 205,
        "64": 174,
        "65": 363
      }
    },
    {
      "id": "1764301516515",
      "timestamp": 1764301516515,
      "score": "81.54",
      "results": [
        {
          "qNum": 1,
          "poolQNum": 32,
          "question": {
            "id": 1,
            "questionText": "An application contains two components: one component to handle HTTP requests, and another component to handle background processing tasks. Each component must scale independently. The developer wants to deploy this application using AWS Elastic Beanstalk. How should this application be deployed, based on these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy the application in a single Elastic Beanstalk environment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy each component in a separate Elastic Beanstalk environment.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use multiple Elastic Beanstalk environments for the HTTP component but one environment for the background task component.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use multiple Elastic Beanstalk environments for the background task component but one environment for the HTTP component.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 2,
          "poolQNum": 373,
          "question": {
            "id": 2,
            "questionText": "An on-premises legacy application is caching data files locally and writing shared images to local disks. What is necessary to allow for horizontal scaling when migrating the application to AWS?",
            "questionImage": null,
            "options": [
              {
                "text": "Modify the application to have both shared images and caching data written to Amazon EBS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the application to read and write cache data on Amazon S3, and also store shared images on S3.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Modify the application to use Amazon S3 for serving shared images; cache data can then be written to local disks.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the application to read and write cache data on Amazon S3, while continuing to write shared images to local disks.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 3,
          "poolQNum": 164,
          "question": {
            "id": 3,
            "questionText": "A Developer must allow guest users without logins to access an Amazon Cognito-enabled site to view files stored within an Amazon S3 bucket. How should the Developer meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a blank user ID in a user pool, add to the user group, and grant access to AWS resources.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a new identity pool, enable access to unauthenticated identities, and grant access to AWS resources.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a new user pool, enable access to authenticated identifies, and grant access to AWS resources.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a new user pool, disable authentication access, and grant access to AWS resources.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 4,
          "poolQNum": 288,
          "question": {
            "id": 4,
            "questionText": "An e-commerce web application that shares session state on-premises is being migrated to AWS. The application must be fault tolerant, natively highly scalable, and any service interruption should not affect the user experience. What is the best option to store the session state?",
            "questionImage": null,
            "options": [
              {
                "text": "Store the session state in Amazon ElastiCache.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the session state in Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the session state in Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable session stickiness using elastic load balancers.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 5,
          "poolQNum": 203,
          "question": {
            "id": 5,
            "questionText": "A Developer is storing sensitive data generated by an application in Amazon S3. The Developer wants to encrypt the data at rest. A company policy requires an audit trail of when the master key was used and by whom. Which encryption option will meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Server-side encryption with Amazon S3 managed keys (SSE-S3).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with AWS KMS managed keys (SSE-KMS).",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Server-side encryption with customer-provided keys (SSE-C).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with self-managed keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 6,
          "poolQNum": 148,
          "question": {
            "id": 6,
            "questionText": "A Developer needs to deploy an application running on AWS Fargate using Amazon ECS. The application has environment variables that must be passed to a container for the application to initialize. How should the environment variables be passed to the container?",
            "questionImage": null,
            "options": [
              {
                "text": "Define an array that includes the environment variables under the environment parameter within the service definition.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Define an array that includes the environment variables under the environment parameter within the task definition.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Define an array that includes the environment variables under the entryPoint parameter within the task definition.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Define an array that includes the environment variables under the entryPoint parameter within the service definition.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 7,
          "poolQNum": 17,
          "question": {
            "id": 7,
            "questionText": "A company is migrating its on-premises database to Amazon RDS for MySQL. The company has read-heavy workloads, and wants to make sure it re-factors its code to achieve optimum read performance for its queries. How can this objective be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Add database retries to effectively use RDS with vertical scaling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use RDS with multi-AZ deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a connection string to use an RDS read replica for read queries.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add a connection string to use a read replica on an EC2 instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 8,
          "poolQNum": 232,
          "question": {
            "id": 8,
            "questionText": "Which of the following are valid arguments for an SNS Publish request? (Choose THREE)",
            "questionImage": null,
            "options": [
              {
                "text": "TopicArn.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Subject.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Destination.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Format.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Message.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Language.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2",
            "3",
            "5"
          ],
          "correctOptions": [
            "1",
            "2",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 9,
          "poolQNum": 377,
          "question": {
            "id": 9,
            "questionText": "When a Developer tries to run an AWS CodeBuild project, it raises an error because the length of all environment variables exceeds the limit for the combined maximum of characters. What is the recommended solution?",
            "questionImage": null,
            "options": [
              {
                "text": "Add the export `LC_ALL=\"en_US.utf8\"` command to the `pre_build` section to ensure `POSIX` localization.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito to store key-value pairs for large numbers of environment variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the settings for the build project to use an Amazon S3 bucket for large numbers of environment variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Systems Manager Parameter Store to store large numbers of environment variables.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 10,
          "poolQNum": 296,
          "question": {
            "id": 10,
            "questionText": "A company is migrating a single-server, on-premises web application to AWS. The company intends to use multiple servers behind an Elastic Load Balancer (ELB) to balance the load, and will also store session data in memory on the web server. The company does not want to lose that session data if a server fails or goes offline, and it wants to minimize user's downtime. Where should the company move session data to MOST effectively reduce downtime and make users' session data more fault tolerant?",
            "questionImage": null,
            "options": [
              {
                "text": "An Amazon ElastiCache for Redis cluster.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "A second Amazon EBS volume.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The web server's primary disk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An Amazon EC2 instance dedicated to session data.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 11,
          "poolQNum": 159,
          "question": {
            "id": 11,
            "questionText": "A company wants to containerize an existing three-tier web application and deploy it to Amazon ECS Fargate. The application is using session data to keep track of user activities. Which approach would provide the BEST user experience?",
            "questionImage": null,
            "options": [
              {
                "text": "Provision a Redis cluster in Amazon ElastiCache and save the session data in the cluster.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a session table in Amazon Redshift and save the session data in the database table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable session stickiness in the existing Network Load Balancer and manage the session data in the container.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon S3 bucket as data store and save the session data in the bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 12,
          "poolQNum": 337,
          "question": {
            "id": 12,
            "questionText": "A company is building an application to track athlete performance using an Amazon DynamoDB table. Each item in the table is identified by a partition key (`user_id`) and a sort key (`sport_name`). The table design is shown below. (Note: Not all table attributes are shown) A Developer is asked to write a leaderboard application to display the top performers (`user_id`) based on the score for each `sport_name`. What process will allow the Developer to extract results MOST efficiently from the DynamoDB table?",
            "questionImage": "images/question337.jpg",
            "options": [
              {
                "text": "Use a DynamoDB query operation with the key attributes of `user_id` and `sport_name` and order the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a global secondary index with a partition key of `sport_name` and a sort key of score, and get the results.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use a DynamoDB scan operation to retrieve scores and `user_id` based on `sport_name`, and order the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a local secondary index with a primary key of `sport_name` and a sort key of score and get the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 13,
          "poolQNum": 316,
          "question": {
            "id": 13,
            "questionText": "A company has a website that is developed in PHP and WordPress and is launched using AWS Elastic Beanstalk. There is a new version of the website that needs to be deployed in the Elastic Beanstalk environment. The company cannot tolerate having the website offline if an update fails. Deployments must have minimal impact and rollback as soon as possible. What deployment method should be used?",
            "questionImage": null,
            "options": [
              {
                "text": "All at once.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Snapshots.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Immutable.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 14,
          "poolQNum": 257,
          "question": {
            "id": 14,
            "questionText": "Company B provides an online image recognition service and utilizes SQS to decouple system components for scalability The SQS consumers poll the imaging queue as often as possible to keep end-to-end throughput as high as possible. However, Company B is realizing that polling in tight loops is burning CPU cycles and increasing costs with empty responses. How can Company B reduce the number of empty responses?",
            "questionImage": null,
            "options": [
              {
                "text": "Set the imaging queue visibility `Timeout` attribute to 20 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set the Imaging queue `ReceiveMessageWaitTimeSeconds` attribute to 20 seconds.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set the imaging queue `MessageRetentionPeriod` attribute to 20 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set the `DelaySeconds` parameter of a message to 20 seconds.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 15,
          "poolQNum": 135,
          "question": {
            "id": 15,
            "questionText": "Two containerized microservices are hosted on Amazon EC2 ECS. The first microservice reads an Amazon RDS Aurora database instance, and the second microservice reads an Amazon DynamoDB table. How can each microservice be granted the minimum privileges?",
            "questionImage": null,
            "options": [
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `false` on EC2 instance boot in ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the second microservice with an IAM role for ECS tasks with read-only access to DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `false` on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `true` on EC2 instance boot in the ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the secondmicroservice with an IAM role for ECS tasks with read-only access to DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `true` on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 16,
          "poolQNum": 279,
          "question": {
            "id": 16,
            "questionText": "A company is running a Docker application on Amazon ECS. The application must scale based on user load in the last 15 seconds. How should a Developer instrument the code so that the requirement can be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 30 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a standard-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 30 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a standard-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 17,
          "poolQNum": 20,
          "question": {
            "id": 17,
            "questionText": "A software company needs to make sure user-uploaded documents are securely stored in Amazon S3. The documents must be encrypted at rest in Amazon S3. The company does not want to manage the security infrastructure in-house, but the company still needs extra protection to ensure it has control over its encryption keys due to industry regulations. Which encryption strategy should a developer use to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Server-side encryption with Amazon S3 managed keys (SSE-S3).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with customer-provided encryption keys (SSE-C).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with AWS KMS managed keys (SSE-KMS).",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client-side encryption.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 18,
          "poolQNum": 314,
          "question": {
            "id": 18,
            "questionText": "An application that runs on an Amazon EC2 instance needs to access and make API calls to multiple AWS services. What is the MOST secure way to provide access to the AWS services with MINIMAL management overhead?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS KMS to store and retrieve credentials.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use EC2 instance profiles.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS `root` user to make requests to the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store and retrieve credentials from AWS CodeCommit.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 19,
          "poolQNum": 286,
          "question": {
            "id": 19,
            "questionText": "A company needs to distribute firmware updates to its customers around the world. Which service will allow easy and secure control of the access to the downloads at the lowest cost?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon CloudFront with signed URLs for Amazon S3.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a dedicated Amazon CloudFront Distribution for each customer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudFront with AWS Lambda@Edge.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon API Gateway and AWS Lambda to control access to an S3 bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 20,
          "poolQNum": 233,
          "question": {
            "id": 20,
            "questionText": "How can software determine the public and private IP addresses of the Amazon EC2 instance that it is running on?",
            "questionImage": null,
            "options": [
              {
                "text": "Query the appropriate Amazon CloudWatch metric.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use `ipconfig` or `ifconfig` command.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Query the local instance userdata.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Query the local instance metadata.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 21,
          "poolQNum": 193,
          "question": {
            "id": 21,
            "questionText": "A Software Engineer developed an AWS Lambda function in Node.js to do some CPU-intensive data processing. With the default settings, the Lambda function takes about 5 minutes to complete. Which approach should a Developer take to increase the speed of completion?",
            "questionImage": null,
            "options": [
              {
                "text": "Instead of using Node.js, rewrite the Lambda function using Python.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Instead of packaging the libraries in the `ZIP` file with the function, move them to a Lambda layer and use the layer with the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Allocate the maximum available CPU units to the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the available memory to the function.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 22,
          "poolQNum": 214,
          "question": {
            "id": 22,
            "questionText": "A Developer is storing sensitive documents in Amazon S3 that will require encryption at rest. The encryption keys must be rotated annually, at least. What is the easiest way to achieve this?",
            "questionImage": null,
            "options": [
              {
                "text": "Encrypt the data before sending it to Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Import a custom key into AWS KMS with annual rotation enabled.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS KMS with automatic key rotation.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Export a key from AWS KMS to encrypt the data.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 23,
          "poolQNum": 67,
          "question": {
            "id": 23,
            "questionText": "A Developer must re-implement the business logic for an order fulfilment system. The business logic has to make requests to multiple vendors to decide where to purchase an item. The whole process can take up to a week to complete. What is the MOST efficient and SIMPLEST way to implement a system that meets these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS Step Functions to execute parallel Lambda functions, and join the results.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an AWS SQS for each vendor, poll the queue from a worker instance, and joint the results.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Lambda to asynchronously call a Lambda function for each vendor, and join the results.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudWatch Events to orchestrate the Lambda functions.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 24,
          "poolQNum": 169,
          "question": {
            "id": 24,
            "questionText": "A Developer is preparing a deployment package using AWS CloudFormation. The package consists of two separate templates: one for the infrastructure and one for the application. The application has to be inside the VPC that is created from the infrastructure template. How can the application stack refer to the VPC created from the infrastructure template?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the Ref function to import the VPC into the application stack from the infrastructure template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the export flag in the infrastructure template, and then use the `Fn::ImportValue` function in the application template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use the `DependsOn` attribute to specify that the application instance depends on the VPC in the application template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `Fn::GetAtt` function to include the attribute of the VPC in the application template.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 25,
          "poolQNum": 258,
          "question": {
            "id": 25,
            "questionText": "An Amazon S3 bucket, `myawsbucket` is configured with website hosting in Tokyo region, what is the region-specific website endpoint?",
            "questionImage": null,
            "options": [
              {
                "text": "`www.myawsbucket.ap-northeast-1.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`myawsbucket.s3-website-ap-northeast-1.amazonaws.com`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`myawsbucket.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`myawsbucket.tokyo.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 26,
          "poolQNum": 376,
          "question": {
            "id": 26,
            "questionText": "The Developer for a retail company must integrate a fraud detection solution into the order processing solution. The fraud detection solution takes between ten and thirty minutes to verify an order. At peak, the web site can receive one hundred orders per minute. What is the most scalable method to add the fraud detection solution to the order processing pipeline?",
            "questionImage": null,
            "options": [
              {
                "text": "Add all new orders to an Amazon SQS queue. Configure a fleet of 10 EC2 instances spanning multiple AZs with the fraud detection solution installed on them to pull orders from this queue. Update the order with a pass or fails status.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add all new orders to an SQS queue. Configure an Auto Scaling group that uses the queue depth metric as its unit of scale to launch a dynamically-sized fleet of EC2 instances spanning multiple AZs with the fraud detection solution installed on them to pull orders from this queue. Update the order with a pass or fails status.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add all new orders to an Amazon Kinesis Stream. Subscribe a Lambda function to automatically read batches of records from the Kinesis Stream. The Lambda function includes the fraud detection software and will update the order with a pass or fail status.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write all new orders to Amazon DynamoDB. Configure DynamoDB Streams to include all new orders. Subscribe a Lambda function to automatically read batches of records from the Kinesis Stream. The Lambda function includes the fraud detection software and will update the order with a pass or fail status.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 27,
          "poolQNum": 54,
          "question": {
            "id": 27,
            "questionText": "A Developer is creating a mobile application with a limited budget. The solution requires a scalable service that will enable customers to sign up and authenticate into the mobile application while using the organization's current SAML 2.0 identity provider. Which AWS service should be used to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS IAM.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon EC2.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 28,
          "poolQNum": 336,
          "question": {
            "id": 28,
            "questionText": "A Developer is writing a serverless application that requires that an AWS Lambda function be invoked every 10 minutes. What is an automated and serverless way to trigger the function?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy an Amazon EC2 instance based on Linux, and edit its `/etc/crontab` file by adding a command to periodically invoke the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure an environment variable named PERIOD for the Lambda function. Set the value to `600`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon CloudWatch Events rule that triggers on a regular schedule to invoke the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an Amazon SNS topic that has a subscription to the Lambda function with a 600-second timer.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 29,
          "poolQNum": 269,
          "question": {
            "id": 29,
            "questionText": "What type of block cipher does Amazon S3 offer for server side encryption?",
            "questionImage": null,
            "options": [
              {
                "text": "Triple DES.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Advanced Encryption Standard.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Blowfish.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "RC5.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 30,
          "poolQNum": 14,
          "question": {
            "id": 30,
            "questionText": "An application deployed on AWS Elastic Beanstalk experiences increased error rates during deployments of new application versions, resulting in service degradation for users. The Development team believes that this is because of the reduction in capacity during the deployment steps. The team would like to change the deployment policy configuration of the environment to an option that maintains full capacity during deployment while using the existing instances. Which deployment policy will meet these requirements while using the existing instances?",
            "questionImage": null,
            "options": [
              {
                "text": "All at once.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling with additional batch.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Immutable.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 31,
          "poolQNum": 303,
          "question": {
            "id": 31,
            "questionText": "A Developer wants access to make the log data of an application running on an EC2 instance available to systems administrators. Which of the following enables monitoring of this metric in Amazon CloudWatch?",
            "questionImage": null,
            "options": [
              {
                "text": "Retrieve the log data from CloudWatch using the `GetMetricData` API call.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Retrieve the log data from AWS CloudTrail using the `LookupEvents` API call.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Launch a new EC2 instance, configure Amazon CloudWatch Events, and then install the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Install the Amazon CloudWatch Logs agent on the EC2 instance that the application is running on.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 32,
          "poolQNum": 102,
          "question": {
            "id": 32,
            "questionText": "A Developer will be using the AWS CLI on a local development server to manage AWS services. What can be done to ensure that the CLI uses the Developer's IAM permissions when making commands?",
            "questionImage": null,
            "options": [
              {
                "text": "Specify the Developer's IAM access key ID and secret access key as parameters for each CLI command.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Run the `aws configure` CLI command, and provide the Developer's IAM access key ID and secret access key.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Specify the Developer's IAM user name and password as parameters for each CLI command.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the Developer's IAM role when making the CLI command.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 33,
          "poolQNum": 308,
          "question": {
            "id": 33,
            "questionText": "A Development team has pushed out 10 applications running on several Amazon EC2 instances. The Operations team is asking for a graphical representation of one key performance metric for each application. These metrics should be available on one screen for easy monitoring. Which steps should the Developer take to accomplish this using Amazon CloudWatch?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a custom namespace with a unique metric name for each application.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a custom dimension with a unique metric name for each application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a custom event with a unique metric name for each application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a custom alarm with a unique metric name for each application.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 34,
          "poolQNum": 334,
          "question": {
            "id": 34,
            "questionText": "In a move toward using microservices, a company's Management team has asked all Development teams to build their services so that API requests depend only on that service's data store. One team is building a Payments service which has its own database; the service needs data that originates in the Accounts database. Both are using Amazon DynamoDB. What approach will result in the simplest, decoupled, and reliable method to get near-real time updates from the Accounts database?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon Glue to perform frequent ETL updates from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache in Payments, with the cache updated by triggers in the Accounts database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Kinesis Data Firehose to deliver all changes from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon DynamoDB Streams to deliver all changes from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 35,
          "poolQNum": 388,
          "question": {
            "id": 35,
            "questionText": "A company has an application that needs to get objects from an Amazon S3 bucket. The application runs on Amazon EC2 instances. All the objects in the S3 bucket are encrypted with an AWS Key Management Service (AWS KMS) customer managed key. The resources in the VPC do not have access to the internet and use a gateway VPC endpoint to access Amazon S3. The company discovers that the application is unable to get objects from the S3 bucket. Which factors could cause this issue? (Choose three.)",
            "questionImage": null,
            "options": [
              {
                "text": "The IAM instance profile that is attached to the EC2 instances does not allow the s3:ListBucket action for the S3 bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The IAM instance profile that is attached to the EC2 instances does not allow the s3:ListParts action for the S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The KMS key policy that encrypts the objects in the S3 bucket does not allow the kms:ListKeys action to the EC2 instance profile ARN.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The KMS key policy that encrypts the objects in the S3 bucket does not allow the kms:Decrypt action to the EC2 instance profile ARN.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The S3 bucket policy does not allow access from the gateway VPC endpoint.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The security group that is attached to the EC2 instances is missing an inbound rule from the S3 managed prefix list over port 443.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "4",
            "5"
          ],
          "correctOptions": [
            "1",
            "4",
            "5"
          ],
          "isCorrect": true
        },
        {
          "qNum": 36,
          "poolQNum": 349,
          "question": {
            "id": 36,
            "questionText": "A stock market monitoring application uses Amazon Kinesis for data ingestion. During simulated tests of peak data rates, the Kinesis stream cannot keep up with the incoming data. What step will allow Kinesis to accommodate the traffic during peak hours?",
            "questionImage": null,
            "options": [
              {
                "text": "Install the Kinesis Producer Library (KPL) for ingesting data into the stream.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Reduce the data retention period to allow for more data ingestion using `DecreaseStreamRetentionPeriod`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the shard count of the stream using `UpdateShardCount`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Ingest multiple records into the stream in a single call using `PutRecords`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 37,
          "poolQNum": 260,
          "question": {
            "id": 37,
            "questionText": "You have written an application that uses the Elastic Load Balancing service to spread traffic to several web servers. Your users complain that they are sometimes forced to login again in the middle of using your application, after they have already logged in. This is not behavior you have designed. What is a possible solution to prevent this happening?",
            "questionImage": null,
            "options": [
              {
                "text": "Use instance memory to save session state.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use instance storage to save session state.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use EBS to save session state.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use ElastiCache to save session state.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Glacier to save session slate.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 38,
          "poolQNum": 3,
          "question": {
            "id": 38,
            "questionText": "A developer wants to send multi-value headers to an AWS Lambda function that is registered as a target with an Application Load Balancer (ALB). What should the developer do to achieve this?",
            "questionImage": null,
            "options": [
              {
                "text": "Place the Lambda function and target group in the same account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Send the request body to the Lambda function with a size less than 1 MB 0.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Include the Base64 encoding status status code, status description, and headers in the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable the multi-value headers on the ALB.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 39,
          "poolQNum": 372,
          "question": {
            "id": 39,
            "questionText": "An application displays a status dashboard. The status is updated by 1 KB messages from an SQS queue. Although the status changes infrequently, the Developer must minimize the time between the message arrival in the queue and the dashboard update. What technique provides the shortest delay in updating the dashboard?",
            "questionImage": null,
            "options": [
              {
                "text": "Retrieve the messages from the queue using long polling every 20 seconds.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Reduce the size of the messages by compressing them before sending.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Retrieve the messages from the queue using short polling every 10 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Reduce the size of each message payload by sending it in two parts.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 40,
          "poolQNum": 375,
          "question": {
            "id": 40,
            "questionText": "After installing the AWS CLI, a Developer tries to run the command `aws configure` but receives the following error: `Error: aws: command not found`. What is the most likely cause of this error?",
            "questionImage": null,
            "options": [
              {
                "text": "The `aws` executable is not in the `PATH` environment variable.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Access to the `aws` executable has been denied to the installer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Incorrect AWS credentials were provided.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The `aws` script does not have an executable file mode.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 41,
          "poolQNum": 146,
          "question": {
            "id": 41,
            "questionText": "A front-end web application is using Amazon Cognito user pools to handle the user authentication flow. A developer is integrating Amazon DynamoDB into the application using the AWS SDK for JavaScript. How would the developer securely call the API without exposing the access or secret keys?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure Amazon Cognito identity pools and exchange the JSON Web Token (JWT) for temporary credentials.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Run the web application in an Amazon EC2 instance with the instance profile configured.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Hardcore the credentials, use Amazon S3 to host the web application, and enable server-side encryption.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito user pool JSON Web Tokens (JWITs) to access the DynamoDB APIs.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 42,
          "poolQNum": 341,
          "question": {
            "id": 42,
            "questionText": "A company has multiple Developers located across the globe who are updating code incrementally for a development project. When Developers upload code concurrently, internet connectivity is slow and it is taking a long time to upload code for deployment in AWS Elastic Beanstalk. Which step will result in minimized upload and deployment time with the LEAST amount of administrative effort?",
            "questionImage": null,
            "options": [
              {
                "text": "Allow the Developers to upload the code to an Amazon S3 bucket, and deploy it directly to Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Allow the Developers to upload the code to a central FTP server to deploy the application to Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an AWS CodeCommit repository, allow the Developers to commit code to it, and then directly deploy the code to Elastic Beanstalk.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a code repository on an Amazon EC2 instance so that all Developers can update the code, and deploy the application from the instance to Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 43,
          "poolQNum": 362,
          "question": {
            "id": 43,
            "questionText": "A Developer has developed a web application and wants to deploy it quickly on a Tomcat server on AWS. The Developer wants to avoid having to manage the underlying infrastructure. What is the easiest way to deploy the application, based on these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS CloudFormation.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Elastic Beanstalk.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodePipeline",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 44,
          "poolQNum": 69,
          "question": {
            "id": 44,
            "questionText": "A Developer is receiving HTTP `400`: `ThrottlingException` errors intermittently when calling the Amazon CloudWatch API. When a call fails, no data is retrieved. What best practice should first be applied to address this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Contact AWS Support for a limit increase.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS CLI to get the metrics.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Analyze the applications and remove the API call.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Retry the call with exponential backoff.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 45,
          "poolQNum": 361,
          "question": {
            "id": 45,
            "questionText": "A Developer is creating a Lambda function that will generate and export a file. The function requires 100 MB of temporary storage for temporary files while executing. These files will not be needed after the function is complete. How can the Developer MOST efficiently handle the temporary files?",
            "questionImage": null,
            "options": [
              {
                "text": "Store the files in EBS and delete the files at the end of the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Copy the files to EFS and delete the files at the end of the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the files in the `/tmp` directory and delete the files at the end of the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Copy the files to an S3 bucket with a lifecycle policy to delete the files.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 46,
          "poolQNum": 382,
          "question": {
            "id": 46,
            "questionText": "A company is using Amazon API Gateway to manage access to a set of microservices implemented as AWS Lambda functions. Following a bug report, the company makes a minor breaking change to one of the APIs. In order to avoid impacting existing clients when the new API is deployed, the company wants to allow clients six months to migrate from v1 to v2. Which approach should the Developer use to handle this change?",
            "questionImage": null,
            "options": [
              {
                "text": "Update the underlying Lambda function and provide clients with the new Lambda invocation URL.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use API Gateway to automatically propagate the change to clients, specifying 180 days in the phased deployment parameter.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use API Gateway to deploy a new stage named v2 to the API and provide users with its URL.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Update the underlying Lambda function, create an Amazon CloudFront distribution with the updated Lambda function as its origin.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 47,
          "poolQNum": 329,
          "question": {
            "id": 47,
            "questionText": "A Developer must deploy a new AWS Lambda function using an AWS CloudFormation template. Which procedures will deploy a Lambda function? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Upload the code to an AWS CodeCommit repository, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an `AWS::Lambda::Function` resource in the template, then write the code directly inside the CloudFormation template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload a `.ZIP` file containing the function code to Amazon S3, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload a `.ZIP` file to AWS CloudFormation containing the function code, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload the function code to a private Git repository, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "3"
          ],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 48,
          "poolQNum": 317,
          "question": {
            "id": 48,
            "questionText": "A company has a multi-tiered web application on AWS. During a recent spike in traffic, one of the primary relational databases on Amazon RDS could not serve all the traffic. Some read queries for repeatedly accessed items failed, so users received error messages. What can be done to minimize the impact on database read queries MOST efficiently during future traffic spikes?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon S3 to cache database query results.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon RDS as a custom origin for Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use local storage and memory on Amazon EC2 instances to cache data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache in front of the primary database to cache data.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 49,
          "poolQNum": 108,
          "question": {
            "id": 49,
            "questionText": "What are the steps to using the AWS CLI to launch a templatized serverless application?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS CloudFormation get-template then CloudFormation execute-change-set.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CloudFormation validate-template then CloudFormation create-change-set.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CloudFormation package then CloudFormation deploy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS CloudFormation create-stack then CloudFormation update-stack.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 50,
          "poolQNum": 323,
          "question": {
            "id": 50,
            "questionText": "A Developer has been asked to make changes to the source code of an AWS Lambda function. The function is managed using an AWS CloudFormation template. The template is configured to load the source code from an Amazon S3 bucket. The Developer manually created a `.ZIP` file deployment package containing the changes and put the file into the correct location on Amazon S3. When the function is invoked, the code changes have not been applied. What step is required to update the function with the changes?",
            "questionImage": null,
            "options": [
              {
                "text": "Delete the `.ZIP` file on S3, and re-upload by using a different object key name.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the CloudFormation stack with the correct values for the function code properties S3Bucket, S3Key, or S3ObjectVersion.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Ensure that the function source code is base64-encoded before uploading the deployment package to S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the execution role of the Lambda function to allow S3 access permission to the deployment package `.ZIP` file.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 51,
          "poolQNum": 22,
          "question": {
            "id": 51,
            "questionText": "A gaming company is developing a mobile game application for iOS and Android platforms. This mobile game securely stores user data locally on the device. The company wants to allow users to use multiple device for the game, which requires user data synchronization across device.Which service should be used to synchronize user data across devices without the need to create a backend application?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 52,
          "poolQNum": 167,
          "question": {
            "id": 52,
            "questionText": "A Developer registered an AWS Lambda function as a target for an Application Load Balancer (ALB) using a CLI command. However, the Lambda function is not being invoked when the client sends requests through the ALB. Why is the Lambda function not being invoked?",
            "questionImage": null,
            "options": [
              {
                "text": "A Lambda function cannot be registered as a target for an ALB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A Lambda function can be registered with an ALB using AWS Management Console only.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The permissions to invoke the Lambda function are missing.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Cross-zone is not enabled on the ALB.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 53,
          "poolQNum": 200,
          "question": {
            "id": 53,
            "questionText": "A Developer has created a new AWS IAM user that has `s3:putObject` permission to write to a specific Amazon S3 bucket. This S3 bucket uses server-side encryption with AWS KMS managed keys (SSE-KMS) as the default encryption. Using the access key and secret key of the IAM user, the application received an access denied error when calling the `PutObject` API. How can this issue be resolved?",
            "questionImage": null,
            "options": [
              {
                "text": "Update the policy of the IAM user to allow the `s3:EncryptionConfiguration` action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the bucket policy of the S3 bucket to allow the IAM user to upload objects.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the policy of the IAM user to allow the `kms:GenerateDataKey` action.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Update the ACL of the S3 bucket to allow the IAM user to upload objects.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 54,
          "poolQNum": 136,
          "question": {
            "id": 54,
            "questionText": "A developer has written an AWS Lambda function using Java as the runtime environment. The developer wants to isolate a performance bottleneck in the code. Which steps should be taken to reveal the bottleneck?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the Amazon CloudWatch API to write timestamps to a custom CloudWatch metric. Use the CloudWatch console to analyze the resulting data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS X-Ray API to write trace data into X-Ray from strategic places within the code. Use the Amazon CloudWatch console to analyze the resulting data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS X-Ray API to write trace data into X-Ray from strategic places within the code. Use the X-Ray console to analyze the resulting data.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use the Amazon CloudWatch API to write timestamps to a custom CloudWatch metric. Use the AWS X-Ray console to analyze the resulting data.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 55,
          "poolQNum": 250,
          "question": {
            "id": 55,
            "questionText": "Which of the following services are included at no additional cost with the use of the AWS platform?",
            "questionImage": null,
            "options": [
              {
                "text": "Simple Storage Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Elastic Compute Cloud.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Auto Scaling.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Elastic Load Balancing.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "CloudFormation.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Simple Workflow Service.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "3",
            "6"
          ],
          "correctOptions": [
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 56,
          "poolQNum": 300,
          "question": {
            "id": 56,
            "questionText": "A Developer is building a mobile application and needs any update to user profile data to be pushed to all devices accessing the specific identity. The Developer does not want to manage a back end to maintain the user profile data. What is the MOST efficient way for the Developer to achieve these requirements using Amazon Cognito?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Cognito federated identities.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use a Cognito user pool.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Cognito Sync.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Cognito events.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 57,
          "poolQNum": 219,
          "question": {
            "id": 57,
            "questionText": "After launching an instance that you intend to serve as a NAT (Network Address Translation) device in a public subnet you modify your route tables to have the NAT device be the target of internet bound traffic of your private subnet. When you try and make an outbound connection to the Internet from an instance in the private subnet, you are not successful. NAT device be the target of internet bound traffic of your private subnet. Which of the following steps could resolve the issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Attaching a second Elastic Network interface (ENI) to the NAT instance, and placing it in the private subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Attaching a second Elastic Network Interface (ENI) to the instance in the private subnet, and placing it in the public subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disabling the `Source/Destination Check` attribute on the NAT instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Attaching an Elastic IP address to the instance in the private subnet.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 58,
          "poolQNum": 212,
          "question": {
            "id": 58,
            "questionText": "An application is running on a cluster of Amazon EC2 instances. While trying to read objects stored within a single Amazon S3 bucket that are encrypted with server-side encryption with AWS KMS managed keys (SSE-KMS), the application receives the following error. Which combination of steps should be taken to prevent this failure? (Choose TWO)",
            "questionImage": "images/question212.jpg",
            "options": [
              {
                "text": "Contact AWS Support to request an AWS KMS rate limit increase.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Perform error retries with exponential backoff in the application code.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Contact AWS Support to request a S3 rate limit increase.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Import a customer master key (CMK) with a larger key size.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use more than one customer master key (CMK) to encrypt S3 data.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "2"
          ],
          "correctOptions": [
            "1",
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 59,
          "poolQNum": 295,
          "question": {
            "id": 59,
            "questionText": "A Developer is investigating an issue whereby certain requests are passing through an Amazon API Gateway endpoint /MyAPI, but the requests do not reach the AWS Lambda function backing /MyAPI. The Developer found that a second Lambda function sometimes runs at maximum concurrency allowed for the given AWS account. How can the Developer address this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Manually reduce the concurrent execution limit at the account level.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add another API Gateway stage for /MyAPI, and shard the requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure the second Lambda function's concurrency execution limit.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Reduce the throttling limits in the API Gateway /MyAPI endpoint",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 60,
          "poolQNum": 369,
          "question": {
            "id": 60,
            "questionText": "A company is using AWS CodePipeline to deliver one of its applications. The delivery pipeline is triggered by changes to the master branch of an AWS CodeCommit repository and uses AWS CodeBuild to implement the test and build stages of the process and AWS CodeDeploy to deploy the application. The pipeline has been operating successfully for several months and there have been no modifications. Following a recent change to the application's source code, AWS CodeDeploy has not deployed the updates application as expected. What are the possible causes? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "The change was not made in the master branch of the AWS CodeCommit repository.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "One of the earlier stages in the pipeline failed and the pipeline has terminated.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "One of the Amazon EC2 instances in the company's AWS CodePipeline cluster is inactive.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The AWS CodePipeline is incorrectly configured and is not executing AWS CodeDeploy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodePipeline does not have permissions to access AWS CodeCommit.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "2"
          ],
          "correctOptions": [
            "1",
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 61,
          "poolQNum": 370,
          "question": {
            "id": 61,
            "questionText": "A social media company is using Amazon Cognito in order to synchronize profiles across different mobile devices, to enable end users to have a seamless experience. Which of the following configurations can be used to silently notify users whenever an update is available on all other devices?",
            "questionImage": null,
            "options": [
              {
                "text": "Modify the user pool to include all the devices which keep them in sync.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the SyncCallback interface to receive notifications on the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon Cognito stream to analyze the data and push the notifications.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the push synchronization feature with the appropriate IAM role.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 62,
          "poolQNum": 151,
          "question": {
            "id": 62,
            "questionText": "A developer is writing an application that will process data delivered into an Amazon S3 bucket. The data is delivered approximately 10 times a day, and the developer expects the data will be processed in less than 1 minute, on average. How can the developer deploy and invoke the application with the lowest cost and lowest latency?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an Amazon CloudWatch alarm triggered by an S3 object upload.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an S3 event notification.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an Amazon CloudWatch scheduled event.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the application onto an Amazon EC2 instance and have it poll the S3 bucket for new objects.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 63,
          "poolQNum": 53,
          "question": {
            "id": 63,
            "questionText": "A web application is using Amazon Kinesis Streams for clickstream data that may not be consumed for up to 12 hours. How can the Developer implement encryption at rest for data within the Kinesis Streams?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable SSL connections to Kinesis.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Kinesis Consumer Library.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Encrypt the data once it is at rest with a Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable server-side encryption in Kinesis Streams.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 64,
          "poolQNum": 205,
          "question": {
            "id": 64,
            "questionText": "A company is developing a web application that allows its employees to upload a profile picture to a private Amazon S3 bucket. There is no size limit for the profile pictures, which should be displayed every time an employee logs in. For security reasons, the pictures cannot be publicly accessible. What is a viable long-term solution for this scenario?",
            "questionImage": null,
            "options": [
              {
                "text": "Generate a presigned URL when a picture is uploaded. Save the URL in an Amazon DynamoDB table. Return the URL to the browser when the employee logs in.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Save the picture's S3 key in an Amazon DynamoDB table. Create an Amazon S3 VPC endpoint to allow the employees to download pictures once they log in.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Encode a picture using base64. Save the base64 string in an Amazon DB table. Allow the browser to retrieve the string and convert it to a picture.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Save the picture's S3 key in an Amazon DynamoDB table. Use a function to generate a presigned URL every time an employee logs in. Return the URL to the browser.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 65,
          "poolQNum": 158,
          "question": {
            "id": 65,
            "questionText": "A Developer has an Amazon DynamoDB table that must be in provisioned mode to comply with user requirements. The application needs to support the following: Average item size: 10 KB. Item reads each second: 10 strongly consistent. Item writes each second: 2 transactional. Which read and write capacity cost-effectively meets these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Read `10`; write `2`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Read `30`; write `40`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use on-demand scaling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Read `300`; write `400`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        }
      ],
      "questionMap": {
        "1": 32,
        "2": 373,
        "3": 164,
        "4": 288,
        "5": 203,
        "6": 148,
        "7": 17,
        "8": 232,
        "9": 377,
        "10": 296,
        "11": 159,
        "12": 337,
        "13": 316,
        "14": 257,
        "15": 135,
        "16": 279,
        "17": 20,
        "18": 314,
        "19": 286,
        "20": 233,
        "21": 193,
        "22": 214,
        "23": 67,
        "24": 169,
        "25": 258,
        "26": 376,
        "27": 54,
        "28": 336,
        "29": 269,
        "30": 14,
        "31": 303,
        "32": 102,
        "33": 308,
        "34": 334,
        "35": 388,
        "36": 349,
        "37": 260,
        "38": 3,
        "39": 372,
        "40": 375,
        "41": 146,
        "42": 341,
        "43": 362,
        "44": 69,
        "45": 361,
        "46": 382,
        "47": 329,
        "48": 317,
        "49": 108,
        "50": 323,
        "51": 22,
        "52": 167,
        "53": 200,
        "54": 136,
        "55": 250,
        "56": 300,
        "57": 219,
        "58": 212,
        "59": 295,
        "60": 369,
        "61": 370,
        "62": 151,
        "63": 53,
        "64": 205,
        "65": 158
      }
    },
    {
      "id": "1764413225061",
      "timestamp": 1764413225062,
      "score": "67.69",
      "results": [
        {
          "qNum": 1,
          "poolQNum": 119,
          "question": {
            "id": 1,
            "questionText": "A company has 25,000 employees and is growing. The company is creating an application that will be accessible to its employees only. A developer is using Amazon S3 to store images and Amazon RDS to store application data. The company requires that all employee information remain in the legacy Security Assertion Markup Language (SAML) employee directory only and is not interested in mirroring any employee information on AWS. How can the developer provide authorized access for the employees who will be using this application so each employee can access their own application data only?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon VPC and keep all resources inside the VPC, and use a VPC link for the S3 bucket with the bucket policy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito user pools, federate with the SAML provider, and use user pool groups with an IAM policy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon Cognito identity pool, federate with the SAML provider, and use an IAM condition key with a value for the `cognito-identity.amazonaws.com:sub` variable to grant access to the employees.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a unique IAM role for each employee and have each employee assume the role to access the application so they can access their personal data only.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 2,
          "poolQNum": 243,
          "question": {
            "id": 2,
            "questionText": "Company C has recently launched an online commerce site for bicycles on AWS. They have a `Product` DynamoDB table that stores details for each bicycle, such as, manufacturer, color, price, quantity and size to display in the online store. Due to customer demand, they want to include an image for each bicycle along with the existing details. Which approach below provides the least impact to provisioned throughput on the `Product` table?",
            "questionImage": null,
            "options": [
              {
                "text": "Serialize the image and store it in multiple DynamoDB tables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an `Images` DynamoDB table to store the Image with a foreign key constraint to the `Product` table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an image data type to the `Product` table to store the images in binary format.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the images in Amazon S3 and add an S3 URL pointer to the `Product` table item for each image.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 3,
          "poolQNum": 377,
          "question": {
            "id": 3,
            "questionText": "When a Developer tries to run an AWS CodeBuild project, it raises an error because the length of all environment variables exceeds the limit for the combined maximum of characters. What is the recommended solution?",
            "questionImage": null,
            "options": [
              {
                "text": "Add the export `LC_ALL=\"en_US.utf8\"` command to the `pre_build` section to ensure `POSIX` localization.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito to store key-value pairs for large numbers of environment variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the settings for the build project to use an Amazon S3 bucket for large numbers of environment variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Systems Manager Parameter Store to store large numbers of environment variables.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 4,
          "poolQNum": 62,
          "question": {
            "id": 4,
            "questionText": "An application reads data from an Amazon DynamoDB table. Several times a day, for a period of 15 seconds, the application receives multiple `ProvisionedThroughputExceeded` errors. How should this exception be handled?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a new global secondary index for the table to help with the additional requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Retry the failed read requests with exponential backoff.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Immediately retry the failed read requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the DynamoDB `UpdateItem` API to increase the provisioned throughput capacity of the table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 5,
          "poolQNum": 274,
          "question": {
            "id": 5,
            "questionText": "A Developer created a new AWS account and must create a scalable AWS Lambda function that meets the following requirements for concurrent execution: Average execution time of 100 seconds 50 requests per second. Which step must be taken prior to deployment to prevent errors?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement dead-letter queues to capture invocation errors.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an event source from Amazon API Gateway to the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement error handling within the application code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Contact AWS Support to increase the concurrent execution limits.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 6,
          "poolQNum": 306,
          "question": {
            "id": 6,
            "questionText": "A company is providing services to many downstream consumers. Each consumer may connect to one or more services. This has resulted in a complex architecture that is difficult to manage and does not scale well. The company needs a single interface to manage these services to consumers. Which AWS service should be used to refactor this architecture?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS X-Ray.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SQS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon API Gateway.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 7,
          "poolQNum": 365,
          "question": {
            "id": 7,
            "questionText": "According to best practice, how should access keys be managed in AWS? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Use the same access key in all applications for consistency.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Delete all access keys for the account `root` user.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Leave unused access keys in the account for tracking purposes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Embed and encrypt access keys in code for continuous deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon IAM roles instead of access keys where possible.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2",
            "5"
          ],
          "correctOptions": [
            "2",
            "5"
          ],
          "isCorrect": true
        },
        {
          "qNum": 8,
          "poolQNum": 310,
          "question": {
            "id": 8,
            "questionText": "A company has three different environments: Development, QA, and Production. The company wants to deploy its code first in the Development environment, then QA, and then Production. Which AWS service can be used to meet this requirement?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS CodeCommit to create multiple repositories to deploy the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CodeBuild to create, configure, and deploy multiple build application projects.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Data Pipeline to create multiple data pipeline provisions to deploy the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CodeDeploy to create multiple deployment groups.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 9,
          "poolQNum": 266,
          "question": {
            "id": 9,
            "questionText": "Which of the following statements about SQS is true?",
            "questionImage": null,
            "options": [
              {
                "text": "Messages will be delivered exactly once and messages will be delivered in First in, First out order.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered exactly once and message delivery order is indeterminate.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered one or more times and messages will be delivered in First in, First out order.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered one or more times and message delivery order is indeterminate.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 10,
          "poolQNum": 293,
          "question": {
            "id": 10,
            "questionText": "To include objects defined by the AWS Serverless Application Model (SAM) in an AWS CloudFormation template, in addition to `Resources`, what section MUST be included in the document root?",
            "questionImage": null,
            "options": [
              {
                "text": "`Conditions`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`Globals`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`Transform`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`Properties`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 11,
          "poolQNum": 2,
          "question": {
            "id": 11,
            "questionText": "Which of the following services are key/value stores? (Choose 3 answers)",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon ElastiCache.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Simple Notification Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Simple Workflow Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Simple Storage Service.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "3",
            "5"
          ],
          "correctOptions": [
            "1",
            "3",
            "5"
          ],
          "isCorrect": true
        },
        {
          "qNum": 12,
          "poolQNum": 328,
          "question": {
            "id": 12,
            "questionText": "A Developer has published an update to an application that is served to a global user base using Amazon CloudFront. After deploying the application, users are not able to see the updated changes. How can the Developer resolve this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Remove the origin from the CloudFront configuration and add it again.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disable forwarding of query strings and request headers from the CloudFront distribution configuration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Invalidate all the application objects from the edge caches.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Disable the CloudFront distribution and enable it again to update all the edge locations.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 13,
          "poolQNum": 292,
          "question": {
            "id": 13,
            "questionText": "A Developer wants to debug an application by searching and filtering log data. The application logs are stored in Amazon CloudWatch Logs. The Developer creates a new metric filter to count exceptions in the application logs. However, no results are returned from the logs. What is the reason that no filtered results are being returned?",
            "questionImage": null,
            "options": [
              {
                "text": "A setup of the Amazon CloudWatch interface VPC endpoint is required for filtering the CloudWatch Logs in the VPC.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "CloudWatch Logs only publishes metric data for events that happen after the filter is created.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The log group for CloudWatch Logs should be first streamed to Amazon Elasticsearch Service before metric filtering returns the results.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Metric data points for logs groups can be filtered only after they are exported to an Amazon S3 bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 14,
          "poolQNum": 151,
          "question": {
            "id": 14,
            "questionText": "A developer is writing an application that will process data delivered into an Amazon S3 bucket. The data is delivered approximately 10 times a day, and the developer expects the data will be processed in less than 1 minute, on average. How can the developer deploy and invoke the application with the lowest cost and lowest latency?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an Amazon CloudWatch alarm triggered by an S3 object upload.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an S3 event notification.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an Amazon CloudWatch scheduled event.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the application onto an Amazon EC2 instance and have it poll the S3 bucket for new objects.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 15,
          "poolQNum": 194,
          "question": {
            "id": 15,
            "questionText": "An online retail company has deployed a serverless application with AWS Lambda, Amazon API Gateway, Amazon S3, and Amazon DynamoDB using AWS CloudFormation. The company rolled out a new release with major upgrades to the Lambda function and deployed the release to production. Subsequently, the application stopped working. Which solution should bring the application back up as quickly as possible?",
            "questionImage": null,
            "options": [
              {
                "text": "Redeploy the application on Amazon EC2 so the Lambda function can resolve dependencies.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Migrate DynamoDB to Amazon RDS and redeploy the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Roll back the Lambda function to the previous version.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Deploy the latest Lambda function in a different Region.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 16,
          "poolQNum": 390,
          "question": {
            "id": 16,
            "questionText": "A developer is deploying an application on Amazon EC2 instances that run in Account A. The application needs to read data from an existing Amazon Kinesis data stream in Account B. Which actions should the developer take to provide the application with access to the stream? (Choose two.)",
            "questionImage": null,
            "options": [
              {
                "text": "Update the instance profile role in Account A with stream read permissions.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an IAM role with stream read permissions in Account B.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a trust policy to the instance profile role and IAM role in Account B to allow the instance profile role to assume the IAM role.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a trust policy to the instance profile role and IAM role in Account B to allow reads from the stream.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a resource-based policy in Account B to allow read access from the instance profile role.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "3",
            "4"
          ],
          "correctOptions": [
            "1",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 17,
          "poolQNum": 35,
          "question": {
            "id": 17,
            "questionText": "An application running on EC2 instances is storing data in an S3 bucket. Security policy mandates that all data must be encrypted in transit. How can the Developer ensure that all traffic to the S3 bucket is encrypted?",
            "questionImage": null,
            "options": [
              {
                "text": "Install certificates on the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a bucket policy that allows traffic where `SecureTransport` is `true`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an HTTPS redirect on the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a bucket policy that denies traffic where `SecureTransport` is `false`.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 18,
          "poolQNum": 324,
          "question": {
            "id": 18,
            "questionText": "A Developer wants to enable AWS X-Ray for a secure application that runs in an Amazon ECS environment. What combination of steps will enable X-Ray? (Select THREE)",
            "questionImage": null,
            "options": [
              {
                "text": "Create a Docker image that runs the X-Ray daemon.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add instrumentation to the application code for X-Ray.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install the X-Ray daemon on the underlying EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure and use an IAM EC2 instance role.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Register the application with X-Ray.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure and use an IAM role for tasks.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "5",
            "6"
          ],
          "correctOptions": [
            "1",
            "2",
            "6"
          ],
          "isCorrect": false
        },
        {
          "qNum": 19,
          "poolQNum": 241,
          "question": {
            "id": 19,
            "questionText": "A startup s photo-sharing site is deployed in a VPC. An ELB distributes web traffic across two subnets. ELB session stickiness is configured to use the AWS-generated session cookie, with a session TTL of 5 minutes. The webserver Auto Scaling Group is configured as: `min-size=4`, `max-size=4`, The startups preparing for a public launch, by running load-testing software installed on a single EC2 instance running in `us-west-2`. After 60 minutes of load-testing, the webserver logs show. Which recommendations can help ensure load-testing HTTP requests are evenly distributed across the four webservers? (Choose TWO)",
            "questionImage": "images/question241.jpg",
            "options": [
              {
                "text": "Launch and run the load-tester EC2 instance from `us-east-1` instead.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Re-configure the load-testing software to re-resolve DNS for each web request.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use a 3rd-party load-testing service which offers globally-distributed test clients.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure ELB and Auto Scaling to distribute across `us-west-2a` and `us-west-2c`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure ELB session stickiness to use the app-specific session cookie.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "3",
            "4"
          ],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 20,
          "poolQNum": 189,
          "question": {
            "id": 20,
            "questionText": "A Developer has built an application running on AWS Lambda using AWS Serverless Application Model (AWS SAM). What is the correct order of execution to successfully deploy the application?",
            "questionImage": null,
            "options": [
              {
                "text": "1. Build the SAM template in Amazon EC2. 2. Package the SAM template to Amazon EBS storage. 3. Deploy the SAM template from Amazon EBS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1. Build the SAM template locally. 2. Package the SAM template onto Amazon S3. 3. Deploy the SAM template from Amazon S3.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "1. Build the SAM template locally. 2. Deploy the SAM template from Amazon S3. 3. Package the SAM template for use.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1. Build the SAM template locally. 2. Package the SAM template from AWS CodeCommit. 3. Deploy the SAM template to CodeCommit.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 21,
          "poolQNum": 240,
          "question": {
            "id": 21,
            "questionText": "Which of the following statements about SWF are true? (Choose THREE)",
            "questionImage": null,
            "options": [
              {
                "text": "SWF tasks are assigned once and never duplicated.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SWF requires an S3 bucket for workflow storage.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SWF workflow executions can last up to a year.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SWF triggers SNS notifications on task assignment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SWF uses deciders and workers to complete tasks.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SWF requires at least 1 EC2 instance per domain.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2",
            "3",
            "5"
          ],
          "correctOptions": [
            "1",
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 22,
          "poolQNum": 286,
          "question": {
            "id": 22,
            "questionText": "A company needs to distribute firmware updates to its customers around the world. Which service will allow easy and secure control of the access to the downloads at the lowest cost?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon CloudFront with signed URLs for Amazon S3.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a dedicated Amazon CloudFront Distribution for each customer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudFront with AWS Lambda@Edge.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon API Gateway and AWS Lambda to control access to an S3 bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 23,
          "poolQNum": 48,
          "question": {
            "id": 23,
            "questionText": "The Lambda function below is being called through an API using Amazon API Gateway. The average execution time for the Lambda function is about 1 second. The pseudocode for the Lambda function is as shown in the exhibit. What two actions can be taken to improve the performance of this Lambda function without increasing the cost of the solution? (Select TWO)",
            "questionImage": "images/question48.jpg",
            "options": [
              {
                "text": "Package only the modules the Lambda function requires.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Amazon DynamoDB instead of Amazon RDS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Move the initialization of the variable Amazon RDS connection outside of the handler function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Implement custom database connection pooling with the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement local caching of Amazon RDS data so Lambda can re-use the cache.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "3",
            "5"
          ],
          "correctOptions": [
            "1",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 24,
          "poolQNum": 187,
          "question": {
            "id": 24,
            "questionText": "A Developer uses Amazon S3 buckets for static website hosting. The Developer creates one S3 bucket for the code and another S3 bucket for the assets, such as image and video files. Access is denied when a user attempts to access the assets bucket from the code bucket, with the website application showing a `403` error. How should the Developer solve this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM role and apply it to the assets bucket for the code bucket to be granted access.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Edit the bucket policy of the assets bucket to allow access from the code bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Edit the bucket policy of the assets bucket to open access to all principals.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the code bucket to use AWS Lambda functions instead of static website hosting.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 25,
          "poolQNum": 46,
          "question": {
            "id": 25,
            "questionText": "A Developer needs to design an application running on AWS that will be used to consume Amazon SQS messages that range from 1 KB up to 1GB in size. How should the Amazon SQS messages be managed?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon S3 and the Amazon SQS CLI.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon S3 and the Amazon SQS Extended Client Library for Java.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Amazon EBS and the Amazon SQS CLI.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon EFS and the Amazon SQS CLI.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 26,
          "poolQNum": 334,
          "question": {
            "id": 26,
            "questionText": "In a move toward using microservices, a company's Management team has asked all Development teams to build their services so that API requests depend only on that service's data store. One team is building a Payments service which has its own database; the service needs data that originates in the Accounts database. Both are using Amazon DynamoDB. What approach will result in the simplest, decoupled, and reliable method to get near-real time updates from the Accounts database?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon Glue to perform frequent ETL updates from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache in Payments, with the cache updated by triggers in the Accounts database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Kinesis Data Firehose to deliver all changes from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon DynamoDB Streams to deliver all changes from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 27,
          "poolQNum": 217,
          "question": {
            "id": 27,
            "questionText": "A Development team would like to migrate their existing application code from a GitHub repository to AWS CodeCommit. What needs to be created before they can migrate a cloned repository to CodeCommit over HTTPS?",
            "questionImage": null,
            "options": [
              {
                "text": "A GitHub secure authentication token.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A public and private SSH key file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A set of Git credentials generated from IAM.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An Amazon EC2 IAM role with CodeCommit permissions.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 28,
          "poolQNum": 86,
          "question": {
            "id": 28,
            "questionText": "A Developer is creating an Auto Scaling group whose instances need to publish a custom metric to Amazon CloudWatch. Which method would be the MOST secure way to authenticate a CloudWatch PUT request?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM user with `PutMetricData` permission and put the user credentials in a private repository; have applications pull the credentials as needed.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM user with `PutMetricData` permission, and modify the Auto Scaling launch configuration to inject the user credentials into the instance user data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the CloudWatch metric policies to allow the `PutMetricData` permission to instances from the Auto Scaling group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM role with `PutMetricData` permission and modify the Auto Scaling launching configuration to launch instances using that role.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 29,
          "poolQNum": 375,
          "question": {
            "id": 29,
            "questionText": "After installing the AWS CLI, a Developer tries to run the command `aws configure` but receives the following error: `Error: aws: command not found`. What is the most likely cause of this error?",
            "questionImage": null,
            "options": [
              {
                "text": "The `aws` executable is not in the `PATH` environment variable.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Access to the `aws` executable has been denied to the installer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Incorrect AWS credentials were provided.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The `aws` script does not have an executable file mode.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 30,
          "poolQNum": 204,
          "question": {
            "id": 30,
            "questionText": "A company's website runs on an Amazon EC2 instance and uses Auto Scaling to scale the environment during peak times. Website users across the world are experiencing high latency due to static content on the EC2 instance, even during non-peak hours. Which combination of steps will resolve the latency issue? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Double the Auto Scaling group's maximum number of servers.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Host the application code on AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Scale vertically by resizing the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon CloudFront distribution to cache the static content.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the application's static content in Amazon S3.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "4",
            "5"
          ],
          "correctOptions": [
            "4",
            "5"
          ],
          "isCorrect": true
        },
        {
          "qNum": 31,
          "poolQNum": 216,
          "question": {
            "id": 31,
            "questionText": "A Developer must encrypt a 100-GB object using AWS KMS. What is the BEST approach?",
            "questionImage": null,
            "options": [
              {
                "text": "Make an `Encrypt` API call to encrypt the plaintext data as ciphertext using a customer master key (CMK).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Make an `Encrypt` API call to encrypt the plaintext data as ciphertext using a customer master key (CMK) with imported key material.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Make an `GenerateDataKey` API call that returns a plaintext key and an encrypted copy of a data key. Use a plaintext key to encrypt the data.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Make an `GenerateDataKeyWithoutPlaintext` API call that returns an encrypted copy of a data key. Use an encrypted key to encrypt the data.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 32,
          "poolQNum": 18,
          "question": {
            "id": 32,
            "questionText": "A developer needs to modify an application architecture to meet new functional requirements. Application data is stored in Amazon DynamoDB and processed for analysis in a nightly batch. The system analysts do not want to wait unit the next day to view the processed data and have asked to have it available in near-real time. Which application architect pattern would enables the data to be processed as it is received?",
            "questionImage": null,
            "options": [
              {
                "text": "Event driven.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client served driven.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Fan-out driven.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Schedule driven.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 33,
          "poolQNum": 245,
          "question": {
            "id": 33,
            "questionText": "When a Simple Queue Service message triggers a task that takes 5 minutes to complete, which process below will result in successful processing of the message and remove it from the queue while minimizing the chances of duplicate processing?",
            "questionImage": null,
            "options": [
              {
                "text": "Retrieve the message with an increased visibility timeout, process the message, delete the message from the queue.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Retrieve the message with an increased visibility timeout, delete the message from the queue, process the message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Retrieve the message with increased `DelaySeconds`, process the message, delete the message from the queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Retrieve the message with increased `DelaySeconds`, delete the message from the queue, process the message.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 34,
          "poolQNum": 179,
          "question": {
            "id": 34,
            "questionText": "A Developer implemented a static website hosted in Amazon S3 that makes web service requests hosted in Amazon API Gateway and AWS Lambda. The site is showing an error that reads: `No Access-Control-Allow-Origin` header is present on the requested resource. Origin `null` is therefore not allowed access.' What should the Developer do to resolve this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable cross-origin resource sharing (CORS) on the S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable cross-origin resource sharing (CORS) for the method in API Gateway.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add the `Access-Control-Request-Method` header to the request.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add the `Access-Control-Request-Headers` header to the request.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 35,
          "poolQNum": 59,
          "question": {
            "id": 35,
            "questionText": "Given the source code for an AWS Lambda function in the local `store.py` containing a handler function called `get_store` and the following AWS CloudFormation template. What should be done to prepare the template so that it can be deployed using the AWS CLI command `aws cloudformation deploy`?",
            "questionImage": "images/question59.jpg",
            "options": [
              {
                "text": "Use AWS CloudFormation compile to base64 encode and embed the source file into a modified CloudFormation template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CloudFormation package to upload the source code to an Amazon S3 bucket and produce a modified CloudFormation template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS Lambda zip to package the source file together with the CloudFormation template and deploy the resulting zip archive.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Serverless `create-package` to embed the source file directly into the existing CloudFormation template.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 36,
          "poolQNum": 43,
          "question": {
            "id": 36,
            "questionText": "An Amazon RDS database instance is used by many applications to look up historical data. The query rate is relatively constant. When the historical data is updated each day, the resulting write traffic slows the read query performance and affects all application users. What can be done to eliminate the performance impact on application users?",
            "questionImage": null,
            "options": [
              {
                "text": "Make sure Amazon RDS is Multi-AZ so it can better absorb increased traffic.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an RDS Read Replica and direct all read traffic to the replica.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Implement Amazon ElastiCache in front of Amazon RDS to buffer the write traffic.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon DynamoDB instead of Amazon RDS to buffer the read traffic.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 37,
          "poolQNum": 236,
          "question": {
            "id": 37,
            "questionText": "In AWS, which security aspects are the customer's responsibility? (Choose FOUR)",
            "questionImage": null,
            "options": [
              {
                "text": "Life-cycle management of IAM credentials.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Decommissioning storage devices.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Security Group and ACL (Access Control List) settings.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Encryption of EBS (Elastic Block Storage) volumes.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Controlling physical access to compute resources.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Patch management on the EC2 instance's operating system.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "3",
            "4",
            "5"
          ],
          "correctOptions": [
            "1",
            "3",
            "4",
            "6"
          ],
          "isCorrect": false
        },
        {
          "qNum": 38,
          "poolQNum": 111,
          "question": {
            "id": 38,
            "questionText": "An application under development is required to store hundreds of video files. The data must be encrypted within the application prior to storage, with a unique key for each video file. How should the Developer code the application?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the `KMS Encrypt` API to encrypt the data. Store the encrypted data key and data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use a cryptography library to generate an encryption key for the application. Use the encryption key to encrypt the data. Store the encrypted data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `KMS GenerateDataKey` API to get a data key. Encrypt the data with the data key. Store the encrypted data key and data.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload the data to an S3 bucket using server side-encryption with an AWS KMS key.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 39,
          "poolQNum": 9,
          "question": {
            "id": 39,
            "questionText": "A company is building a compute-intensive application that will run on a fleet of Amazon EC2 instances. The application uses attached Amazon EBS disks for storing data. The application will process sensitive information and all the data must be encrypted. What should a developer do to ensure the data is encrypted on disk without impacting performance?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure the Amazon EC2 instance fleet to use encrypted EBS volumes for storing data.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add logic to write all data to an encrypted Amazon S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a custom encryption algorithm to the application that will encrypt and decrypt all data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a new Amazon Machine Image (AMI) with an encrypted root volume and store the data to ephemeral disks.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 40,
          "poolQNum": 107,
          "question": {
            "id": 40,
            "questionText": "An application has hundreds of users. Each user may use multiple devices to access the application. The Developer wants to assign unique identifiers to these users regardless of the device they use. Which of the following methods should be used to obtain unique identifiers?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a user table in Amazon DynamoDB as key-value pairs of users and their devices. Use these keys as unique identifiers.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use IAM-generated access key IDs for the users as the unique identifier, but do not store secret keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement developer-authenticated identities by using Amazon Cognito, and get credentials for these identities.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Assign IAM users and roles to the users. Use the unique IAM resource ID as the unique identifier.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 41,
          "poolQNum": 268,
          "question": {
            "id": 41,
            "questionText": "Company C is currently hosting their corporate site in an Amazon S3 bucket with Static Website Hosting enabled. Currently, when visitors go to `http://www.companyc.com` the `index.html` page is returned. Company C now would like a new page welcome.html to be returned when a visitor enters `http://www.companyc.com` in the browser. Which of the following steps will allow Company C to meet this requirement? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Upload an html page named welcome.html to their S3 bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a welcome subfolder in their S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set the Index Document property to welcome.html.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Move the `index.html` page to a welcome subfolder.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set the Error Document property to welcome.html.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "3"
          ],
          "correctOptions": [
            "1",
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 42,
          "poolQNum": 72,
          "question": {
            "id": 42,
            "questionText": "An application will ingest data at a very high throughput from many sources and must store the data in an Amazon S3 bucket. Which service would BEST accomplish this task?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon Kinesis Firehose.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3 Acceleration Transfer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SQS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SNS.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 43,
          "poolQNum": 301,
          "question": {
            "id": 43,
            "questionText": "A company maintains a REST service using Amazon API Gateway and the API Gateway native API key validation. The company recently launched a new registration page, which allows users to sign up for the service. The registration page creates a new API key using `CreateApiKey` and sends the new key to the user. When the user attempts to call the API using this key, the user receives a `403 Forbidden` error. Existing users are unaffected and can still call the API. What code updates will grant these new users access to the API?",
            "questionImage": null,
            "options": [
              {
                "text": "The `createDeployment` method must be called so the API can be redeployed to include the newly created API key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The `updateAuthorizer` method must be called to update the API's authorizer to include the newly created API key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The `importApiKeys` method must be called to import all newly created API keys into the current stage of the API.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The `createUsagePlanKey` method must be called to associate the newly created API key with the correct usage plan.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 44,
          "poolQNum": 331,
          "question": {
            "id": 44,
            "questionText": "A company needs to secure its existing website running behind an Elastic Load Balancer. The website's Amazon EC2 instances are CPU-constrained. What should be done to secure the website while not increasing the CPU load on the EC2 web servers? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Configure an Elastic Load Balancer with SSL pass-through.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure SSL certificates on an Elastic Load Balancer.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure an Elastic Load Balancer with a Loadable Storage System.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Install SSL certificates on the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure an Elastic Load Balancer with SSL termination.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "2",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 45,
          "poolQNum": 295,
          "question": {
            "id": 45,
            "questionText": "A Developer is investigating an issue whereby certain requests are passing through an Amazon API Gateway endpoint /MyAPI, but the requests do not reach the AWS Lambda function backing /MyAPI. The Developer found that a second Lambda function sometimes runs at maximum concurrency allowed for the given AWS account. How can the Developer address this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Manually reduce the concurrent execution limit at the account level.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add another API Gateway stage for /MyAPI, and shard the requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure the second Lambda function's concurrency execution limit.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Reduce the throttling limits in the API Gateway /MyAPI endpoint",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 46,
          "poolQNum": 103,
          "question": {
            "id": 46,
            "questionText": "An application stores images in an S3 bucket. Amazon S3 event notifications are used to trigger a Lambda function that resizes the images. Processing each image takes less than a second. How will AWS Lambda handle the additional traffic?",
            "questionImage": null,
            "options": [
              {
                "text": "Lambda will scale out to execute the requests concurrently.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Lambda will handle the requests sequentially in the order received.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Lambda will process multiple images in a single execution.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Lambda will add more compute to each execution to reduce processing time.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 47,
          "poolQNum": 112,
          "question": {
            "id": 47,
            "questionText": "A developer is testing an application that invokes an AWS Lambda function asynchronously. During the testing phase, the Lambda function fails to process after two retries. How can the developer troubleshoot the failure?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure AWS CloudTrail logging to investigate the invocation failures.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure Dead Letter Queues by sending events to Amazon SQS for investigatio.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure Amazon Simple Workflow Service to process any direct unprocessed events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure AWS Config to process any direct unprocessed events.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 48,
          "poolQNum": 118,
          "question": {
            "id": 48,
            "questionText": "A company has an application where reading objects from Amazon S3 is based on the type of user. The user types are registered user and guest user. The company has 25,000 users and is growing. Information is pulled from an S3 bucket depending on the user type. Which approaches are recommended to provide access to both user types? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Provide a different access key and secret access key in the application code for registered users and guest users to provide read access to the objects.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use S3 bucket policies to restrict read access to specific IAM users.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito to provide access using authenticated and unauthenticated roles.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a new IAM user for each user and grant read access.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS IAM service and let the application assume the different roles using the AWS Security Token Service (AWS STS) `AssumeRole` action depending on the type of user and provide read access to Amazon S3 using the assumed role.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "3",
            "5"
          ],
          "correctOptions": [
            "3",
            "5"
          ],
          "isCorrect": true
        },
        {
          "qNum": 49,
          "poolQNum": 104,
          "question": {
            "id": 49,
            "questionText": "A company is building a stock trading application that requires sub-millisecond latency in processing trading requests. Amazon DynamoDB is used to store all the trading data that is used to process each request. After load testing the application, the development team found that due to data retrieval times, the latency requirement is not satisfied. Because of sudden high spikes in the number of requests, DynamoDB read capacity has to be significantly over-provisioned to avoid throttling. What steps should be taken to meet latency requirements and reduce the cost of running the application?",
            "questionImage": null,
            "options": [
              {
                "text": "Add Global Secondary Indexes for trading data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store trading data in Amazon S3 and use Transfer Acceleration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add retries with exponential back-off for DynamoDB queries.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use DynamoDB Accelerator to cache trading data.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 50,
          "poolQNum": 219,
          "question": {
            "id": 50,
            "questionText": "After launching an instance that you intend to serve as a NAT (Network Address Translation) device in a public subnet you modify your route tables to have the NAT device be the target of internet bound traffic of your private subnet. When you try and make an outbound connection to the Internet from an instance in the private subnet, you are not successful. NAT device be the target of internet bound traffic of your private subnet. Which of the following steps could resolve the issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Attaching a second Elastic Network interface (ENI) to the NAT instance, and placing it in the private subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Attaching a second Elastic Network Interface (ENI) to the instance in the private subnet, and placing it in the public subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disabling the `Source/Destination Check` attribute on the NAT instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Attaching an Elastic IP address to the instance in the private subnet.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 51,
          "poolQNum": 83,
          "question": {
            "id": 51,
            "questionText": "A Lambda function is packaged for deployment to multiple environments, including development, test, production, etc. Each environment has unique set of resources such as databases, etc. How can the Lambda function use the resources for the current environment?",
            "questionImage": null,
            "options": [
              {
                "text": "Apply tags to the Lambda functions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Hardcore resources in the source code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use environment variables for the Lambda functions.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use separate function for development and production.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 52,
          "poolQNum": 222,
          "question": {
            "id": 52,
            "questionText": "Which of the following items are required to allow an application deployed on an EC2 instance to write data to a DynamoDB table? Assume that no security Keys are allowed to be stored on the EC2 instance. (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM User that allows write access to the DynamoDB table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an IAM Role to a running EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an IAM User to a running EC2 Instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Launch an EC2 Instance with the IAM Role included in the launch configuration.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an IAM Role that allows write access to the DynamoDB table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Launch an EC2 Instance with the IAM User included in the launch configuration.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "4",
            "5"
          ],
          "correctOptions": [
            "4",
            "5"
          ],
          "isCorrect": true
        },
        {
          "qNum": 53,
          "poolQNum": 320,
          "question": {
            "id": 53,
            "questionText": "A company is developing an application that will run on several Amazon EC2 instances in an Auto Scaling group and can access a database running on Amazon EC2. The application needs to store secrets required to connect to the database. The application must allow for periodic secret rotation, and there should be no changes to the application when a secret changes. What is the SAFEST way to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Associate an IAM role to the EC2 instance where the application is running with permission to access the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Systems Manager Parameter Store with the SecureString data type to store secrets.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure the application to store secrets in Amazon S3 object metadata.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Hard code the database secrets in the application code itself.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 54,
          "poolQNum": 205,
          "question": {
            "id": 54,
            "questionText": "A company is developing a web application that allows its employees to upload a profile picture to a private Amazon S3 bucket. There is no size limit for the profile pictures, which should be displayed every time an employee logs in. For security reasons, the pictures cannot be publicly accessible. What is a viable long-term solution for this scenario?",
            "questionImage": null,
            "options": [
              {
                "text": "Generate a presigned URL when a picture is uploaded. Save the URL in an Amazon DynamoDB table. Return the URL to the browser when the employee logs in.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Save the picture's S3 key in an Amazon DynamoDB table. Create an Amazon S3 VPC endpoint to allow the employees to download pictures once they log in.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Encode a picture using base64. Save the base64 string in an Amazon DB table. Allow the browser to retrieve the string and convert it to a picture.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Save the picture's S3 key in an Amazon DynamoDB table. Use a function to generate a presigned URL every time an employee logs in. Return the URL to the browser.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 55,
          "poolQNum": 373,
          "question": {
            "id": 55,
            "questionText": "An on-premises legacy application is caching data files locally and writing shared images to local disks. What is necessary to allow for horizontal scaling when migrating the application to AWS?",
            "questionImage": null,
            "options": [
              {
                "text": "Modify the application to have both shared images and caching data written to Amazon EBS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the application to read and write cache data on Amazon S3, and also store shared images on S3.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Modify the application to use Amazon S3 for serving shared images; cache data can then be written to local disks.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the application to read and write cache data on Amazon S3, while continuing to write shared images to local disks.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 56,
          "poolQNum": 190,
          "question": {
            "id": 56,
            "questionText": "A company wants to migrate an imaging service to Amazon EC2 while following security best practices. The images are sourced and read from a non-public Amazon S3 bucket. What should a Developer do to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM user with read-only permissions for the S3 bucket. Temporarily store the user credentials in the Amazon EBS volume of the EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM user with read-only permissions for the S3 bucket. Temporarily store the user credentials in the user data of the EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an EC2 service role with read-only permissions for the S3 bucket. Attach the role to the EC2 instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an S3 service role with read-only permissions for the S3 bucket. Attach the role to the EC2 instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 57,
          "poolQNum": 302,
          "question": {
            "id": 57,
            "questionText": "A Developer is writing a mobile application that allows users to view images from an S3 bucket. The users must be able to log in with their Amazon login, as well as Facebook and/or Google accounts. How can the Developer provide this authentication functionality?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon Cognito with web identity federation.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Amazon Cognito with SAML-based identity federation.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS IAM Access/Secret keys in the application code to allow `Get*` on the S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS STS `AssumeRole` in the application code and assume a role with `Get*` permissions on the S3 bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 58,
          "poolQNum": 349,
          "question": {
            "id": 58,
            "questionText": "A stock market monitoring application uses Amazon Kinesis for data ingestion. During simulated tests of peak data rates, the Kinesis stream cannot keep up with the incoming data. What step will allow Kinesis to accommodate the traffic during peak hours?",
            "questionImage": null,
            "options": [
              {
                "text": "Install the Kinesis Producer Library (KPL) for ingesting data into the stream.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Reduce the data retention period to allow for more data ingestion using `DecreaseStreamRetentionPeriod`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the shard count of the stream using `UpdateShardCount`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Ingest multiple records into the stream in a single call using `PutRecords`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 59,
          "poolQNum": 92,
          "question": {
            "id": 59,
            "questionText": "An application takes 40 seconds to process instructions received in an Amazon SQS message. Assuming the SQS queue is configured with the default `VisibilityTimeout` value, what is the BEST way, upon receiving a message, to ensure that no other instances can retrieve a message that has already been processed or is currently being processed?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the `ChangeMessageVisibility` API to increase the `VisibilityTimeout`, then use the `DeleteMessage` API to delete the message.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use the `DeleteMessage` API call to delete the message from the queue, then call `DeleteQueue` API to remove the queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `ChangeMessageVisibility` API to decrease the timeout value, then use the `DeleteMessage` API to delete the message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `DeleteMessageVisibility` API to cancel the `VisibilityTimeout`, then use the `DeleteMessage` API to delete the message.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 60,
          "poolQNum": 339,
          "question": {
            "id": 60,
            "questionText": "An application running on Amazon EC2 instances must access objects within an Amaon S3 busket that are encrypted using server-side encryption using AWS KMS encryption keys (SSE-KMS). The application must have access to the customer master key (CMK) to decrypt the objects. Which combination of steps will grant the application access? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Write an S3 bucket policy that grants the bucket access to the key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Grant access to the key in the IAM EC2 role attached to the application's EC2 instances.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Write a key policy that enables IAM policies to grant access to the key.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Grant access to the key in the S3 bucket's ACL.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a Systems Manager parameter that exposes the KMS key to the EC2 instances.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2",
            "3"
          ],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 61,
          "poolQNum": 168,
          "question": {
            "id": 61,
            "questionText": "A company provides APIs as a service and commits to a service level agreement (SLA) with all its users. To comply with each SLA, what should the company do?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable throttling limits for each method in Amazon API Gateway.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a usage plan for each user and request API keys to access the APIs.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Enable API rate limiting in Amazon Cognito for each user.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable default throttling limits for each stage after deploying the APIs.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 62,
          "poolQNum": 55,
          "question": {
            "id": 62,
            "questionText": "A company wants to migrate its web application to AWS and leverage Auto Scaling to handle peak workloads. The Solutions Architect determined that the best metric for an Auto Scaling event is the number of concurrent users. Based on this information, what should the Developer use to autoscale based on concurrent users?",
            "questionImage": null,
            "options": [
              {
                "text": "An Amazon SNS topic to be triggered when a concurrent user threshold is met.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An Amazon Cloudwatch NetworkIn metric.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon CloudFront to leverage AWS Edge Locations.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A Custom Amazon CloudWatch metric for concurrent users.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 63,
          "poolQNum": 363,
          "question": {
            "id": 63,
            "questionText": "An application runs on multiple EC2 instances behind an ELB. Where is the session data best written so that it can be served reliably across multiple requests?",
            "questionImage": null,
            "options": [
              {
                "text": "Write data to Amazon ElastiCache.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Write data to Amazon Elastic Block Store.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write data to Amazon EC2 Instance Store.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write data to the `root` filesystem.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 64,
          "poolQNum": 383,
          "question": {
            "id": 64,
            "questionText": "A company developed a set of APIs that are being served through the Amazon API Gateway. The API calls need to be authenticated based on OpenID identity providers such as Amazon or Facebook. The APIs should allow access based on a custom authorization model. Which is the simplest and MOST secure design to use to build an authentication and authorization model for the APIs?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon Cognito user pools and a custom authorizer to authenticate and authorize users based on JSON Web Tokens.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Build a OpenID token broker with Amazon and Facebook. Users will authenticate with these identify providers and pass the JSON Web Token to the API to authenticate each API call.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store user credentials in Amazon DynamoDB and have the application retrieve temporary credentials from AWS STS. Make API calls by passing user credentials to the APIs for authentication and authorization.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon RDS to store user credentials and pass them to the APIs for authentications and authorization.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 65,
          "poolQNum": 399,
          "question": {
            "id": 65,
            "questionText": "A company is running a custom application on a set of on-premises Linux servers that are accessed using Amazon API Gateway. AWS X-Ray tracing has been enabled on the API test stage. How can a developer enable X-Ray tracing on the on-premises servers with the LEAST amount of configuration?",
            "questionImage": null,
            "options": [
              {
                "text": "Install and run the X-Ray SDK on the on-premises servers to capture and relay the data to the X-Ray service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Install and run the X-Ray daemon on the on-premises servers to capture and relay the data to the X-Ray service.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Capture incoming requests on-premises and configure an AWS Lambda function to pull, process, and relay relevant data to X-Ray using the PutTraceSegments API call.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Capture incoming requests on-premises and configure an AWS Lambda function to pull, process, and relay relevant data to X-Ray using the PutTelemetryRecords API call.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        }
      ],
      "questionMap": {
        "1": 119,
        "2": 243,
        "3": 377,
        "4": 62,
        "5": 274,
        "6": 306,
        "7": 365,
        "8": 310,
        "9": 266,
        "10": 293,
        "11": 2,
        "12": 328,
        "13": 292,
        "14": 151,
        "15": 194,
        "16": 390,
        "17": 35,
        "18": 324,
        "19": 241,
        "20": 189,
        "21": 240,
        "22": 286,
        "23": 48,
        "24": 187,
        "25": 46,
        "26": 334,
        "27": 217,
        "28": 86,
        "29": 375,
        "30": 204,
        "31": 216,
        "32": 18,
        "33": 245,
        "34": 179,
        "35": 59,
        "36": 43,
        "37": 236,
        "38": 111,
        "39": 9,
        "40": 107,
        "41": 268,
        "42": 72,
        "43": 301,
        "44": 331,
        "45": 295,
        "46": 103,
        "47": 112,
        "48": 118,
        "49": 104,
        "50": 219,
        "51": 83,
        "52": 222,
        "53": 320,
        "54": 205,
        "55": 373,
        "56": 190,
        "57": 302,
        "58": 349,
        "59": 92,
        "60": 339,
        "61": 168,
        "62": 55,
        "63": 363,
        "64": 383,
        "65": 399
      }
    },
    {
      "id": "1764749794913",
      "timestamp": 1764749794913,
      "score": "83.08",
      "results": [
        {
          "qNum": 1,
          "poolQNum": 211,
          "question": {
            "id": 1,
            "questionText": "A Developer is trying to make API calls using SDK. The IAM user credentials used by the application require multi-factor authentication for all API calls. Which method the Developer use to access the multi-factor authentication protected API?",
            "questionImage": null,
            "options": [
              {
                "text": "GetFederationToken.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "GetCallerIdentity.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "GetSessionToken.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "DecodeAutherizationMessage.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 2,
          "poolQNum": 36,
          "question": {
            "id": 2,
            "questionText": "A supplier is writing a new RESTful API for customers to query the status of orders. The customers requested the following API endpoint `http://www.supplierdomain.com/status/customerID`. Which of the following application designs meet the requirements? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon SQS; Amazon SNS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Elastic Load Balancing; Amazon EC2.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon ElastiCache; Amazon Elacticsearch Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon API Gateway; AWS Lambda.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3; Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2",
            "4"
          ],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 3,
          "poolQNum": 68,
          "question": {
            "id": 3,
            "questionText": "A mobile app stores blog posts in an Amazon DynamoDB table. Millions of posts are added every day, and each post represents a single item in the table. The mobile app requires only recent posts. Any post that is older than 48 hours can be removed. What is the MOST cost-effective way to delete posts that are older than 48 hours?",
            "questionImage": null,
            "options": [
              {
                "text": "For each item, add a new attribute of type `String` that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the `BatchWriteItem` API operation. Schedule a cron job on an Amazon EC2 instance once an hour to start the script.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "For each item, add a new attribute of type `String` that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the `BatchWriteItem` API operation. Place the script in a container image. Schedule an Amazon Elastic Container Service (Amazon ECS) task on AWS Fargate that invokes the container every 5 minutes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "For each item, add a new attribute of type `Date` that has a timestamp that is set to 48 hours after the blog post creation time. Create a Global Secondary Index (GSI) that uses the new attribute as a sort key. Create an AWS Lambda function that references the GSI and removes expired items by using the `BatchWriteItem` API operation. Schedule the function with an Amazon CloudWatch event every minute.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "For each item, add a new attribute of type `Number` that has a timestamp that is set to 48 hours after the blog post creation time. Configure the DynamoDB table with a TTL that references the new attribute.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 4,
          "poolQNum": 19,
          "question": {
            "id": 4,
            "questionText": "A developer has built an application that inserts data into an Amazon DynamoDB table. The table is configured to use provisioned capacity. The application is deployed on a burstable nano Amazon EC2 Instance. The application logs show that the application has been failing because of a `ProvisionedThroughputExceedException` error. Which actions should the developer take to resolve this issue? (Choose two.)",
            "questionImage": null,
            "options": [
              {
                "text": "Move the application to a larger EC instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the number or read capacity units (RCUs) that are provisioned for the DynamoDB table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Reduce the frequency of requests to DynamoDB by implement ng exponential backoff.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Increase the frequency of requests to DynamoDB by decreasing the retry delay.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the capacity mode of the DynamoDB table from provisioned to on-demand.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "5"
          ],
          "correctOptions": [
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 5,
          "poolQNum": 350,
          "question": {
            "id": 5,
            "questionText": "A company has an AWS CloudFormation template that is stored as a single file. The template is able to launch and create a full infrastructure stack. Which best practice would increase the maintainability of the template?",
            "questionImage": null,
            "options": [
              {
                "text": "Use nested stacks for common template patterns.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Embed credentials to prevent typos.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Remove mappings to decrease the number of variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use `AWS::Include` to reference publicly-hosted template files.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 6,
          "poolQNum": 188,
          "question": {
            "id": 6,
            "questionText": "A company has implemented AWS CodePipeline to automate its release pipelines. The Development team is writing an AWS Lambda function what will send notifications for state changes of each of the actions in the stages. Which steps must be taken to associate the Lambda function with the event source?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a trigger that invokes the Lambda function from the Lambda console by selecting CodePipeline as the event source.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an event trigger and specify the Lambda function from the CodePipeline console.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an Amazon CloudWatch alarm that monitors status changes in Code Pipeline and triggers the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon CloudWatch Events rule that uses CodePipeline as an event source.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 7,
          "poolQNum": 341,
          "question": {
            "id": 7,
            "questionText": "A company has multiple Developers located across the globe who are updating code incrementally for a development project. When Developers upload code concurrently, internet connectivity is slow and it is taking a long time to upload code for deployment in AWS Elastic Beanstalk. Which step will result in minimized upload and deployment time with the LEAST amount of administrative effort?",
            "questionImage": null,
            "options": [
              {
                "text": "Allow the Developers to upload the code to an Amazon S3 bucket, and deploy it directly to Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Allow the Developers to upload the code to a central FTP server to deploy the application to Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an AWS CodeCommit repository, allow the Developers to commit code to it, and then directly deploy the code to Elastic Beanstalk.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a code repository on an Amazon EC2 instance so that all Developers can update the code, and deploy the application from the instance to Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 8,
          "poolQNum": 291,
          "question": {
            "id": 8,
            "questionText": "A Developer must analyze performance issues with production-distributed applications written as AWS Lambda functions. These distributed Lambda applications invoke other components that make up the applications. How should the Developer identify and troubleshoot the root cause of the performance issues in production?",
            "questionImage": null,
            "options": [
              {
                "text": "Add logging statements to the Lambda functions, then use Amazon CloudWatch to view the logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Cloud Trail and then examine the logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS X-Ray, then examine the segments and errors.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Run Amazon Inspector agents and then analyze performance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 9,
          "poolQNum": 186,
          "question": {
            "id": 9,
            "questionText": "A company has implemented AWS CodeDeploy as part of its cloud native CI/CD stack. The company enables automatic rollbacks while deploying a new version of a popular web application from in-place to Amazon EC2. What occurs if the deployment of the new version fails due to code regression?",
            "questionImage": null,
            "options": [
              {
                "text": "The last known good deployment is automatically restored using the snapshot stored in Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "CodeDeploy switches the Amazon Route 53 alias records back to the known good green deployment and terminates the failed blue deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A new deployment of the last known version of the application is deployed with a new deployment ID.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS CodePipeline promotes the most recent deployment with a SUCCEEDED status to production.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 10,
          "poolQNum": 277,
          "question": {
            "id": 10,
            "questionText": "A company runs an e-commerce website that uses Amazon DynamoDB where pricing for items is dynamically updated in real time. At any given time, multiple updates may occur simultaneously for pricing information on a particular product. This is causing the original editor's changes to be overwritten without a proper review process. Which DynamoDB write option should be selected to prevent this overwriting?",
            "questionImage": null,
            "options": [
              {
                "text": "Concurrent writes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Conditional writes.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Atomic writes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Batch writes.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 11,
          "poolQNum": 387,
          "question": {
            "id": 11,
            "questionText": "Amazon S3 has the following structure: `S3://BUCKET/FOLDERNAME/FILENAME.zip`. Which S3 best practice would optimize performance with thousands of PUT request each second to a single bucket?",
            "questionImage": null,
            "options": [
              {
                "text": "Prefix folder names with user id; for example, `s3://BUCKET/2013-FOLDERNAME/FILENAME.zip`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Prefix file names with timestamps; for example, `s3://BUCKET/FOLDERNAME/2013-26-05-15-00-00-FILENAME.zip`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Prefix file names with random hex hashes; for example, `s3://BUCKET/FOLDERNAME/23a6-FILENAME.zip`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Prefix folder names with random hex hashes; for example, `s3://BUCKET/23a6-FOLDERNAME/FILENAME.zip`.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 12,
          "poolQNum": 339,
          "question": {
            "id": 12,
            "questionText": "An application running on Amazon EC2 instances must access objects within an Amaon S3 busket that are encrypted using server-side encryption using AWS KMS encryption keys (SSE-KMS). The application must have access to the customer master key (CMK) to decrypt the objects. Which combination of steps will grant the application access? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Write an S3 bucket policy that grants the bucket access to the key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Grant access to the key in the IAM EC2 role attached to the application's EC2 instances.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Write a key policy that enables IAM policies to grant access to the key.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Grant access to the key in the S3 bucket's ACL.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a Systems Manager parameter that exposes the KMS key to the EC2 instances.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2",
            "3"
          ],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 13,
          "poolQNum": 274,
          "question": {
            "id": 13,
            "questionText": "A Developer created a new AWS account and must create a scalable AWS Lambda function that meets the following requirements for concurrent execution: Average execution time of 100 seconds 50 requests per second. Which step must be taken prior to deployment to prevent errors?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement dead-letter queues to capture invocation errors.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an event source from Amazon API Gateway to the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement error handling within the application code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Contact AWS Support to increase the concurrent execution limits.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 14,
          "poolQNum": 7,
          "question": {
            "id": 14,
            "questionText": "An application is being developed to audit several AWS accounts. The application will run in Account A and must access AWS services in Accounts B and C. What is the MOST secure way to allow the application to call AWS services in each audited account?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure cross-account roles in each audited account. Write code in Account A that assumes those roles.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use S3 cross-region replication to communicate among accounts, with Amazon S3 event notifications to trigger Lambda functions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy an application in each audited account with its own role. Have Account A authenticate with the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM user with an access key in each audited account. Write code in Account A that uses those access keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 15,
          "poolQNum": 53,
          "question": {
            "id": 15,
            "questionText": "A web application is using Amazon Kinesis Streams for clickstream data that may not be consumed for up to 12 hours. How can the Developer implement encryption at rest for data within the Kinesis Streams?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable SSL connections to Kinesis.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Kinesis Consumer Library.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Encrypt the data once it is at rest with a Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable server-side encryption in Kinesis Streams.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 16,
          "poolQNum": 322,
          "question": {
            "id": 16,
            "questionText": "An AWS Lambda function must read data from an Amazon RDS MySQL database in a VPC and also reach a public endpoint over the internet to get additional data. Which steps must be taken to allow the function to access both the RDS resource and the public endpoint? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Modify the default configuration for the Lambda function to associate it with an Amazon VPC private subnet.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Modify the default network access control list to allow outbound traffic.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a NAT Gateway to the VPC.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Modify the default configuration of the Lambda function to associate it with a VPC public subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an environmental variable to the Lambda function to allow outbound internet access.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "3"
          ],
          "correctOptions": [
            "1",
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 17,
          "poolQNum": 54,
          "question": {
            "id": 17,
            "questionText": "A Developer is creating a mobile application with a limited budget. The solution requires a scalable service that will enable customers to sign up and authenticate into the mobile application while using the organization's current SAML 2.0 identity provider. Which AWS service should be used to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS IAM.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon EC2.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 18,
          "poolQNum": 320,
          "question": {
            "id": 18,
            "questionText": "A company is developing an application that will run on several Amazon EC2 instances in an Auto Scaling group and can access a database running on Amazon EC2. The application needs to store secrets required to connect to the database. The application must allow for periodic secret rotation, and there should be no changes to the application when a secret changes. What is the SAFEST way to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Associate an IAM role to the EC2 instance where the application is running with permission to access the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Systems Manager Parameter Store with the SecureString data type to store secrets.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure the application to store secrets in Amazon S3 object metadata.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Hard code the database secrets in the application code itself.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 19,
          "poolQNum": 93,
          "question": {
            "id": 19,
            "questionText": "A Developer is developing an application that manages financial transactions. To improve security, multi-factor authentication (MFA) will be required as part of the login protocol. What services can the Developer use to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon DynamoDB to store MFA session data, and Amazon SNS to send MFA codes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito with MFA.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Directory Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS IAM with MFA enabled.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 20,
          "poolQNum": 75,
          "question": {
            "id": 20,
            "questionText": "A large e-commerce site is being designed to deliver static objects from Amazon S3. The Amazon S3 bucket will server more than 300 GET requests per second. What should be done to optimize performance? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Integrate Amazon CloudFront with Amazon S3.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Enable Amazon S3 cross-region replication.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Delete expired Amazon S3 server log files.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure Amazon S3 lifecycle rules.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Randomize Amazon S3 key name prefixes.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "5"
          ],
          "correctOptions": [
            "1",
            "5"
          ],
          "isCorrect": true
        },
        {
          "qNum": 21,
          "poolQNum": 367,
          "question": {
            "id": 21,
            "questionText": "An application needs to use the IP address of the client in its processing. The application has been moved into AWS and has been placed behind an Application Load Balancer (ALB). However, all the client IP addresses now appear to be the same. The application must maintain the ability to scale horizontally. Based on this scenario, what is the MOST cost-effective solution to this problem?",
            "questionImage": null,
            "options": [
              {
                "text": "Remove the application from the ALB. Delete the ALB and change Amazon Route 53 to direct traffic to the instance running the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Remove the application from the ALB. Create a Classic Load Balancer in its place. Direct traffic to the application using the HTTP protocol.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Alter the application code to inspect the `X-Forwarded-For` header. Ensure that the code can work properly if a list of IP addresses is passed in the header.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Alter the application code to inspect a custom header. Alter the client code to pass the IP address in the custom header.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 22,
          "poolQNum": 142,
          "question": {
            "id": 22,
            "questionText": "A developer is provided with an HTTPS clone URL for an AWS CodeCommit repository. What needs to be configured before cloning this repository?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS KMS to set up public and private keys for use with AWS CodeCommit.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set up the Git credential helper to use an AWS credential profile, and enable the helper to send the path to the repositories.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS Certificate Manager to provision public and private SSL/TLS certificates.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Generate encryption keys using AWS CloudHSM, then export the key for use with AWS CodeCommit.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 23,
          "poolQNum": 45,
          "question": {
            "id": 23,
            "questionText": "An application is running on an EC2 instance. The Developer wants to store an application metric in Amazon CloudWatch. What is the best practice for implementing this requirement?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the PUT Object API call to send data to an S3 bucket. Use an event notification to invoke a Lambda function to publish data to CloudWatch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Publish the metric data to an Amazon Kinesis Stream using a `PutRecord` API call. Subscribe a Lambda function that publishes data to CloudWatch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the CloudWatch `PutMetricData` API call to submit a custom metric to CloudWatch. Provide the required credentials to enable the API call.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the CloudWatch `PutMetricData` API call to submit a custom metric to CloudWatch. Launch the EC2 instance with the required IAM role to enable the API call.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 24,
          "poolQNum": 338,
          "question": {
            "id": 24,
            "questionText": "A Developer is creating a mobile application that will not require users to log in. What is the MOST efficient method to grant users access to AWS resources?",
            "questionImage": null,
            "options": [
              {
                "text": "Use an identity provider to securely authenticate with the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an AWS Lambda function to create an IAM user when a user accesses the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create credentials using AWS KMS and apply these credentials to users when using the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito to associate unauthenticated users with an IAM role that has limited access to resources.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 25,
          "poolQNum": 103,
          "question": {
            "id": 25,
            "questionText": "An application stores images in an S3 bucket. Amazon S3 event notifications are used to trigger a Lambda function that resizes the images. Processing each image takes less than a second. How will AWS Lambda handle the additional traffic?",
            "questionImage": null,
            "options": [
              {
                "text": "Lambda will scale out to execute the requests concurrently.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Lambda will handle the requests sequentially in the order received.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Lambda will process multiple images in a single execution.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Lambda will add more compute to each execution to reduce processing time.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 26,
          "poolQNum": 327,
          "question": {
            "id": 26,
            "questionText": "A Developer wants to find a list of items in a global secondary index from an Amazon DynamoDB table. Which DynamoDB API call can the Developer use in order to consume the LEAST number of read capacity units?",
            "questionImage": null,
            "options": [
              {
                "text": "Scan operation using `eventually-consistent` reads.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Query operation using `strongly-consistent` reads.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Query operation using `eventually-consistent` reads.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Scan operation using `strongly-consistent` reads.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 27,
          "poolQNum": 132,
          "question": {
            "id": 27,
            "questionText": "A developer is using Amazon DynamoDB to store application data. The developer wants to further improve application performance by reducing response times for read and write operations. Which DynamoDB feature should be used to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon DynamoDB Streams.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon DynamoDB Accelerator.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon DynamoDB global tables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon DynamoDB transactions.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 28,
          "poolQNum": 176,
          "question": {
            "id": 28,
            "questionText": "A company is launching an ecommerce website and will host the static data in Amazon S3. The company expects approximately 1,000 transactions per second (TPS) for GET and PUT requests in total. Logging must be enabled to track all requests and must be retained for auditing purposes. What is the MOST cost-effective solution?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable AWS CloudTrail logging for the S3 bucket-level action and create a lifecycle policy to move the data from the log bucket to Amazon S3 Glacier in 90 days.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable S3 server access logging and create a lifecycle policy to expire the data in 90 days.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable AWS CloudTrail logging for the S3 bucket-level action and create a lifecycle policy to expire the data in 90 days.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable S3 server access logging and create a lifecycle policy to move the data to Amazon S3 Glacier in 90 days.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 29,
          "poolQNum": 149,
          "question": {
            "id": 29,
            "questionText": "A company's fleet of Amazon EC2 instances receives data from millions of users through an API. The servers batch the data, add an object for each user, and upload the objects to an S3 bucket to ensure high access rates. The object attributes are `Customer ID`, `Server ID`, `TS-Server` (`TimeStamp` and `Server ID`), the size of the object, and a timestamp. A Developer wants to find all the objects for a given user collected during a specified time range. After creating an S3 object created event, how can the Developer achieve this requirement?",
            "questionImage": null,
            "options": [
              {
                "text": "Execute an AWS Lambda function in response to the S3 object creation events that creates an Amazon DynamoDB record for every object with the `Customer ID` as the partition key and the `Server ID` as the sort key. Retrieve all the records using the `Customer ID` and `Server ID` attributes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Execute an AWS Lambda function in response to the S3 object creation events that creates an Amazon Redshift record for every object with the `Customer ID` as the partition key and `TS-Server` as the sort key. Retrieve all the records using the `Customer ID` and `TS-Server` attributes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Execute an AWS Lambda function in response to the S3 object creation events that creates an Amazon DynamoDB record for every object with the `Customer ID` as the partition key and `TS-Server` as the sort key. Retrieve all the records using the `Customer ID` and `TS-Server` attributes.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Execute an AWS Lambda function in response to the S3 object creation events that creates an Amazon Redshift record for every object with the `Customer ID` as the partition key and the `Server ID` as the sort key. Retrieve all the records using the `Customer ID` and `Server ID` attributes.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 30,
          "poolQNum": 324,
          "question": {
            "id": 30,
            "questionText": "A Developer wants to enable AWS X-Ray for a secure application that runs in an Amazon ECS environment. What combination of steps will enable X-Ray? (Select THREE)",
            "questionImage": null,
            "options": [
              {
                "text": "Create a Docker image that runs the X-Ray daemon.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add instrumentation to the application code for X-Ray.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install the X-Ray daemon on the underlying EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure and use an IAM EC2 instance role.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Register the application with X-Ray.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure and use an IAM role for tasks.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1",
            "2",
            "6"
          ],
          "correctOptions": [
            "1",
            "2",
            "6"
          ],
          "isCorrect": true
        },
        {
          "qNum": 31,
          "poolQNum": 83,
          "question": {
            "id": 31,
            "questionText": "A Lambda function is packaged for deployment to multiple environments, including development, test, production, etc. Each environment has unique set of resources such as databases, etc. How can the Lambda function use the resources for the current environment?",
            "questionImage": null,
            "options": [
              {
                "text": "Apply tags to the Lambda functions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Hardcore resources in the source code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use environment variables for the Lambda functions.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use separate function for development and production.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 32,
          "poolQNum": 285,
          "question": {
            "id": 32,
            "questionText": "A Developer is building a web application that uses Amazon API Gateway to expose an AWS Lambda function to process requests from clients. During testing, the Developer notices that the API Gateway times out even though the Lambda function finishes under the set time limit. Which of the following API Gateway metrics in Amazon CloudWatch can help the Developer troubleshoot the issue? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "CacheHitCount.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "IntegrationLatency.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "CacheMissCount.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Latency.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Count.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2",
            "3"
          ],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 33,
          "poolQNum": 43,
          "question": {
            "id": 33,
            "questionText": "An Amazon RDS database instance is used by many applications to look up historical data. The query rate is relatively constant. When the historical data is updated each day, the resulting write traffic slows the read query performance and affects all application users. What can be done to eliminate the performance impact on application users?",
            "questionImage": null,
            "options": [
              {
                "text": "Make sure Amazon RDS is Multi-AZ so it can better absorb increased traffic.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an RDS Read Replica and direct all read traffic to the replica.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Implement Amazon ElastiCache in front of Amazon RDS to buffer the write traffic.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon DynamoDB instead of Amazon RDS to buffer the read traffic.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 34,
          "poolQNum": 139,
          "question": {
            "id": 34,
            "questionText": "An IAM role is attached to an Amazon EC2 instance that explicitly denies access to all Amazon S3 API actions. The EC2 instance credentials file specifies the IAM access key and secret access key, which allow full administrative access. Given that multiple modes of IAM access are present for this EC2 instance, which of the following is correct?",
            "questionImage": null,
            "options": [
              {
                "text": "The EC2 instance will only be able to list the S3 buckets.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The EC2 instance will only be able to list the contents of one S3 bucket at a time.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The EC2 instance will be able to perform all actions on any S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The EC2 instance will not be able to perform any S3 action on any S3 bucket.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 35,
          "poolQNum": 17,
          "question": {
            "id": 35,
            "questionText": "A company is migrating its on-premises database to Amazon RDS for MySQL. The company has read-heavy workloads, and wants to make sure it re-factors its code to achieve optimum read performance for its queries. How can this objective be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Add database retries to effectively use RDS with vertical scaling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use RDS with multi-AZ deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a connection string to use an RDS read replica for read queries.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add a connection string to use a read replica on an EC2 instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 36,
          "poolQNum": 244,
          "question": {
            "id": 36,
            "questionText": "Which DynamoDB limits can be raised by contacting AWS support? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "The number of hash keys per account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The maximum storage used per account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The number of tables per account.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The number of local secondary indexes per account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The number of provisioned throughput units per account.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "3",
            "5"
          ],
          "correctOptions": [
            "3",
            "5"
          ],
          "isCorrect": true
        },
        {
          "qNum": 37,
          "poolQNum": 384,
          "question": {
            "id": 37,
            "questionText": "Where should an Elastic Beanstalk configuration file named `healthcheckur1.config` be placed in the application source bundle?",
            "questionImage": null,
            "options": [
              {
                "text": "In the `root` of the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the `bin` folder.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In `healthcheckur1.config.ebextension` under `root`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the `.ebextensions` folder.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 38,
          "poolQNum": 87,
          "question": {
            "id": 38,
            "questionText": "A Developer is working on an application that tracks hundreds of millions of product reviews in an Amazon DynamoDB table. The records include the data elements shown in the table. Which field, when used as the partition key, would result in the MOST consistent performance using DynamoDB?",
            "questionImage": "images/question87.jpg",
            "options": [
              {
                "text": "`starRating`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`reviewID`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`comment`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`productID`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 39,
          "poolQNum": 273,
          "question": {
            "id": 39,
            "questionText": "A company is using continuous integration and continuous delivery systems. A Developer now needs to automate a software package deployment to both Amazon EC2 instances and virtual servers running on-premises. Which AWS service should be used to accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS CodePipeline.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeBuild.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeDeploy.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 40,
          "poolQNum": 11,
          "question": {
            "id": 40,
            "questionText": "An AWS Lambda function generates a 3MB JSON file and then uploads it to an Amazon S3 bucket daily. The file contains sensitive information, so the Developer must ensure that it is encrypted before uploading to the bucket. Which of the following modifications should the Developer make to ensure that the data is encrypted before uploading it to the bucket?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the default AWS KMS customer master key for S3 in the Lambda function code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the S3 managed key and call the `GenerateDataKey` API to encrypt the file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `GenerateDataKey` API, then use that data key to encrypt the file in the Lambda function code.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use a custom KMS customer master key created for S3 in the Lambda function code.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 41,
          "poolQNum": 366,
          "question": {
            "id": 41,
            "questionText": "An application running on an Amazon Linux EC2 instance needs to manage the AWS infrastructure. How can the EC2 instance be configured to make AWS API calls securely?",
            "questionImage": null,
            "options": [
              {
                "text": "Sign the AWS CLI command using the signature version 4 process.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Run the `aws configure` AWS CLI command and specify the access key id and secret access key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Specify a role for the EC2 instance with the necessary privileges.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Pass the access key id and secret access key as parameters for each AWS CLI command.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 42,
          "poolQNum": 397,
          "question": {
            "id": 42,
            "questionText": "A developer is creating an AWS CloudFormation template to deploy Amazon EC2 instances across multiple AWS accounts. The developer must choose the EC2 instances from a list of approved instance types. How can the developer incorporate the list of approved instance types in the CloudFormation template?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a separate CloudFormation template for each EC2 instance type in the list.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the Resources section of the CloudFormation template, create resources for each EC2 instance type in the list.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the CloudFormation template, create a separate parameter for each EC2 instance type in the list.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the CloudFormation template, create a parameter with the list of EC2 instance types as AllowedValues.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 43,
          "poolQNum": 13,
          "question": {
            "id": 43,
            "questionText": "A developer must extend an existing application that is based on the AWS Serverless Application Model (AWS SAM). The developer has used the AWS SAM CLI to create the project. The project contains different AWS Lambda functions. Which combination of commands must the developer use to redeploy the AWS SAM application? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "`sam init`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`sam validate`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`sam build`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`sam deploy`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`sam publish`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "3",
            "4"
          ],
          "correctOptions": [
            "3",
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 44,
          "poolQNum": 174,
          "question": {
            "id": 44,
            "questionText": "A Developer is building a serverless application using AWS Lambda and must create a REST API using an HTTP GET method. What needs to be defined to meet this requirement? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "A Lambda@Edge function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An Amazon API Gateway with a Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An exposed GET method in an Amazon API Gateway.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An exposed GET method in the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An exposed GET method in Amazon Route 53.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2",
            "3"
          ],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 45,
          "poolQNum": 266,
          "question": {
            "id": 45,
            "questionText": "Which of the following statements about SQS is true?",
            "questionImage": null,
            "options": [
              {
                "text": "Messages will be delivered exactly once and messages will be delivered in First in, First out order.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered exactly once and message delivery order is indeterminate.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered one or more times and messages will be delivered in First in, First out order.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered one or more times and message delivery order is indeterminate.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 46,
          "poolQNum": 122,
          "question": {
            "id": 46,
            "questionText": "A development team is working on a mobile app that allows users to upload pictures to Amazon S3. The team expects the app will be used by hundreds of thousands of users during a single event simultaneously. Once the pictures are uploaded, the backend service will scan and parse the pictures for inappropriate content. Which approach is the MOST resilient way to achieve this goal, which also smooths out temporary volume spikes for the backend service?",
            "questionImage": null,
            "options": [
              {
                "text": "Develop an AWS Lambda function to check the upload folder in the S3 bucket. If new uploaded pictures are detected, the Lambda function will scan and parse them.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Once a picture is uploaded to Amazon S3, publish the event to an Amazon SQS queue. Use the queue as an event source to trigger an AWS Lambda function. In the Lambda function, scan and parse the picture.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "When the user uploads a picture, invoke an API hosted in Amazon API Gateway. The API will invoke an AWS Lambda function to scan and parse the picture.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a state machine in AWS Step Functions to check the upload folder in the S3 bucket. If a new picture is detected, invoke an AWS Lambda function to scan and parse it.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 47,
          "poolQNum": 378,
          "question": {
            "id": 47,
            "questionText": "A set of APIs are exposed to customers using the Amazon API Gateway. These APIs have caching enabled on the API Gateway. Customers have asked for an option to invalidate this cache for each of the APIs. What action can be taken to allow API customers to invalidate the API Cache?",
            "questionImage": null,
            "options": [
              {
                "text": "Ask customers to use AWS credentials to call the `InvalidateCache` API.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Ask customers to invoke an AWS API endpoint which invalidates the cache.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Ask customers to pass an HTTP header called `Cache-Control:max-age=0`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Ask customers to add a query string parameter called `INVALIDATE_CACHE` when making an API call.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 48,
          "poolQNum": 235,
          "question": {
            "id": 48,
            "questionText": "Which EC2 API call would you use to retrieve a list of Amazon Machine Images (AMIs)?",
            "questionImage": null,
            "options": [
              {
                "text": "`DescribeInstances`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`DescribeAMIs`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`DescribeImages`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`GetAMIs`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "You cannot retrieve a list of AMIs as there are over 10,000 AMIs.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 49,
          "poolQNum": 192,
          "question": {
            "id": 49,
            "questionText": "An application ingests a large number of small messages and stores them in a database. The application uses AWS Lambda. A Development team is making changes to the application's processing logic. In testing, it is taking more than 15 minutes to process each message. The team is concerned the current backend may time out. Which changes should be made to the backend system to ensure each message is processed in the MOST scalable way?",
            "questionImage": null,
            "options": [
              {
                "text": "Add the messages to an Amazon SQS queue. Set up and Amazon EC2 instance to poll the queue and process messages as they arrive.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add the messages to an Amazon SQS queue. Set up Amazon EC2 instances in an Auto Scaling group to poll the queue and process the messages as they arrive.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a support ticket to increase the Lambda timeout to 60 minutes to allow for increased processing time.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the application to directly insert the body of the message into an Amazon RDS database.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 50,
          "poolQNum": 401,
          "question": {
            "id": 50,
            "questionText": "A developer is deploying a new application to Amazon Elastic Container Service (Amazon ECS). The developer needs to securely store and retrieve different types of variables. These variables include authentication information for a remote API, the URL for the API, and credentials. The authentication information and API URL must be available to all current and future deployed versions of the application across development, testing, and production environments. How should the developer retrieve the variables with the FEWEST application changes?",
            "questionImage": null,
            "options": [
              {
                "text": "Update the application to retrieve the variables from AWS Systems Manager Parameter Store. Use unique paths in Parameter Store for each variable in each environment. Store the credentials in AWS Secrets Manager in each environment.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Update the application to retrieve the variables from AWS Key Management Service (AWS KMS). Store the API URL and credentials as unique keys for each environment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the application to retrieve the variables from an encrypted file that is stored with the application. Store the API URL and credentials in unique files for each environment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the application to retrieve the variables from each of the deployed environments. Define the authentication information and API URL in the ECS task definition as unique names during the deployment process.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 51,
          "poolQNum": 56,
          "question": {
            "id": 51,
            "questionText": "A Developer has written a serverless application using multiple AWS services. The business logic is written as a Lambda function which has dependencies on third-party libraries. The Lambda function endpoints will be exposed using Amazon API Gateway. The Lambda function will write the information to Amazon DynamoDB. The Developer is ready to deploy the application but must have the ability to rollback. How can this deployment be automated, based on these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy using Amazon Lambda API operations to create the Lambda function by providing a deployment package.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an AWS CloudFormation template and use CloudFormation syntax to define the Lambda function resource in the template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use syntax conforming to the Serverless Application Model in the AWS CloudFormation template to define the Lambda function resource.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a bash script which uses AWS CLI to package and deploy the application.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 52,
          "poolQNum": 16,
          "question": {
            "id": 52,
            "questionText": "The development team is working on an API that will be served from Amazon API gateway. The API will be served from three environments: development, test, and production. The API Gateway is configured to use 237 GB of cache in all three stages. Which is the MOST cost-efficient deployment strategy?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a single API Gateway with all three stages.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create three API Gateways, one for each stage in a single AWS account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an API Gateway in three separate AWS accounts.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable the cache for development and test environments only when needed.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 53,
          "poolQNum": 332,
          "question": {
            "id": 53,
            "questionText": "A Developer is writing an imaging micro service on AWS Lambda. The service is dependent on several libraries that are not available in the Lambda runtime environment. Which strategy should the Developer follow to create the Lambda deployment package?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a `ZIP` file with the source code and all dependent libraries.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a `ZIP` file with the source code and a script that installs the dependent libraries at runtime.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a `ZIP` file with the source code. Stage the dependent libraries on an Amazon S3 bucket indicated by the Lambda environment variable `LD_LIBRARY_PATH`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a `ZIP` file with the source code and a buildspec.yaml file that installs the dependent libraries on AWS Lambda.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 54,
          "poolQNum": 108,
          "question": {
            "id": 54,
            "questionText": "What are the steps to using the AWS CLI to launch a templatized serverless application?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS CloudFormation get-template then CloudFormation execute-change-set.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CloudFormation validate-template then CloudFormation create-change-set.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CloudFormation package then CloudFormation deploy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS CloudFormation create-stack then CloudFormation update-stack.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 55,
          "poolQNum": 121,
          "question": {
            "id": 55,
            "questionText": "An application needs to encrypt data that is written to Amazon S3 where the keys are managed in an on-premises data center, and the encryption is handled by S3. Which type of encryption should be used?",
            "questionImage": null,
            "options": [
              {
                "text": "Use server-side encryption with Amazon S3-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use server-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use client-side encryption with customer master keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use server-side encryption with customer-provided keys.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 56,
          "poolQNum": 172,
          "question": {
            "id": 56,
            "questionText": "A Developer has written an application that runs on Amazon EC2 instances and generates a value every minute. The Developer wants to monitor and graph the values generated over time without logging in to the instance each time. Which approach should the Developer use to achieve this goal?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the Amazon CloudWatch metrics reported by default for all EC2 instances. View each value from the CloudWatch console.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Develop the application to store each value in a file on Amazon S3 every minute with the timestamp as the name.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Publish each generated value as a custom metric to Amazon CloudWatch using available AWS SDKs.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store each value as a variable and add the variable to the list of EC2 metrics that should be reported to the Amazon CloudWatch console.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 57,
          "poolQNum": 318,
          "question": {
            "id": 57,
            "questionText": "A Developer must build an application that uses Amazon DynamoDB. The requirements state that the items being stored in the DynamoDB table will be 7KB in size and that reads must be strongly consistent. The maximum read rate is 3 items per second, and the maximum write rate is 10 items per second. How should the Developer size the DynamoDB table to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Read: 3 read capacity. `unitsWrite`: 70 write capacity units.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Read: 6 read capacity. `unitsWrite`: 70 write capacity units.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Read: 6 read capacity. `unitsWrite`: 10 write capacity units.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Read: 3 read capacity. `unitsWrite`: 10 write capacity units.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 58,
          "poolQNum": 175,
          "question": {
            "id": 58,
            "questionText": "A Developer is writing an application in AWS Lambda. To simplify testing and deployments, the Developer needs the database connection string to be easily changed without modifying the Lambda code. How can this requirement be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Store the connection string as a secret in AWS Secrets Manager.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the connection string in an IAM user account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the connection string in AWS KMS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the connection string as a Lambda layer.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 59,
          "poolQNum": 62,
          "question": {
            "id": 59,
            "questionText": "An application reads data from an Amazon DynamoDB table. Several times a day, for a period of 15 seconds, the application receives multiple `ProvisionedThroughputExceeded` errors. How should this exception be handled?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a new global secondary index for the table to help with the additional requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Retry the failed read requests with exponential backoff.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Immediately retry the failed read requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the DynamoDB `UpdateItem` API to increase the provisioned throughput capacity of the table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 60,
          "poolQNum": 296,
          "question": {
            "id": 60,
            "questionText": "A company is migrating a single-server, on-premises web application to AWS. The company intends to use multiple servers behind an Elastic Load Balancer (ELB) to balance the load, and will also store session data in memory on the web server. The company does not want to lose that session data if a server fails or goes offline, and it wants to minimize user's downtime. Where should the company move session data to MOST effectively reduce downtime and make users' session data more fault tolerant?",
            "questionImage": null,
            "options": [
              {
                "text": "An Amazon ElastiCache for Redis cluster.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "A second Amazon EBS volume.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The web server's primary disk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An Amazon EC2 instance dedicated to session data.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": true
        },
        {
          "qNum": 61,
          "poolQNum": 102,
          "question": {
            "id": 61,
            "questionText": "A Developer will be using the AWS CLI on a local development server to manage AWS services. What can be done to ensure that the CLI uses the Developer's IAM permissions when making commands?",
            "questionImage": null,
            "options": [
              {
                "text": "Specify the Developer's IAM access key ID and secret access key as parameters for each CLI command.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Run the `aws configure` CLI command, and provide the Developer's IAM access key ID and secret access key.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Specify the Developer's IAM user name and password as parameters for each CLI command.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the Developer's IAM role when making the CLI command.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 62,
          "poolQNum": 265,
          "question": {
            "id": 62,
            "questionText": "If an application is storing hourly log files from thousands of instances from a high traffic web site, which naming scheme would give optimal performance on S3?",
            "questionImage": null,
            "options": [
              {
                "text": "Sequential.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`instanceID_log-HH-DD-MM-YYYY`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`instanceIDLog-YYYY-MM-DD-HH`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`HH-DD-MM-YYYY-log_instanceID`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`YYYY-MM-DD-HH-logInstanceID`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 63,
          "poolQNum": 219,
          "question": {
            "id": 63,
            "questionText": "After launching an instance that you intend to serve as a NAT (Network Address Translation) device in a public subnet you modify your route tables to have the NAT device be the target of internet bound traffic of your private subnet. When you try and make an outbound connection to the Internet from an instance in the private subnet, you are not successful. NAT device be the target of internet bound traffic of your private subnet. Which of the following steps could resolve the issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Attaching a second Elastic Network interface (ENI) to the NAT instance, and placing it in the private subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Attaching a second Elastic Network Interface (ENI) to the instance in the private subnet, and placing it in the public subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disabling the `Source/Destination Check` attribute on the NAT instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Attaching an Elastic IP address to the instance in the private subnet.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 64,
          "poolQNum": 310,
          "question": {
            "id": 64,
            "questionText": "A company has three different environments: Development, QA, and Production. The company wants to deploy its code first in the Development environment, then QA, and then Production. Which AWS service can be used to meet this requirement?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS CodeCommit to create multiple repositories to deploy the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CodeBuild to create, configure, and deploy multiple build application projects.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Data Pipeline to create multiple data pipeline provisions to deploy the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CodeDeploy to create multiple deployment groups.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": true
        },
        {
          "qNum": 65,
          "poolQNum": 279,
          "question": {
            "id": 65,
            "questionText": "A company is running a Docker application on Amazon ECS. The application must scale based on user load in the last 15 seconds. How should a Developer instrument the code so that the requirement can be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 30 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a standard-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 30 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a standard-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        }
      ],
      "questionMap": {
        "1": 211,
        "2": 36,
        "3": 68,
        "4": 19,
        "5": 350,
        "6": 188,
        "7": 341,
        "8": 291,
        "9": 186,
        "10": 277,
        "11": 387,
        "12": 339,
        "13": 274,
        "14": 7,
        "15": 53,
        "16": 322,
        "17": 54,
        "18": 320,
        "19": 93,
        "20": 75,
        "21": 367,
        "22": 142,
        "23": 45,
        "24": 338,
        "25": 103,
        "26": 327,
        "27": 132,
        "28": 176,
        "29": 149,
        "30": 324,
        "31": 83,
        "32": 285,
        "33": 43,
        "34": 139,
        "35": 17,
        "36": 244,
        "37": 384,
        "38": 87,
        "39": 273,
        "40": 11,
        "41": 366,
        "42": 397,
        "43": 13,
        "44": 174,
        "45": 266,
        "46": 122,
        "47": 378,
        "48": 235,
        "49": 192,
        "50": 401,
        "51": 56,
        "52": 16,
        "53": 332,
        "54": 108,
        "55": 121,
        "56": 172,
        "57": 318,
        "58": 175,
        "59": 62,
        "60": 296,
        "61": 102,
        "62": 265,
        "63": 219,
        "64": 310,
        "65": 279
      }
    }
  ]
}