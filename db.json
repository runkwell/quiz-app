{
  "history": [
    {
      "id": "1763095257790",
      "timestamp": 1763095257790,
      "score": "0.00",
      "results": [
        {
          "qNum": 1,
          "poolQNum": 346,
          "question": {
            "id": 1,
            "questionText": "Where can PortMapping be defined when launching containers in Amazon ECS?",
            "questionImage": null,
            "options": [
              {
                "text": "Security groups.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Elastic Container Registry (Amzon ECR).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Container agent.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Task definition.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 2,
          "poolQNum": 352,
          "question": {
            "id": 2,
            "questionText": "A company caches session information for a web application in an Amazon DynamoDB table. The company wants an automated way to delete old items from the table. What is the simplest way to do this?",
            "questionImage": null,
            "options": [
              {
                "text": "Write a script that deletes old records; schedule the scripts as a cron job on an Amazon EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an attribute with the expiration time; enable the `Time To Live` feature based on that attribute.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Each day, create a new table to hold session data; delete the previous day's table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an attribute with the expiration time; name the attribute `ItemExpiration`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 3,
          "poolQNum": 179,
          "question": {
            "id": 3,
            "questionText": "A Developer implemented a static website hosted in Amazon S3 that makes web service requests hosted in Amazon API Gateway and AWS Lambda. The site is showing an error that reads: `No Access-Control-Allow-Origin` header is present on the requested resource. Origin `null` is therefore not allowed access.' What should the Developer do to resolve this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable cross-origin resource sharing (CORS) on the S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable cross-origin resource sharing (CORS) for the method in API Gateway.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add the `Access-Control-Request-Method` header to the request.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add the `Access-Control-Request-Headers` header to the request.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 4,
          "poolQNum": 187,
          "question": {
            "id": 4,
            "questionText": "A Developer uses Amazon S3 buckets for static website hosting. The Developer creates one S3 bucket for the code and another S3 bucket for the assets, such as image and video files. Access is denied when a user attempts to access the assets bucket from the code bucket, with the website application showing a `403` error. How should the Developer solve this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM role and apply it to the assets bucket for the code bucket to be granted access.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Edit the bucket policy of the assets bucket to allow access from the code bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Edit the bucket policy of the assets bucket to open access to all principals.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the code bucket to use AWS Lambda functions instead of static website hosting.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 5,
          "poolQNum": 263,
          "question": {
            "id": 5,
            "questionText": "You are providing AWS consulting services for a company developing a new mobile application that will be leveraging Amazon SNS Mobile Push for push notifications. In order to send direct notification messages to individual devices each device registration identifier or token needs to be registered with SNS; however the developers are not sure of the best way to do this. You advise them to:",
            "questionImage": null,
            "options": [
              {
                "text": "Bulk upload the device tokens contained in a CSV file via the AWS Management Console.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Let the push notification service (e.g. Amazon Device Messaging) handle the registration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement a token vending service to handle the registration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Call the `CreatePlatformEndPoint` API function to register multiple device tokens.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 6,
          "poolQNum": 223,
          "question": {
            "id": 6,
            "questionText": "Which of the following are correct statements with policy evaluation logic in AWS Identity and Access Management? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "By default, all requests are denied.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An explicit allow overrides an explicit deny.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An explicit allow overrides default deny.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An explicit deny does not override an explicit allow.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "By default, all request are allowed.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 7,
          "poolQNum": 355,
          "question": {
            "id": 7,
            "questionText": "AWS CodeBuild builds code for an application, creates the Docker image, pushes the image to Amazon Elastic Container Registry (Amazon ECR), and tags the image with a unique identifier. If the Developers already have AWS CLI configured on their workstations, how can the Docker images be pulled to the workstations?",
            "questionImage": null,
            "options": [
              {
                "text": "Run the following: `docker pull REPOSITORY URI : TAG`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Run the output of the following: `aws ecr get-login` and then run: `docker pull REPOSITORY URI : TAG`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Run the following: `aws ecr get-login` and then run: `docker pull REPOSITORY URI : TAG`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Run the output of the following: `aws ecr get-download-url-for-layer` and then run: `docker pull REPOSITORY URI : TAG`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 8,
          "poolQNum": 240,
          "question": {
            "id": 8,
            "questionText": "Which of the following statements about SWF are true? (Choose THREE)",
            "questionImage": null,
            "options": [
              {
                "text": "SWF tasks are assigned once and never duplicated.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SWF requires an S3 bucket for workflow storage.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SWF workflow executions can last up to a year.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SWF triggers SNS notifications on task assignment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SWF uses deciders and workers to complete tasks.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SWF requires at least 1 EC2 instance per domain.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 9,
          "poolQNum": 330,
          "question": {
            "id": 9,
            "questionText": "How should custom libraries be utilized in AWS Lambda?",
            "questionImage": null,
            "options": [
              {
                "text": "Host the library on Amazon S3 and reference to it from the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Install the library locally and upload a `ZIP` file of the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Import the necessary Lambda blueprint when creating the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the function runtime to include the necessary library.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 10,
          "poolQNum": 258,
          "question": {
            "id": 10,
            "questionText": "An Amazon S3 bucket, `myawsbucket` is configured with website hosting in Tokyo region, what is the region-specific website endpoint?",
            "questionImage": null,
            "options": [
              {
                "text": "`www.myawsbucket.ap-northeast-1.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`myawsbucket.s3-website-ap-northeast-1.amazonaws.com`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`myawsbucket.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`myawsbucket.tokyo.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 11,
          "poolQNum": 296,
          "question": {
            "id": 11,
            "questionText": "A company is migrating a single-server, on-premises web application to AWS. The company intends to use multiple servers behind an Elastic Load Balancer (ELB) to balance the load, and will also store session data in memory on the web server. The company does not want to lose that session data if a server fails or goes offline, and it wants to minimize user's downtime. Where should the company move session data to MOST effectively reduce downtime and make users' session data more fault tolerant?",
            "questionImage": null,
            "options": [
              {
                "text": "An Amazon ElastiCache for Redis cluster.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "A second Amazon EBS volume.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The web server's primary disk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An Amazon EC2 instance dedicated to session data.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 12,
          "poolQNum": 205,
          "question": {
            "id": 12,
            "questionText": "A company is developing a web application that allows its employees to upload a profile picture to a private Amazon S3 bucket. There is no size limit for the profile pictures, which should be displayed every time an employee logs in. For security reasons, the pictures cannot be publicly accessible. What is a viable long-term solution for this scenario?",
            "questionImage": null,
            "options": [
              {
                "text": "Generate a presigned URL when a picture is uploaded. Save the URL in an Amazon DynamoDB table. Return the URL to the browser when the employee logs in.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Save the picture's S3 key in an Amazon DynamoDB table. Create an Amazon S3 VPC endpoint to allow the employees to download pictures once they log in.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Encode a picture using base64. Save the base64 string in an Amazon DB table. Allow the browser to retrieve the string and convert it to a picture.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Save the picture's S3 key in an Amazon DynamoDB table. Use a function to generate a presigned URL every time an employee logs in. Return the URL to the browser.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 13,
          "poolQNum": 362,
          "question": {
            "id": 13,
            "questionText": "A Developer has developed a web application and wants to deploy it quickly on a Tomcat server on AWS. The Developer wants to avoid having to manage the underlying infrastructure. What is the easiest way to deploy the application, based on these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS CloudFormation.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Elastic Beanstalk.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodePipeline",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 14,
          "poolQNum": 283,
          "question": {
            "id": 14,
            "questionText": "A Developer is trying to deploy a serverless application using AWS CodeDeploy. The application was updated and needs to be redeployed. What file does the Developer need to update to push that change through CodeDeploy?",
            "questionImage": null,
            "options": [
              {
                "text": "`dockerrun.aws.json`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`buildspec.yml`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`appspec.yml`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`ebextensions.config`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 15,
          "poolQNum": 254,
          "question": {
            "id": 15,
            "questionText": "Which of the following programming languages have an officially supported AWS SDK? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Perl.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "PHP.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Pascal.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Java.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SQL.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 16,
          "poolQNum": 78,
          "question": {
            "id": 16,
            "questionText": "A customer wants to deploy its source code on an AWS Elastic Beanstalk environment. The customer needs to perform deployment with minimal outage and should only use existing instances to retain application access log. What deployment policy would satisfy these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Rolling.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "All at once.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling with an additional batch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Immutable.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 17,
          "poolQNum": 167,
          "question": {
            "id": 17,
            "questionText": "A Developer registered an AWS Lambda function as a target for an Application Load Balancer (ALB) using a CLI command. However, the Lambda function is not being invoked when the client sends requests through the ALB. Why is the Lambda function not being invoked?",
            "questionImage": null,
            "options": [
              {
                "text": "A Lambda function cannot be registered as a target for an ALB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A Lambda function can be registered with an ALB using AWS Management Console only.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The permissions to invoke the Lambda function are missing.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Cross-zone is not enabled on the ALB.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 18,
          "poolQNum": 332,
          "question": {
            "id": 18,
            "questionText": "A Developer is writing an imaging micro service on AWS Lambda. The service is dependent on several libraries that are not available in the Lambda runtime environment. Which strategy should the Developer follow to create the Lambda deployment package?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a `ZIP` file with the source code and all dependent libraries.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a `ZIP` file with the source code and a script that installs the dependent libraries at runtime.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a `ZIP` file with the source code. Stage the dependent libraries on an Amazon S3 bucket indicated by the Lambda environment variable `LD_LIBRARY_PATH`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a `ZIP` file with the source code and a buildspec.yaml file that installs the dependent libraries on AWS Lambda.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 19,
          "poolQNum": 123,
          "question": {
            "id": 19,
            "questionText": "A development team wants to run their container workloads on Amazon ECS. Each application container needs to share data with another container to collect logs and metrics. What should the developer team do to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Create two pod specifications. Make one to include the application container and the other to include the other container. Link the two pods together.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create two task definitions. Make one to include the application container and the other to include the other container. Mount a shared volume between the two tasks.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create one task definition. Specify both containers in the definition. Mount a shared volume between those two containers.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a single pod specification. Include both containers in the specification. Mount a persistent volume to both containers.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 20,
          "poolQNum": 172,
          "question": {
            "id": 20,
            "questionText": "A Developer has written an application that runs on Amazon EC2 instances and generates a value every minute. The Developer wants to monitor and graph the values generated over time without logging in to the instance each time. Which approach should the Developer use to achieve this goal?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the Amazon CloudWatch metrics reported by default for all EC2 instances. View each value from the CloudWatch console.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Develop the application to store each value in a file on Amazon S3 every minute with the timestamp as the name.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Publish each generated value as a custom metric to Amazon CloudWatch using available AWS SDKs.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store each value as a variable and add the variable to the list of EC2 metrics that should be reported to the Amazon CloudWatch console.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 21,
          "poolQNum": 316,
          "question": {
            "id": 21,
            "questionText": "A company has a website that is developed in PHP and WordPress and is launched using AWS Elastic Beanstalk. There is a new version of the website that needs to be deployed in the Elastic Beanstalk environment. The company cannot tolerate having the website offline if an update fails. Deployments must have minimal impact and rollback as soon as possible. What deployment method should be used?",
            "questionImage": null,
            "options": [
              {
                "text": "All at once.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Snapshots.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Immutable.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 22,
          "poolQNum": 100,
          "question": {
            "id": 22,
            "questionText": "A Developer uses AWS CodeDeploy to automate application deployment that connects to an external MySQL database. The Developer wants to securely access the encrypted secrets, such as API keys and database passwords. Which of the following solutions would involve the LEAST administrative effort?",
            "questionImage": null,
            "options": [
              {
                "text": "Save the secrets in Amazon S3 with AWS KMS server-side encryption, and use a signed URL to access them by using the IAM role from Amazon EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the instance metadata to store the secrets and to programmatically access the secrets from EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the Amazon DynamoDB client-side encryption library to save the secrets in DynamoDB and to programmatically access the secrets from EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS SSM Parameter Store to store the secrets and to programmatically access them by using the IAM role from EC2 instances.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 23,
          "poolQNum": 368,
          "question": {
            "id": 23,
            "questionText": "A development team is using AWS Elastic Beanstalk to deploy a two-tier application that consists of a load-balanced web tier and an Amazon RDS database tier in production. The team would like to separate the RDS instance from the Elastic Beanstalk. How can this be accomplished?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the Elastic Beanstalk CLI to disassociate the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS CLI to disassociate the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the deployment policy to disassociate the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Recreate a new Elastic Beanstalk environment without Amazon RDS.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 24,
          "poolQNum": 76,
          "question": {
            "id": 24,
            "questionText": "A legacy service has an XML-based SOAP interface. The Developer wants to expose the functionality of the service to external clients with the Amazon API Gateway. Which technique will accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a RESTful API with the API Gateway; transform the incoming JSON into a valid XML message for the SOAP interface using mapping templates.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a RESTful API with the API Gateway; pass the incoming JSON to the SOAP interface through an Application Load Balancer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a RESTful API with the API Gateway; pass the incoming XML to the SOAP interface through an Application Load Balancer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a RESTful API with the API Gateway; transform the incoming XML into a valid message for the SOAP interface using mapping templates.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 25,
          "poolQNum": 251,
          "question": {
            "id": 25,
            "questionText": "Your application is trying to upload a 6 GB file to Simple Storage Service and receive a `Your proposed upload exceeds the maximum allowed object size.` error message. What is a possible solution for this?",
            "questionImage": null,
            "options": [
              {
                "text": "None, Simple Storage Service objects are limited to 5 GB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the multi-part upload API for this object.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use the large object upload API for this object.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Contact support to increase your object size limit.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload to a different region.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 26,
          "poolQNum": 5,
          "question": {
            "id": 26,
            "questionText": "A Developer wants to upload data to Amazon S3 and must encrypt the data in transit. Which of the following solutions will accomplish this task? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Set up hardware VPN tunnels to a VPC and access S3 through a VPC endpoint.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set up Client-Side Encryption with an AWS KMS-Managed Customer Master Key.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set up Server-Side Encryption with AWS KMS-Managed Keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Transfer the data over an SSL connection.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set up Server-Side Encryption with S3-Managed Keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 27,
          "poolQNum": 158,
          "question": {
            "id": 27,
            "questionText": "A Developer has an Amazon DynamoDB table that must be in provisioned mode to comply with user requirements. The application needs to support the following: Average item size: 10 KB. Item reads each second: 10 strongly consistent. Item writes each second: 2 transactional. Which read and write capacity cost-effectively meets these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Read `10`; write `2`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Read `30`; write `40`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use on-demand scaling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Read `300`; write `400`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 28,
          "poolQNum": 59,
          "question": {
            "id": 28,
            "questionText": "Given the source code for an AWS Lambda function in the local `store.py` containing a handler function called `get_store` and the following AWS CloudFormation template. What should be done to prepare the template so that it can be deployed using the AWS CLI command `aws cloudformation deploy`?",
            "questionImage": "images/question59.jpg",
            "options": [
              {
                "text": "Use AWS CloudFormation compile to base64 encode and embed the source file into a modified CloudFormation template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CloudFormation package to upload the source code to an Amazon S3 bucket and produce a modified CloudFormation template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS Lambda zip to package the source file together with the CloudFormation template and deploy the resulting zip archive.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Serverless `create-package` to embed the source file directly into the existing CloudFormation template.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 29,
          "poolQNum": 119,
          "question": {
            "id": 29,
            "questionText": "A company has 25,000 employees and is growing. The company is creating an application that will be accessible to its employees only. A developer is using Amazon S3 to store images and Amazon RDS to store application data. The company requires that all employee information remain in the legacy Security Assertion Markup Language (SAML) employee directory only and is not interested in mirroring any employee information on AWS. How can the developer provide authorized access for the employees who will be using this application so each employee can access their own application data only?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon VPC and keep all resources inside the VPC, and use a VPC link for the S3 bucket with the bucket policy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito user pools, federate with the SAML provider, and use user pool groups with an IAM policy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon Cognito identity pool, federate with the SAML provider, and use an IAM condition key with a value for the `cognito-identity.amazonaws.com:sub` variable to grant access to the employees.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a unique IAM role for each employee and have each employee assume the role to access the application so they can access their personal data only.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 30,
          "poolQNum": 208,
          "question": {
            "id": 30,
            "questionText": "A Developer has an e-commerce API hosted on Amazon ECS. Variable and spiking demand on the application is causing order processing to take too long. The application processes Amazon SQS queues. The `ApproximateNumberOfMessagesVisible` metric spikes at very high values throughout the day, which cause Amazon CloudWatch alarm breaches. Other ECS metrics for the API containers are well within limits. What can the Developer implement to improve performance while keeping costs low?",
            "questionImage": null,
            "options": [
              {
                "text": "Target tracking scaling policy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Docker Swarm.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Service scheduler.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Step scaling policy.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 31,
          "poolQNum": 374,
          "question": {
            "id": 31,
            "questionText": "A Developer must trigger an AWS Lambda function based on the item lifecycle activity in an Amazon DynamoDB table. How can the Developer create the solution?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable a DynamoDB stream that publishes an Amazon SNS message. Trigger the Lambda function synchronously from the SNS message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable a DynamoDB stream that publishes an SNS message. Trigger the Lambda function asynchronously from the SNS message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable a DynamoDB stream, and trigger the Lambda function synchronously from the stream.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Enable a DynamoDB stream, and trigger the Lambda function asynchronously from the stream.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 32,
          "poolQNum": 357,
          "question": {
            "id": 32,
            "questionText": "A company needs a new REST API that can return information about the contents of an Amazon S3 bucket, such as a count of the objects stored in it. The company has decided that the new API should be written as a microservice using AWS Lambda and Amazon API Gateway. How should the Developer ensure that the microservice has the necessary access to the Amazon S3 bucket, while adhering to security best practices?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM user that has permissions to access the Amazon S3 bucket, and store the IAM user credentials in the Lambda function source code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM role that has permissions to access the Amazon S3 bucket and assign it to the Lambda function as its execution role.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an Amazon S3 bucket policy that specifies the Lambda service as its principal and assign it to the Amazon S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM role, attach the AmazonS3FullAccess managed policy to it, and assign the role to the Lambda function as its execution role.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 33,
          "poolQNum": 6,
          "question": {
            "id": 33,
            "questionText": "A Developer wants to encrypt new objects that are being uploaded to an Amazon S3 bucket by an application. There must be an audit trail of who has used the key during this process. There should be no change to the performance of the application. Which type of encryption meets these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Server-side encryption using S3-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client-side encryption with a client-side symmetric master key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Client-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 34,
          "poolQNum": 17,
          "question": {
            "id": 34,
            "questionText": "A company is migrating its on-premises database to Amazon RDS for MySQL. The company has read-heavy workloads, and wants to make sure it re-factors its code to achieve optimum read performance for its queries. How can this objective be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Add database retries to effectively use RDS with vertical scaling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use RDS with multi-AZ deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a connection string to use an RDS read replica for read queries.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add a connection string to use a read replica on an EC2 instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 35,
          "poolQNum": 213,
          "question": {
            "id": 35,
            "questionText": "When developing an AWS Lambda function that processes Amazon Kinesis Data Streams, Administrators within the company must receive a notice that includes the processed data. How should the Developer write the function to send processed data to the Administrators?",
            "questionImage": null,
            "options": [
              {
                "text": "Separate the Lambda handler from the core logic.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudWatch Events to send the processed data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Publish the processed data to an Amazon SNS topic.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Push the processed data to Amazon SQS.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 36,
          "poolQNum": 366,
          "question": {
            "id": 36,
            "questionText": "An application running on an Amazon Linux EC2 instance needs to manage the AWS infrastructure. How can the EC2 instance be configured to make AWS API calls securely?",
            "questionImage": null,
            "options": [
              {
                "text": "Sign the AWS CLI command using the signature version 4 process.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Run the `aws configure` AWS CLI command and specify the access key id and secret access key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Specify a role for the EC2 instance with the necessary privileges.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Pass the access key id and secret access key as parameters for each AWS CLI command.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 37,
          "poolQNum": 370,
          "question": {
            "id": 37,
            "questionText": "A social media company is using Amazon Cognito in order to synchronize profiles across different mobile devices, to enable end users to have a seamless experience. Which of the following configurations can be used to silently notify users whenever an update is available on all other devices?",
            "questionImage": null,
            "options": [
              {
                "text": "Modify the user pool to include all the devices which keep them in sync.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the SyncCallback interface to receive notifications on the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon Cognito stream to analyze the data and push the notifications.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the push synchronization feature with the appropriate IAM role.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 38,
          "poolQNum": 295,
          "question": {
            "id": 38,
            "questionText": "A Developer is investigating an issue whereby certain requests are passing through an Amazon API Gateway endpoint /MyAPI, but the requests do not reach the AWS Lambda function backing /MyAPI. The Developer found that a second Lambda function sometimes runs at maximum concurrency allowed for the given AWS account. How can the Developer address this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Manually reduce the concurrent execution limit at the account level.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add another API Gateway stage for /MyAPI, and shard the requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure the second Lambda function's concurrency execution limit.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Reduce the throttling limits in the API Gateway /MyAPI endpoint",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 39,
          "poolQNum": 201,
          "question": {
            "id": 39,
            "questionText": "A company has a web application that uses an Amazon Cognito user pool for authentication. The company wants to create a login page with the company logo. What should a Developer do to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a hosted user interface in Amazon Cognito and customize it with the company logo.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a login page with the company logo and upload it to Amazon Cognito.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a login page in Amazon API Gateway with the logo and save the link in Amazon Cognito.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload the logo to the Amazon Cognito app settings and point to the logo on a custom login page.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 40,
          "poolQNum": 51,
          "question": {
            "id": 40,
            "questionText": "A Developer is asked to implement a caching layer in front of Amazon RDS. Cached content is expensive to regenerate in case of service failure. Which implementation below would work while maintaining maximum uptime?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement Amazon ElastiCache Redis in Cluster Mode.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install Redis on an Amazon EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement Amazon ElastiCache Memcached.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Migrate the database to Amazon Redshift.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 41,
          "poolQNum": 16,
          "question": {
            "id": 41,
            "questionText": "The development team is working on an API that will be served from Amazon API gateway. The API will be served from three environments: development, test, and production. The API Gateway is configured to use 237 GB of cache in all three stages. Which is the MOST cost-efficient deployment strategy?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a single API Gateway with all three stages.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create three API Gateways, one for each stage in a single AWS account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an API Gateway in three separate AWS accounts.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable the cache for development and test environments only when needed.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 42,
          "poolQNum": 356,
          "question": {
            "id": 42,
            "questionText": "A web application is designed to allow new users to create accounts using their email addresses. The application will store attributes for each user, and is expecting millions of user to sign up. What should the Developer implement to achieve the design goals?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon Cognito user pools.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Mobile Hub user data storage.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito Sync.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Mobile Hub cloud logic.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 43,
          "poolQNum": 319,
          "question": {
            "id": 43,
            "questionText": "A Developer is creating an AWS Lambda function to process a stream of data from an Amazon Kinesis Data Stream. When the Lambda function parses the data and encounters a missing field, it exits the function with an error. The function is generating duplicate records from the Kinesis stream. When the Developer looks at the stream output without the Lambda function, there are no duplicate records. What is the reason for the duplicates?",
            "questionImage": null,
            "options": [
              {
                "text": "The Lambda function did not advance the Kinesis stream pointer to the next record after the error.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The Lambda event source used asynchronous invocation, resulting in duplicate records.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The Lambda function did not handle the error, and the Lambda service attempted to reprocess the data.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The Lambda function is not keeping up with the amount of data coming from the stream.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 44,
          "poolQNum": 336,
          "question": {
            "id": 44,
            "questionText": "A Developer is writing a serverless application that requires that an AWS Lambda function be invoked every 10 minutes. What is an automated and serverless way to trigger the function?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy an Amazon EC2 instance based on Linux, and edit its `/etc/crontab` file by adding a command to periodically invoke the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure an environment variable named PERIOD for the Lambda function. Set the value to `600`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon CloudWatch Events rule that triggers on a regular schedule to invoke the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an Amazon SNS topic that has a subscription to the Lambda function with a 600-second timer.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 45,
          "poolQNum": 90,
          "question": {
            "id": 45,
            "questionText": "A Developer has created a software package to be deployed on multiple EC2 instances using IAM roles. What actions could be performed to verify IAM access to get records from Amazon Kinesis Streams? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Use the AWS CLI to retrieve the IAM group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Query Amazon EC2 metadata for in-line IAM policies.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Request a token from AWS STS, and perform a describe action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Perform a get action using the `--dry-run` argument.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Validate the IAM role policy with the IAM policy simulator.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "4",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 46,
          "poolQNum": 290,
          "question": {
            "id": 46,
            "questionText": "A Developer has a stateful web server on-premises that is being migrated to AWS. The Developer must have greater elasticity in the new design. How should the Developer re-factor the application to make it more elastic? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Use pessimistic concurrency on Amazon DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudFront with an Auto Scaling group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudFront with an AWS Web Application Firewall.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store session state data in an Amazon DynamoDB table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use an ELB with an Auto Scaling group.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "4",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 47,
          "poolQNum": 56,
          "question": {
            "id": 47,
            "questionText": "A Developer has written a serverless application using multiple AWS services. The business logic is written as a Lambda function which has dependencies on third-party libraries. The Lambda function endpoints will be exposed using Amazon API Gateway. The Lambda function will write the information to Amazon DynamoDB. The Developer is ready to deploy the application but must have the ability to rollback. How can this deployment be automated, based on these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy using Amazon Lambda API operations to create the Lambda function by providing a deployment package.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an AWS CloudFormation template and use CloudFormation syntax to define the Lambda function resource in the template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use syntax conforming to the Serverless Application Model in the AWS CloudFormation template to define the Lambda function resource.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a bash script which uses AWS CLI to package and deploy the application.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 48,
          "poolQNum": 143,
          "question": {
            "id": 48,
            "questionText": "What is required to trace Lambda-based applications with AWS X-Ray?",
            "questionImage": null,
            "options": [
              {
                "text": "Send logs from the Lambda application to an S3 bucket; trigger a Lambda function from the bucket to send data to AWS X-Ray.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Trigger a Lambda function from the application logs in Amazon CloudWatch to submit tracing data to AWS X-Ray.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an IAM execution role to give the Lambda function permissions and enable tracing.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Update and add AWS X-Ray daemon code to relevant parts of the Lambda function to set up the trace.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 49,
          "poolQNum": 193,
          "question": {
            "id": 49,
            "questionText": "A Software Engineer developed an AWS Lambda function in Node.js to do some CPU-intensive data processing. With the default settings, the Lambda function takes about 5 minutes to complete. Which approach should a Developer take to increase the speed of completion?",
            "questionImage": null,
            "options": [
              {
                "text": "Instead of using Node.js, rewrite the Lambda function using Python.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Instead of packaging the libraries in the `ZIP` file with the function, move them to a Lambda layer and use the layer with the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Allocate the maximum available CPU units to the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the available memory to the function.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 50,
          "poolQNum": 271,
          "question": {
            "id": 50,
            "questionText": "A team of Developers must migrate an application running inside an AWS Elastic Beanstalk environment from a Classic Load Balancer to an Application Load Balancer. Which steps should be taken to accomplish the task using the AWS Management Console?",
            "questionImage": null,
            "options": [
              {
                "text": "1. Update the application code in the existing deployment. 2. Select a new load balancer type before running the deployment. 3. Deploy the new version of the application code to the environment.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "1. Create a new environment with the same configurations except for the load balancer type. 2. Deploy the same application version as used in the original environment. 3. Run the `swap-environment-cnames` action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1. Clone the existing environment, changing the associated load balancer type. 2. Deploy the same application version as used in the original environment. 3. Run the `swap-environment-cnames` action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1. Edit the environment definitions in the existing deployment. 2. Change the associated load balancer type according to the requirements. 3. Rebuild the environment with the new load balancer type.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 51,
          "poolQNum": 286,
          "question": {
            "id": 51,
            "questionText": "A company needs to distribute firmware updates to its customers around the world. Which service will allow easy and secure control of the access to the downloads at the lowest cost?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon CloudFront with signed URLs for Amazon S3.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a dedicated Amazon CloudFront Distribution for each customer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudFront with AWS Lambda@Edge.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon API Gateway and AWS Lambda to control access to an S3 bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 52,
          "poolQNum": 71,
          "question": {
            "id": 52,
            "questionText": "Where should the `appspec.yml` file be placed in order for AWS CodeDeploy to work?",
            "questionImage": null,
            "options": [
              {
                "text": "In the root of the application source code directory structure.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "In the `bin` folder along with all the complied code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In an S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the same folder as the application configuration files.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 53,
          "poolQNum": 162,
          "question": {
            "id": 53,
            "questionText": "A Company runs continuous integration/continuous delivery (CI/CD) pipelines for its application on AWS CodePipeline. A Developer must write unit tests and run them as part of the pipelines before staging the artifacts for testing. How should the Developer incorporate unit tests as part of CI/CD pipelines?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a separate CodePipeline pipeline to run unit tests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the AWS CodeBuild specification to include a phase for running unit tests.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install the AWS CodeDeploy agent on an Amazon EC2 instance to run unit tests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a testing branch in AWS CodeCommit to run unit tests.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 54,
          "poolQNum": 161,
          "question": {
            "id": 54,
            "questionText": "A Developer is investigating an application's performance issues. The application consists of hundreds of microservices, and a single API call can potentially have a deep call stack. The Developer must isolate the component that is causing the issue. Which AWS service or feature should the Developer use to gather information about what is happening and isolate the fault?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS X-Ray.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "VPC Flow Logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon GuardDuty.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Macie.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 55,
          "poolQNum": 267,
          "question": {
            "id": 55,
            "questionText": "A corporate web application is deployed within an Amazon VPC, and is connected to the corporate data center via IPSec VPN. The application must authenticate against the on-premise LDAP server. Once authenticated, logged-in users can only access an S3 keyspace specific to the user. Which two approaches can satisfy the objectives? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "The application authenticates against LDAP. The application then calls the IAM Security Service to login to IAM using the LDAP credentials. The application can use the 1AM temporary credentials to access the appropriate S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The application authenticates against LDAP, and retrieves the name of an IAM role associated with the user. The application then calls the IAM Security Token Service to assume that IAM Role. The application can use the temporary credentials to access the appropriate S3 bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The application authenticates against IAM Security Token Service using the LDAP credentials. The application uses those temporary AWS security credentials to access the appropriate S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Develop an identity broker which authenticates against LDAP, and then calls IAM Security Token Service to get IAM federated user credentials. The application calls the identity broker to get IAM federated user credentials with access to the appropriate S3 bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Develop an identity broker which authenticates against IAM Security Token Service to assume an IAM Role to get temporary AWS security credentials. The application calls the identity broker to get AWS temporary security credentials with access to the appropriate S3 bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 56,
          "poolQNum": 89,
          "question": {
            "id": 56,
            "questionText": "A company needs to encrypt data at rest, but it wants to leverage an AWS managed service using its own master key. Which of the following AWS service can be used to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "SSE with Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SSE with AWS KMS.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client-side encryption.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS IAM roles and policies.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 57,
          "poolQNum": 35,
          "question": {
            "id": 57,
            "questionText": "An application running on EC2 instances is storing data in an S3 bucket. Security policy mandates that all data must be encrypted in transit. How can the Developer ensure that all traffic to the S3 bucket is encrypted?",
            "questionImage": null,
            "options": [
              {
                "text": "Install certificates on the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a bucket policy that allows traffic where `SecureTransport` is `true`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an HTTPS redirect on the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a bucket policy that denies traffic where `SecureTransport` is `false`.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 58,
          "poolQNum": 84,
          "question": {
            "id": 58,
            "questionText": "A Developer needs temporary access to resources in a second account. What is the MOST secure way to achieve this?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the Amazon Cognito user pools to get short-lived credentials for the second account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a dedicated IAM access key for the second account, and send it by mail.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a cross-account access role, and use `sts:AssumeRole` API to get short-lived credentials.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Establish trust, and add an SSH key for the second account to the IAM user.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 59,
          "poolQNum": 49,
          "question": {
            "id": 59,
            "questionText": "An application on AWS is using third-party APIs. The Developer needs to monitor API errors in the code, and wants to receive notifications if failures go above a set threshold value. How can the Developer achieve these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Publish a custom metric on Amazon CloudWatch and use Amazon Simple Email Service (SES) for notification.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon CloudWatch API-error metric and use Amazon Simple Notification Service (SNS) for notification.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon CloudWatch API-error metric and use Amazon SES for notification.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Publish a custom metric on Amazon CloudWatch and use Amazon SNS for notification.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 60,
          "poolQNum": 317,
          "question": {
            "id": 60,
            "questionText": "A company has a multi-tiered web application on AWS. During a recent spike in traffic, one of the primary relational databases on Amazon RDS could not serve all the traffic. Some read queries for repeatedly accessed items failed, so users received error messages. What can be done to minimize the impact on database read queries MOST efficiently during future traffic spikes?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon S3 to cache database query results.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon RDS as a custom origin for Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use local storage and memory on Amazon EC2 instances to cache data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache in front of the primary database to cache data.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 61,
          "poolQNum": 164,
          "question": {
            "id": 61,
            "questionText": "A Developer must allow guest users without logins to access an Amazon Cognito-enabled site to view files stored within an Amazon S3 bucket. How should the Developer meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a blank user ID in a user pool, add to the user group, and grant access to AWS resources.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a new identity pool, enable access to unauthenticated identities, and grant access to AWS resources.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a new user pool, enable access to authenticated identifies, and grant access to AWS resources.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a new user pool, disable authentication access, and grant access to AWS resources.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 62,
          "poolQNum": 132,
          "question": {
            "id": 62,
            "questionText": "A developer is using Amazon DynamoDB to store application data. The developer wants to further improve application performance by reducing response times for read and write operations. Which DynamoDB feature should be used to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon DynamoDB Streams.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon DynamoDB Accelerator.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon DynamoDB global tables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon DynamoDB transactions.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 63,
          "poolQNum": 371,
          "question": {
            "id": 63,
            "questionText": "An on-premises application is implemented using a Linux, Apache, MySQL and PHP (LAMP) stack. The Developer wants to run this application in AWS. Which of the following sets of AWS services can be used to run this stack?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon API Gateway, Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Lambda, Amazon DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon EC2, Amazon Aurora.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon Cognito, Amazon RDS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon ECS, Amazon EBS.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 64,
          "poolQNum": 23,
          "question": {
            "id": 64,
            "questionText": "A Developer is making changes to a custom application that is currently using AWS Elastic Beanstalk. After the Developer completes the changes, what solutions will update the Elastic Beanstalk environment with the new application version? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Package the application code into a `.zip` file, and upload, then deploy the packaged application from the AWS Management Console.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Package the application code into a `.tar` file, create a new application version from the AWS Management Console, then update the environment by using AWS CLI.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Package the application code into a `.tar` file, and upload and deploy the packaged application from the AWS Management Console.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Package the application code into a `.zip` file, create a new application version from the packaged application by using AWS CLI, then update the environment by using AWS CLI.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Package the application code into a `.zip` file, create a new application version from the AWS Management Console, then rebuild the environment by using AWS CLI.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 65,
          "poolQNum": 209,
          "question": {
            "id": 65,
            "questionText": "A Developer wants to build an application that will allow new users to register and create new user accounts. The application must also allow users with social media accounts to log in using their social media credentials. Which AWS service or feature can be used to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS IAM.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito identity pools.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito user pools.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Directory Service.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        }
      ],
      "questionMap": {
        "1": 346,
        "2": 352,
        "3": 179,
        "4": 187,
        "5": 263,
        "6": 223,
        "7": 355,
        "8": 240,
        "9": 330,
        "10": 258,
        "11": 296,
        "12": 205,
        "13": 362,
        "14": 283,
        "15": 254,
        "16": 78,
        "17": 167,
        "18": 332,
        "19": 123,
        "20": 172,
        "21": 316,
        "22": 100,
        "23": 368,
        "24": 76,
        "25": 251,
        "26": 5,
        "27": 158,
        "28": 59,
        "29": 119,
        "30": 208,
        "31": 374,
        "32": 357,
        "33": 6,
        "34": 17,
        "35": 213,
        "36": 366,
        "37": 370,
        "38": 295,
        "39": 201,
        "40": 51,
        "41": 16,
        "42": 356,
        "43": 319,
        "44": 336,
        "45": 90,
        "46": 290,
        "47": 56,
        "48": 143,
        "49": 193,
        "50": 271,
        "51": 286,
        "52": 71,
        "53": 162,
        "54": 161,
        "55": 267,
        "56": 89,
        "57": 35,
        "58": 84,
        "59": 49,
        "60": 317,
        "61": 164,
        "62": 132,
        "63": 371,
        "64": 23,
        "65": 209
      }
    },
    {
      "id": "1763095519836",
      "timestamp": 1763095519836,
      "score": "0.00",
      "results": [
        {
          "qNum": 1,
          "poolQNum": 63,
          "question": {
            "id": 1,
            "questionText": "A Developer is writing a Linux-based application to run on AWS Elastic Beanstalk. Application requirements state that the application must maintain full capacity during updates while minimizing cost. Which type of Elastic Beanstalk deployment policy should the Developer specify for the environment?",
            "questionImage": null,
            "options": [
              {
                "text": "Immutable.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "All at Once.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling with additional batch.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 2,
          "poolQNum": 333,
          "question": {
            "id": 2,
            "questionText": "A Developer is designing a fault-tolerant environment where client sessions will be saved. How can the Developer ensure that no sessions are lost if an Amazon EC2 instance fails?",
            "questionImage": null,
            "options": [
              {
                "text": "Use sticky sessions with an Elastic Load Balancer target group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon SQS to save session data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon DynamoDB to perform scalable session handling.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Elastic Load Balancer connection draining to stop sending requests to failing instances.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 3,
          "poolQNum": 334,
          "question": {
            "id": 3,
            "questionText": "In a move toward using microservices, a company's Management team has asked all Development teams to build their services so that API requests depend only on that service's data store. One team is building a Payments service which has its own database; the service needs data that originates in the Accounts database. Both are using Amazon DynamoDB. What approach will result in the simplest, decoupled, and reliable method to get near-real time updates from the Accounts database?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon Glue to perform frequent ETL updates from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache in Payments, with the cache updated by triggers in the Accounts database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Kinesis Data Firehose to deliver all changes from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon DynamoDB Streams to deliver all changes from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 4,
          "poolQNum": 248,
          "question": {
            "id": 4,
            "questionText": "An application stores payroll information nightly in DynamoDB for a large number of employees across hundreds of offices. Item attributes consist of individual name, office identifier, and cumulative daily hours. Managers run reports for ranges of names working in their office. One query is: `Return all Items in this office for names starting with A through E`. Which table configuration will result in the lowest impact on provisioned throughput for this query?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure the table to have a hash index on the name attribute, and a range index on the office identifier.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure the table to have a range index on the name attribute, and a hash index on the office identifier.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure a hash index on the name attribute and no range index.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure a hash index on the office identifier attribute and no range index.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 5,
          "poolQNum": 11,
          "question": {
            "id": 5,
            "questionText": "An AWS Lambda function generates a 3MB JSON file and then uploads it to an Amazon S3 bucket daily. The file contains sensitive information, so the Developer must ensure that it is encrypted before uploading to the bucket. Which of the following modifications should the Developer make to ensure that the data is encrypted before uploading it to the bucket?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the default AWS KMS customer master key for S3 in the Lambda function code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the S3 managed key and call the `GenerateDataKey` API to encrypt the file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `GenerateDataKey` API, then use that data key to encrypt the file in the Lambda function code.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use a custom KMS customer master key created for S3 in the Lambda function code.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 6,
          "poolQNum": 131,
          "question": {
            "id": 6,
            "questionText": "A developer is using AWS CodeDeploy to deploy an application running on Amazon EC2. The developer wants to change the file permissions for a specific deployment file. Which lifecycle event should a developer use to meet this requirement?",
            "questionImage": null,
            "options": [
              {
                "text": "AfterInstall.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "DownloadBundle.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "BeforeInstall.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "ValidateService.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 7,
          "poolQNum": 267,
          "question": {
            "id": 7,
            "questionText": "A corporate web application is deployed within an Amazon VPC, and is connected to the corporate data center via IPSec VPN. The application must authenticate against the on-premise LDAP server. Once authenticated, logged-in users can only access an S3 keyspace specific to the user. Which two approaches can satisfy the objectives? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "The application authenticates against LDAP. The application then calls the IAM Security Service to login to IAM using the LDAP credentials. The application can use the 1AM temporary credentials to access the appropriate S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The application authenticates against LDAP, and retrieves the name of an IAM role associated with the user. The application then calls the IAM Security Token Service to assume that IAM Role. The application can use the temporary credentials to access the appropriate S3 bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The application authenticates against IAM Security Token Service using the LDAP credentials. The application uses those temporary AWS security credentials to access the appropriate S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Develop an identity broker which authenticates against LDAP, and then calls IAM Security Token Service to get IAM federated user credentials. The application calls the identity broker to get IAM federated user credentials with access to the appropriate S3 bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Develop an identity broker which authenticates against IAM Security Token Service to assume an IAM Role to get temporary AWS security credentials. The application calls the identity broker to get AWS temporary security credentials with access to the appropriate S3 bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 8,
          "poolQNum": 247,
          "question": {
            "id": 8,
            "questionText": "Which of the following is an example of a good DynamoDB hash key schema for provisioned throughput efficiency?",
            "questionImage": null,
            "options": [
              {
                "text": "User ID, where the application has many different users.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Status Code where most status codes are the same.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Device ID, where one is by far more popular than all the others.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Game Type, where there are three possible game types.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 9,
          "poolQNum": 311,
          "question": {
            "id": 9,
            "questionText": "A company uses Amazon DynamoDB for managing and tracking orders. The DynamoDB table is partitioned based on the order date. The company receives a huge increase in orders during a sales event, causing DynamoDB writes to throttle, and the consumed throughput is far below the provisioned throughput. According to AWS best practices, how can this issue be resolved with MINIMAL costs?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a new DynamoDB table for every order date.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the read and write capacity units of the DynamoDB table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a random number suffix to the partition key values.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add a global secondary index to the DynamoDB table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 10,
          "poolQNum": 257,
          "question": {
            "id": 10,
            "questionText": "Company B provides an online image recognition service and utilizes SQS to decouple system components for scalability The SQS consumers poll the imaging queue as often as possible to keep end-to-end throughput as high as possible. However, Company B is realizing that polling in tight loops is burning CPU cycles and increasing costs with empty responses. How can Company B reduce the number of empty responses?",
            "questionImage": null,
            "options": [
              {
                "text": "Set the imaging queue visibility `Timeout` attribute to 20 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set the Imaging queue `ReceiveMessageWaitTimeSeconds` attribute to 20 seconds.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set the imaging queue `MessageRetentionPeriod` attribute to 20 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set the `DelaySeconds` parameter of a message to 20 seconds.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 11,
          "poolQNum": 58,
          "question": {
            "id": 11,
            "questionText": "A Developer is creating a web application that requires authentication, but also needs to support guest access to provide users limited access without having to authenticate. What service can provide support for the application to allow guest access?",
            "questionImage": null,
            "options": [
              {
                "text": "IAM temporary credentials using AWS STS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Directory Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito with unauthenticated access enabled.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "IAM with SAML integration",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 12,
          "poolQNum": 106,
          "question": {
            "id": 12,
            "questionText": "A Developer wants to use AWS X-Ray to trace a user request end-to-end throughput the software stack. The Developer made the necessary changes in the application tested it, and found that the application is able to send the traces to AWS X-Ray. However, when the application is deployed to an EC2 instance, the traces are not availableWhich of the following could create this situation? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "The traces are reaching X-Ray, but the Developer does not have access to view the records.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The X-Ray daemon is not installed on the EC2 instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The X-Ray endpoint specified in the application configuration is incorrect.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The instance role does not have `xray:BatchGetTraces` and `xray:GetTraceGraph` permissions.The instance role does not have `xray:PutTraceSegments` and `xray:PutTelemetryRecords` permissions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The instance role does not have `xray:PutTraceSegments` and `xray:PutTelemetryRecords` permissions.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 13,
          "poolQNum": 381,
          "question": {
            "id": 13,
            "questionText": "An existing serverless application processes uploaded image files. The process currently uses a single Lambda function that takes an image file, performs the processing, and stores the file in Amazon S3. Users of the application now require thumbnail generation of the images. Users want to avoid any impact to the time it takes to perform the image uploads. How can thumbnail generation be added to the application, meeting user requirements while minimizing changes to existing code?",
            "questionImage": null,
            "options": [
              {
                "text": "Change the existing Lambda function handling the uploads to create thumbnails at the time of upload. Have the function store both the image and thumbnail in Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a second Lambda function that handles thumbnail generation and storage. Change the existing Lambda function to invoke it asynchronously.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an S3 event notification with a Lambda function destination. Create a new Lambda function to generate and store thumbnails.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an S3 event notification to an SQS Queue. Create a scheduled Lambda function that processes the queue, and generates and stores thumbnails.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 14,
          "poolQNum": 317,
          "question": {
            "id": 14,
            "questionText": "A company has a multi-tiered web application on AWS. During a recent spike in traffic, one of the primary relational databases on Amazon RDS could not serve all the traffic. Some read queries for repeatedly accessed items failed, so users received error messages. What can be done to minimize the impact on database read queries MOST efficiently during future traffic spikes?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon S3 to cache database query results.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon RDS as a custom origin for Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use local storage and memory on Amazon EC2 instances to cache data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache in front of the primary database to cache data.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 15,
          "poolQNum": 329,
          "question": {
            "id": 15,
            "questionText": "A Developer must deploy a new AWS Lambda function using an AWS CloudFormation template. Which procedures will deploy a Lambda function? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Upload the code to an AWS CodeCommit repository, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an `AWS::Lambda::Function` resource in the template, then write the code directly inside the CloudFormation template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload a `.ZIP` file containing the function code to Amazon S3, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload a `.ZIP` file to AWS CloudFormation containing the function code, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload the function code to a private Git repository, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 16,
          "poolQNum": 224,
          "question": {
            "id": 16,
            "questionText": "You have an environment that consists of a public subnet using Amazon VPC and 3 instances that are running in this subnet. These three instances can successfully communicate with other hosts on the Internet. You launch a fourth instance in the same subnet, using the same AMI and security group configuration you used for the others, but find that this instance cannot be accessed from the Internet. What should you do to enable internet access?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy a NAT instance into the public subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the routing table for the public subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure a publically routable IP Address In the host OS of the fourth instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Assign an Elastic IP address to the fourth instance.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 17,
          "poolQNum": 53,
          "question": {
            "id": 17,
            "questionText": "A web application is using Amazon Kinesis Streams for clickstream data that may not be consumed for up to 12 hours. How can the Developer implement encryption at rest for data within the Kinesis Streams?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable SSL connections to Kinesis.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Kinesis Consumer Library.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Encrypt the data once it is at rest with a Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable server-side encryption in Kinesis Streams.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 18,
          "poolQNum": 342,
          "question": {
            "id": 18,
            "questionText": "A company recently migrated its web, application and NoSQL database tiers to AWS. The company is using Auto Scaling to scale the web and application tiers. More than 95 percent of the Amazon DynamoDB requests are repeated read requests. How can the DynamoDB NoSQL tier be scaled up to cache these repeated requests?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon EMR.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon DynamoDB Accelerator.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon SQS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 19,
          "poolQNum": 258,
          "question": {
            "id": 19,
            "questionText": "An Amazon S3 bucket, `myawsbucket` is configured with website hosting in Tokyo region, what is the region-specific website endpoint?",
            "questionImage": null,
            "options": [
              {
                "text": "`www.myawsbucket.ap-northeast-1.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`myawsbucket.s3-website-ap-northeast-1.amazonaws.com`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`myawsbucket.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`myawsbucket.tokyo.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 20,
          "poolQNum": 64,
          "question": {
            "id": 20,
            "questionText": "When writing a Lambda function, what is the benefit of instantiating AWS clients outside the scope of the handler?",
            "questionImage": null,
            "options": [
              {
                "text": "Legibility and stylistic convention.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Taking advantage of connection re-use.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Better error handling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Creating a new instance per invocation.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 21,
          "poolQNum": 287,
          "question": {
            "id": 21,
            "questionText": "An application writes items to an Amazon DynamoDB table. As the application scales to thousands of instances, calls to the DynamoDB API generate occasional `ThrottlingException` errors. The application is coded in a language incompatible with the AWS SDK. How should the error be handled?",
            "questionImage": null,
            "options": [
              {
                "text": "Add exponential backoff to the application logic.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Amazon SQS as an API message bus.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Pass API calls through Amazon API Gateway.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Send the items to DynamoDB through Amazon Kinesis Data Firehose.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 22,
          "poolQNum": 343,
          "question": {
            "id": 22,
            "questionText": "A Development team is working on a case management solution that allows medical claims to be processed and reviewed. Users log in to provide information related to their medical and financial situations. As part of the application, sensitive documents such as medical records, medical imaging, bank statements, and receipts are uploaded to Amazon S3. All documents must be securely transmitted and stored. All access to the documents must be recorded for auditing. What is the MOST secure approach?",
            "questionImage": null,
            "options": [
              {
                "text": "Use S3 default encryption using Advanced Encryption Standard-256 (AES-256) on the destination bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito for authorization and authentication to ensure the security of the application and documents.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Lambda to encrypt and decrypt objects as they are placed into the S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use client-side encryption/decryption with Amazon S3 and AWS KMS.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 23,
          "poolQNum": 157,
          "question": {
            "id": 23,
            "questionText": "An application is experiencing performance issues based on increased demand. This increased demand is on read-only historical records pulled from an Amazon RDS-hosted database with custom views and queries. A Developer must improve performance without changing the database structure. Which approach will improve performance and MINIMIZE management overhead?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy Amazon DynamoDB, move all the data, and point to DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy Amazon ElastiCache for Redis and cache the data for the application.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Deploy Memcached on Amazon EC2 and cache the data for the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy Amazon DynamoDB Accelerator (DAX) on Amazon RDS to improve cache performance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 24,
          "poolQNum": 196,
          "question": {
            "id": 24,
            "questionText": "A Developer has a legacy application that is hosted on-premises. Other applications hosted on AWS depend on the on-premises application for proper functioning. In case of any application errors, the Developer wants to be able to use Amazon CloudWatch to monitor and troubleshoot all applications from one place. How can the Developer accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "Install an AWS SDK on the on-premises server to automatically send logs to CloudWatch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Download the CloudWatch agent to the on-premises server. Configure the agent to use IAM user credentials with permissions for CloudWatch.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload log files from the on-premises server to Amazon S3 and have CloudWatch read the files.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload log files from the on-premises server to an Amazon EC2 instance and have the instance forward the logs to CloudWatch.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 25,
          "poolQNum": 168,
          "question": {
            "id": 25,
            "questionText": "A company provides APIs as a service and commits to a service level agreement (SLA) with all its users. To comply with each SLA, what should the company do?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable throttling limits for each method in Amazon API Gateway.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a usage plan for each user and request API keys to access the APIs.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Enable API rate limiting in Amazon Cognito for each user.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable default throttling limits for each stage after deploying the APIs.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 26,
          "poolQNum": 232,
          "question": {
            "id": 26,
            "questionText": "Which of the following are valid arguments for an SNS Publish request? (Choose THREE)",
            "questionImage": null,
            "options": [
              {
                "text": "TopicArn.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Subject.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Destination.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Format.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Message.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Language.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "2",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 27,
          "poolQNum": 118,
          "question": {
            "id": 27,
            "questionText": "A company has an application where reading objects from Amazon S3 is based on the type of user. The user types are registered user and guest user. The company has 25,000 users and is growing. Information is pulled from an S3 bucket depending on the user type. Which approaches are recommended to provide access to both user types? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Provide a different access key and secret access key in the application code for registered users and guest users to provide read access to the objects.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use S3 bucket policies to restrict read access to specific IAM users.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito to provide access using authenticated and unauthenticated roles.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a new IAM user for each user and grant read access.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS IAM service and let the application assume the different roles using the AWS Security Token Service (AWS STS) `AssumeRole` action depending on the type of user and provide read access to Amazon S3 using the assumed role.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 28,
          "poolQNum": 270,
          "question": {
            "id": 28,
            "questionText": "A Development team wants to instrument their code to provide more detailed information to AWS X-Ray than simple outgoing and incoming requests. This will generate large amounts of data, so the Development team wants to implement indexing so they can filter the data. What should the Development team do to achieve this?",
            "questionImage": null,
            "options": [
              {
                "text": "Add annotations to the segment document and the code.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add metadata to the segment document and the code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure the necessary X-Ray environment variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Install required plugins for the appropriate AWS SDK.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 29,
          "poolQNum": 385,
          "question": {
            "id": 29,
            "questionText": "A Developer has implemented a Lambda function that needs to add new customers to an RDS database that is expected to run hundreds of times per hour. The Lambda function is configured to use 512MB of RAM and is based on the following pseudo code. After testing the Lambda function, the Developer notices that the Lambda execution time is much longer than expected. What should the Developer do to improve performance?",
            "questionImage": "images/question385.jpg",
            "options": [
              {
                "text": "Increase the amount of RAM allocated to the Lambda function, which will increase the number of threads the Lambda can use.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the size of the RDS database to allow for an increased number of database connections each hour.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Move the database connection and close statement out of the handler. Place the connection in the global space.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Replace RDS wit Amazon DynamoDB to implement control over the number of writes per second.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 30,
          "poolQNum": 286,
          "question": {
            "id": 30,
            "questionText": "A company needs to distribute firmware updates to its customers around the world. Which service will allow easy and secure control of the access to the downloads at the lowest cost?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon CloudFront with signed URLs for Amazon S3.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a dedicated Amazon CloudFront Distribution for each customer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudFront with AWS Lambda@Edge.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon API Gateway and AWS Lambda to control access to an S3 bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 31,
          "poolQNum": 54,
          "question": {
            "id": 31,
            "questionText": "A Developer is creating a mobile application with a limited budget. The solution requires a scalable service that will enable customers to sign up and authenticate into the mobile application while using the organization's current SAML 2.0 identity provider. Which AWS service should be used to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS IAM.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon EC2.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 32,
          "poolQNum": 210,
          "question": {
            "id": 32,
            "questionText": "A company wants to implement authentication for its new REST service using Amazon API Gateway. To authenticate the calls, each request must include HTTP headers with a client ID and user ID. These credentials must be compared to authentication data in an Amazon DynamoDB table. What MUST the company do to implement this authentication in API Gateway?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement an AWS Lambda authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a model that requires the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the integration requests to require the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement an Amazon Cognito authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 33,
          "poolQNum": 206,
          "question": {
            "id": 33,
            "questionText": "A Developer is going to deploy an AWS Lambda function that requires significant CPU utilization. Which approach will MINIMIZE the average runtime of the function?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy the function into multiple AWS Regions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the function into multiple Availability Zones.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the function using Lambda layers.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the function with its memory allocation set to the maximum amount.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 34,
          "poolQNum": 155,
          "question": {
            "id": 34,
            "questionText": "A Developer is writing an application that runs on Amazon EC2 instances in an Auto Scaling group. The application data is stored in an Amazon DynamoDB table and records are constantly updated by all instances. An instance sometimes retrieves old data. The Developer wants to correct this by making sure the reads are strongly consistent. How can the Developer accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "Set `ConsistentRead` to `true` when calling `GetItem`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a new DynamoDB Accelerator (DAX) table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set Consistency to strong when calling `UpdateTable`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `GetShardIterator` command.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 35,
          "poolQNum": 162,
          "question": {
            "id": 35,
            "questionText": "A Company runs continuous integration/continuous delivery (CI/CD) pipelines for its application on AWS CodePipeline. A Developer must write unit tests and run them as part of the pipelines before staging the artifacts for testing. How should the Developer incorporate unit tests as part of CI/CD pipelines?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a separate CodePipeline pipeline to run unit tests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the AWS CodeBuild specification to include a phase for running unit tests.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install the AWS CodeDeploy agent on an Amazon EC2 instance to run unit tests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a testing branch in AWS CodeCommit to run unit tests.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 36,
          "poolQNum": 213,
          "question": {
            "id": 36,
            "questionText": "When developing an AWS Lambda function that processes Amazon Kinesis Data Streams, Administrators within the company must receive a notice that includes the processed data. How should the Developer write the function to send processed data to the Administrators?",
            "questionImage": null,
            "options": [
              {
                "text": "Separate the Lambda handler from the core logic.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudWatch Events to send the processed data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Publish the processed data to an Amazon SNS topic.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Push the processed data to Amazon SQS.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 37,
          "poolQNum": 344,
          "question": {
            "id": 37,
            "questionText": "A company has an internet-facing application that uses Web Identity Federation to obtain a temporary credential from AWS Security Token Service (AWS STS). The app then uses the token to access AWS services. Review the following response: Based on the response displayed what permissions are associated with the call from the application?",
            "questionImage": "images/question344.jpg",
            "options": [
              {
                "text": "Permissions associated with the role `AROACLKWSDQRAOEXAMPLE:app1`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Permissions associated with the default role used when the AWS service was built.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Permission associated with the IAM principal that owns the `AccessKeyID` `ASgeIAIOSFODNN7EXAMPLE`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Permissions associated with the account that owns the AWS service.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 38,
          "poolQNum": 125,
          "question": {
            "id": 38,
            "questionText": "An application running on Amazon EC2 opens connections to an Amazon RDS SQL Server database. The developer does not want to store the user name and password for the database in the code. The developer would also like to automatically rotate the credentials. What is the MOST secure way to store and access the database credentials?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM role that has permissions to access the database. Attach the role to the EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Secrets Manager to store the credentials. Retrieve the credentials from Secrets Manager as needed.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the credentials in an encrypted text file in an Amazon S3 bucket. Configure the EC2 instance's user data to download the credentials from Amazon S3 as the instance boots.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the user name and password credentials directly in the source code. No further action is needed because the source code is stored in a private repository.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 39,
          "poolQNum": 159,
          "question": {
            "id": 39,
            "questionText": "A company wants to containerize an existing three-tier web application and deploy it to Amazon ECS Fargate. The application is using session data to keep track of user activities. Which approach would provide the BEST user experience?",
            "questionImage": null,
            "options": [
              {
                "text": "Provision a Redis cluster in Amazon ElastiCache and save the session data in the cluster.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a session table in Amazon Redshift and save the session data in the database table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable session stickiness in the existing Network Load Balancer and manage the session data in the container.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon S3 bucket as data store and save the session data in the bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 40,
          "poolQNum": 313,
          "question": {
            "id": 40,
            "questionText": "In a multi-container Docker environment in AWS Elastic Beanstalk, what is required to configure container instances in the environment?",
            "questionImage": null,
            "options": [
              {
                "text": "An Amazon ECS task definition.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An Amazon ECS cluster.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A Dockerfile in an application package.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A CLI for Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 41,
          "poolQNum": 120,
          "question": {
            "id": 41,
            "questionText": "A company has developed a new serverless application using AWS Lambda functions that will be deployed using the AWS Serverless Application Model (AWS SAM) CLI. Which step should the developer complete prior to deploying the application?",
            "questionImage": null,
            "options": [
              {
                "text": "Compress the application to a `.zip` file and upload it into AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Test the new AWS Lambda function by first tracing it in AWS X-Ray.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Bundle the serverless application using a SAM package.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create the application environment using the `eb create my-env` command.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 42,
          "poolQNum": 276,
          "question": {
            "id": 42,
            "questionText": "An Amazon DynamoDB table uses a Global Secondary Index (GSI) to support read queries. The primary table is write-heavy, whereas the GSI is used for read operations. Looking at Amazon CloudWatch metrics, the Developer notices that write operations to the primary table are throttled frequently under heavy write activity. However, write capacity units to the primary table are available and not fully consumed. Why is the table being throttled?",
            "questionImage": null,
            "options": [
              {
                "text": "The GSI write capacity units are underprovisioned.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "There are not enough read capacity units on the primary table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon DynamoDB Streams is not enabled on the table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A large write operation is being performed against another table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 43,
          "poolQNum": 305,
          "question": {
            "id": 43,
            "questionText": "A company has an application that logs all information to Amazon S3. Whenever there is a new log file, an AWS Lambda function is invoked to process the log files. The code works, gathering all of the necessary information. However, when checking the Lambda function logs, duplicate entries with the same request ID are found. What is causing the duplicate entries?",
            "questionImage": null,
            "options": [
              {
                "text": "The S3 bucket name was specified incorrectly.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The Lambda function failed, and the Lambda service retired the invocation with a delay.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "There was an S3 outage, which caused duplicate entries of the sale log file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The application stopped intermittently and then resumed.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 44,
          "poolQNum": 99,
          "question": {
            "id": 44,
            "questionText": "A Developer executed a AWS CLI command and received the error shown below. What action should the Developer perform to make this error human-readable?",
            "questionImage": "images/question99.jpg",
            "options": [
              {
                "text": "Make a call to AWS KMS to decode the message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS STS `decode-authorization-message` API to decode the message.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use an open source decoding library to decode the message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS IAM `decode-authorization-message` API to decode this message.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 45,
          "poolQNum": 80,
          "question": {
            "id": 45,
            "questionText": "An organization must store thousands of sensitive audio and video files in an Amazon S3 bucket. Organizational security policies require that all data written to this bucket be encrypted. How can compliance with this policy be ensured?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS Lambda to send notifications to the security team if unencrypted objects are put in the bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure an Amazon S3 bucket policy to prevent the upload of objects that do not contain the `x-amz-server-side-encryption` header.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an Amazon CloudWatch event rule to verify that all objects stored in the Amazon S3 bucket are encrypted.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure an Amazon S3 bucket policy to prevent the upload of objects that contain the `x-amz-serverside-encryption` header.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 46,
          "poolQNum": 140,
          "question": {
            "id": 46,
            "questionText": "A development team uses AWS Elastic Beanstalk for application deployment. The team has configured the application version lifecycle policy to limit the number of application versions to 25. However, even with the lifecycle policy, the source bundle is deleted from the Amazon S3 source bucket. What should a developer do in the Elastic Beanstalk application version lifecycle settings to retain the source code in the S3 bucket?",
            "questionImage": null,
            "options": [
              {
                "text": "Change the Set the application versions limit by total count setting to zero.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disable the Lifecycle policy setting.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the Set the application version limit by age setting to zero.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set Retention to Retain source bundle in S3.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 47,
          "poolQNum": 180,
          "question": {
            "id": 47,
            "questionText": "A Developer is building an application that needs to store data in Amazon S3. Management requires that the data be encrypted before it is sent to Amazon S3 for storage. The encryption keys need to be managed by the Security team. Which approach should the Developer take to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement server-side encryption using customer-provided encryption keys (SSE-C).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement server-side encryption by using a client-side master key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement client-side encryption using an AWS KMS managed customer master key (CMK).",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Implement client-side encryption using Amazon S3 managed keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 48,
          "poolQNum": 85,
          "question": {
            "id": 48,
            "questionText": "A Developer needs to use AWS X-Ray to monitor an application that is deployed on EC2 instances. What steps have to be executed to perform the monitoring?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy the X-Ray SDK with the application and use X-Ray annotation.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Install the X-Ray daemon and instrument the application code.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install the X-Ray daemon and configure it to forward data to Amazon CloudWatch Events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the X-Ray SDK with the application and instrument the application code.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 49,
          "poolQNum": 236,
          "question": {
            "id": 49,
            "questionText": "In AWS, which security aspects are the customer's responsibility? (Choose FOUR)",
            "questionImage": null,
            "options": [
              {
                "text": "Life-cycle management of IAM credentials.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Decommissioning storage devices.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Security Group and ACL (Access Control List) settings.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Encryption of EBS (Elastic Block Storage) volumes.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Controlling physical access to compute resources.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Patch management on the EC2 instance's operating system.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3",
            "4",
            "6"
          ],
          "isCorrect": false
        },
        {
          "qNum": 50,
          "poolQNum": 25,
          "question": {
            "id": 50,
            "questionText": "Queries to an Amazon DynamoDB table are consuming a large amount of read capacity. The table has a significant number of large attributes. The application does not need all of the attribute data. How can DynamoDB costs be minimized while maximizing application performance?",
            "questionImage": null,
            "options": [
              {
                "text": "Batch all the writes, and perform the write operations when no or few reads are being performed.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a global secondary index with a minimum set of projected attributes.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Implement exponential backoffs in the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Load balance the reads to the table using an Application Load Balancer.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 51,
          "poolQNum": 220,
          "question": {
            "id": 51,
            "questionText": "You attempt to store an object in the `US-STANDARD` region in Amazon S3, and receive a confirmation that it has been successfully stored. You then immediately make another API call and attempt to read this object. S3 tells you that the object does not exist. What could explain this behavior?",
            "questionImage": null,
            "options": [
              {
                "text": "`US-STANDARD` uses eventual consistency and it can take time for an object to be readable in a bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Objects in Amazon S3 do not become visible until they are replicated to a second region.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`US-STANDARD` imposes a 1 second delay before new objects are readable.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "ou exceeded the bucket object limit, and once this limit is raised the object will be visible.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 52,
          "poolQNum": 123,
          "question": {
            "id": 52,
            "questionText": "A development team wants to run their container workloads on Amazon ECS. Each application container needs to share data with another container to collect logs and metrics. What should the developer team do to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Create two pod specifications. Make one to include the application container and the other to include the other container. Link the two pods together.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create two task definitions. Make one to include the application container and the other to include the other container. Mount a shared volume between the two tasks.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create one task definition. Specify both containers in the definition. Mount a shared volume between those two containers.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a single pod specification. Include both containers in the specification. Mount a persistent volume to both containers.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 53,
          "poolQNum": 238,
          "question": {
            "id": 53,
            "questionText": "How can you secure data at rest on an EBS volume?",
            "questionImage": null,
            "options": [
              {
                "text": "Attach the volume to an instance using EC2's SSL interface.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write the data randomly instead of sequentially.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an encrypted file system on top of the EBS volume.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Encrypt the volume using the S3 server-side encryption service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM policy that restricts read and write access to the volume.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 54,
          "poolQNum": 36,
          "question": {
            "id": 54,
            "questionText": "A supplier is writing a new RESTful API for customers to query the status of orders. The customers requested the following API endpoint `http://www.supplierdomain.com/status/customerID`. Which of the following application designs meet the requirements? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon SQS; Amazon SNS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Elastic Load Balancing; Amazon EC2.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon ElastiCache; Amazon Elacticsearch Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon API Gateway; AWS Lambda.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3; Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 55,
          "poolQNum": 42,
          "question": {
            "id": 55,
            "questionText": "An AWS Lambda function accesses two Amazon DynamoDB tables. A developer wants to improve the performance of the Lambda function by identifying bottlenecks in the function. How can the developer inspect the timing of the DynamoDB API calls?",
            "questionImage": null,
            "options": [
              {
                "text": "Add DynamoDB as an event source to the Lambda function. View the performance with Amazon CloudWatch metrics.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Place an Application Load Balancer (ALB) in front of the two DynamoDB tables. Inspect the ALB logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Limit Lambda to no more than five concurrent invocations Monitor from the Lambda console.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable AWS X-Ray tracing for the function. View the traces from the X-Ray service.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 56,
          "poolQNum": 230,
          "question": {
            "id": 56,
            "questionText": "Which features can be used to restrict access to data in S3? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Use S3 Virtual Hosting.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set an S3 Bucket policy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Enable IAM Identity Federation.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set an S3 ACL on the bucket or the object.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a CloudFront distribution for the bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 57,
          "poolQNum": 340,
          "question": {
            "id": 57,
            "questionText": "What does an Amazon SQS delay queue accomplish?",
            "questionImage": null,
            "options": [
              {
                "text": "Messages are hidden for a configurable amount of time when they are first added to the queue.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Messages are hidden for a configurable amount of time after they are consumed from the queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The consumer can poll the queue for a configurable amount of time before retrieving a message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Message cannot be deleted for a configurable amount of time after they are consumed from the queue.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 58,
          "poolQNum": 29,
          "question": {
            "id": 58,
            "questionText": "A developer needs to deploy a new version to an AWS Elastic Beanstalk application. How can the developer accomplish this task?",
            "questionImage": null,
            "options": [
              {
                "text": "Upload and deploy the new application version in the Elastic Beanstalk console.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use the eb init CLI command to deploy a new version.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Terminate the current Elastic Beanstalk environment and create a new one.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the ebextensions folder to add a source option to services.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 59,
          "poolQNum": 266,
          "question": {
            "id": 59,
            "questionText": "Which of the following statements about SQS is true?",
            "questionImage": null,
            "options": [
              {
                "text": "Messages will be delivered exactly once and messages will be delivered in First in, First out order.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered exactly once and message delivery order is indeterminate.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered one or more times and messages will be delivered in First in, First out order.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered one or more times and message delivery order is indeterminate.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 60,
          "poolQNum": 167,
          "question": {
            "id": 60,
            "questionText": "A Developer registered an AWS Lambda function as a target for an Application Load Balancer (ALB) using a CLI command. However, the Lambda function is not being invoked when the client sends requests through the ALB. Why is the Lambda function not being invoked?",
            "questionImage": null,
            "options": [
              {
                "text": "A Lambda function cannot be registered as a target for an ALB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A Lambda function can be registered with an ALB using AWS Management Console only.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The permissions to invoke the Lambda function are missing.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Cross-zone is not enabled on the ALB.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 61,
          "poolQNum": 301,
          "question": {
            "id": 61,
            "questionText": "A company maintains a REST service using Amazon API Gateway and the API Gateway native API key validation. The company recently launched a new registration page, which allows users to sign up for the service. The registration page creates a new API key using `CreateApiKey` and sends the new key to the user. When the user attempts to call the API using this key, the user receives a `403 Forbidden` error. Existing users are unaffected and can still call the API. What code updates will grant these new users access to the API?",
            "questionImage": null,
            "options": [
              {
                "text": "The `createDeployment` method must be called so the API can be redeployed to include the newly created API key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The `updateAuthorizer` method must be called to update the API's authorizer to include the newly created API key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The `importApiKeys` method must be called to import all newly created API keys into the current stage of the API.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The `createUsagePlanKey` method must be called to associate the newly created API key with the correct usage plan.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 62,
          "poolQNum": 308,
          "question": {
            "id": 62,
            "questionText": "A Development team has pushed out 10 applications running on several Amazon EC2 instances. The Operations team is asking for a graphical representation of one key performance metric for each application. These metrics should be available on one screen for easy monitoring. Which steps should the Developer take to accomplish this using Amazon CloudWatch?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a custom namespace with a unique metric name for each application.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a custom dimension with a unique metric name for each application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a custom event with a unique metric name for each application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a custom alarm with a unique metric name for each application.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 63,
          "poolQNum": 328,
          "question": {
            "id": 63,
            "questionText": "A Developer has published an update to an application that is served to a global user base using Amazon CloudFront. After deploying the application, users are not able to see the updated changes. How can the Developer resolve this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Remove the origin from the CloudFront configuration and add it again.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disable forwarding of query strings and request headers from the CloudFront distribution configuration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Invalidate all the application objects from the edge caches.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Disable the CloudFront distribution and enable it again to update all the edge locations.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 64,
          "poolQNum": 59,
          "question": {
            "id": 64,
            "questionText": "Given the source code for an AWS Lambda function in the local `store.py` containing a handler function called `get_store` and the following AWS CloudFormation template. What should be done to prepare the template so that it can be deployed using the AWS CLI command `aws cloudformation deploy`?",
            "questionImage": "images/question59.jpg",
            "options": [
              {
                "text": "Use AWS CloudFormation compile to base64 encode and embed the source file into a modified CloudFormation template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CloudFormation package to upload the source code to an Amazon S3 bucket and produce a modified CloudFormation template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS Lambda zip to package the source file together with the CloudFormation template and deploy the resulting zip archive.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Serverless `create-package` to embed the source file directly into the existing CloudFormation template.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 65,
          "poolQNum": 70,
          "question": {
            "id": 65,
            "questionText": "An application is real-time processing millions of events that are received through an API. What service could be used to allow multiple consumers to process the data concurrently and MOST cost-effectively?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon SNS with fanout to an SQS queue for each application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SNS with fanout to an SQS FIFO (first-in, first-out) queue for each application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Kinesis Firehose.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Kinesis Streams.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        }
      ],
      "questionMap": {
        "1": 63,
        "2": 333,
        "3": 334,
        "4": 248,
        "5": 11,
        "6": 131,
        "7": 267,
        "8": 247,
        "9": 311,
        "10": 257,
        "11": 58,
        "12": 106,
        "13": 381,
        "14": 317,
        "15": 329,
        "16": 224,
        "17": 53,
        "18": 342,
        "19": 258,
        "20": 64,
        "21": 287,
        "22": 343,
        "23": 157,
        "24": 196,
        "25": 168,
        "26": 232,
        "27": 118,
        "28": 270,
        "29": 385,
        "30": 286,
        "31": 54,
        "32": 210,
        "33": 206,
        "34": 155,
        "35": 162,
        "36": 213,
        "37": 344,
        "38": 125,
        "39": 159,
        "40": 313,
        "41": 120,
        "42": 276,
        "43": 305,
        "44": 99,
        "45": 80,
        "46": 140,
        "47": 180,
        "48": 85,
        "49": 236,
        "50": 25,
        "51": 220,
        "52": 123,
        "53": 238,
        "54": 36,
        "55": 42,
        "56": 230,
        "57": 340,
        "58": 29,
        "59": 266,
        "60": 167,
        "61": 301,
        "62": 308,
        "63": 328,
        "64": 59,
        "65": 70
      }
    },
    {
      "id": "1763095697785",
      "timestamp": 1763095697785,
      "score": "1.54",
      "results": [
        {
          "qNum": 1,
          "poolQNum": 386,
          "question": {
            "id": 1,
            "questionText": "A static website is hosted in an Amazon S3 bucket. Several HTML pages on the site use JavaScript to download images from another Amazon S3 bucket. These images are not displayed when users browse the site. What is the possible cause for the issue?",
            "questionImage": null,
            "options": [
              {
                "text": "The referenced Amazon S3 bucket is in another region.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The images must be stored in the same Amazon S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Port 80 must be opened on the security group in which the Amazon S3 bucket is located.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Cross Origin Resource Sharing must be enabled on the Amazon S3 bucket.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 2,
          "poolQNum": 337,
          "question": {
            "id": 2,
            "questionText": "A company is building an application to track athlete performance using an Amazon DynamoDB table. Each item in the table is identified by a partition key (`user_id`) and a sort key (`sport_name`). The table design is shown below. (Note: Not all table attributes are shown) A Developer is asked to write a leaderboard application to display the top performers (`user_id`) based on the score for each `sport_name`. What process will allow the Developer to extract results MOST efficiently from the DynamoDB table?",
            "questionImage": "images/question337.jpg",
            "options": [
              {
                "text": "Use a DynamoDB query operation with the key attributes of `user_id` and `sport_name` and order the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a global secondary index with a partition key of `sport_name` and a sort key of score, and get the results.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use a DynamoDB scan operation to retrieve scores and `user_id` based on `sport_name`, and order the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a local secondary index with a primary key of `sport_name` and a sort key of score and get the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 3,
          "poolQNum": 5,
          "question": {
            "id": 3,
            "questionText": "A Developer wants to upload data to Amazon S3 and must encrypt the data in transit. Which of the following solutions will accomplish this task? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Set up hardware VPN tunnels to a VPC and access S3 through a VPC endpoint.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set up Client-Side Encryption with an AWS KMS-Managed Customer Master Key.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set up Server-Side Encryption with AWS KMS-Managed Keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Transfer the data over an SSL connection.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set up Server-Side Encryption with S3-Managed Keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 4,
          "poolQNum": 45,
          "question": {
            "id": 4,
            "questionText": "An application is running on an EC2 instance. The Developer wants to store an application metric in Amazon CloudWatch. What is the best practice for implementing this requirement?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the PUT Object API call to send data to an S3 bucket. Use an event notification to invoke a Lambda function to publish data to CloudWatch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Publish the metric data to an Amazon Kinesis Stream using a `PutRecord` API call. Subscribe a Lambda function that publishes data to CloudWatch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the CloudWatch `PutMetricData` API call to submit a custom metric to CloudWatch. Provide the required credentials to enable the API call.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the CloudWatch `PutMetricData` API call to submit a custom metric to CloudWatch. Launch the EC2 instance with the required IAM role to enable the API call.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 5,
          "poolQNum": 275,
          "question": {
            "id": 5,
            "questionText": "A Developer is building a three-tier web application that should be able to handle a minimum of 5000 requests per minute. Requirements state that the web tier should be completely stateless while the application maintains session state for the users. How can session data be externalized, keeping latency at the LOWEST possible value?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an Amazon RDS instance, then implement session handling at the application level to leverage a database inside the RDS database instance for session data storage.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement a shared file system solution across the underlying Amazon EC2 instances, then implement session handling at the application level to leverage the shared file system for session data storage.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon ElastiCache Memcached cluster, then implement session handling at the application level to leverage the cluster for session data storage.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an Amazon DynamoDB table, then implement session handling at the application level to leverage the table for session data storage.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 6,
          "poolQNum": 321,
          "question": {
            "id": 6,
            "questionText": "A Developer writes an AWS Lambda function and uploads the code in a `.ZIP` file to Amazon S3. The Developer makes changes to the code and uploads a new `.ZIP` file to Amazon S3. However, Lambda executes the earlier code. How can the Developer fix this in the LEAST disruptive way?",
            "questionImage": null,
            "options": [
              {
                "text": "Create another Lambda function and specify the new `.ZIP` file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Call the `update-function-code` API.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Remove the earlier `.ZIP` file first, then add the new `.ZIP` file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Call the `create-alias` API.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 7,
          "poolQNum": 133,
          "question": {
            "id": 7,
            "questionText": "A developer is creating a script to automate the deployment process for a serverless application. The developer wants to use an existing AWS Serverless Application Model (AWS SAM) template for the application. What should the developer use for the project? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Call `aws cloudformation package` to create the deployment package. Call `aws cloudformation deploy` to deploy the package afterward.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Call `sam package` to create the deployment package. Call `sam deploy` to deploy the package afterward.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Call `aws s3 cp` to upload the AWS SAM template to Amazon S3. Call `aws lambda update-function-code` to create the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a `ZIP` package locally and call `aws serverlessrepo create-application` to create the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a `ZIP` package and upload it to Amazon S3. Call `aws cloudformation create-stack` to create the application.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 8,
          "poolQNum": 329,
          "question": {
            "id": 8,
            "questionText": "A Developer must deploy a new AWS Lambda function using an AWS CloudFormation template. Which procedures will deploy a Lambda function? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Upload the code to an AWS CodeCommit repository, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an `AWS::Lambda::Function` resource in the template, then write the code directly inside the CloudFormation template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload a `.ZIP` file containing the function code to Amazon S3, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload a `.ZIP` file to AWS CloudFormation containing the function code, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload the function code to a private Git repository, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 9,
          "poolQNum": 278,
          "question": {
            "id": 9,
            "questionText": "A Developer has been asked to create an AWS Lambda function that is triggered any time updates are made to items in an Amazon DynamoDB table. The function has been created, and appropriate permissions have been added to the Lambda execution role. Amazon DynamoDB streams have been enabled for the table, but the function is still not being triggered. Which option would enable DynamoDB table updates to trigger the Lambda function?",
            "questionImage": null,
            "options": [
              {
                "text": "Change the `StreamViewType` parameter value to `NEW_AND_OLD_IMAGES` for the DynamoDB table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure event source mapping for the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Map an Amazon SNS topic to the DynamoDB streams.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the maximum execution time (timeout) setting of the Lambda function.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 10,
          "poolQNum": 210,
          "question": {
            "id": 10,
            "questionText": "A company wants to implement authentication for its new REST service using Amazon API Gateway. To authenticate the calls, each request must include HTTP headers with a client ID and user ID. These credentials must be compared to authentication data in an Amazon DynamoDB table. What MUST the company do to implement this authentication in API Gateway?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement an AWS Lambda authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a model that requires the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the integration requests to require the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement an Amazon Cognito authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 11,
          "poolQNum": 71,
          "question": {
            "id": 11,
            "questionText": "Where should the `appspec.yml` file be placed in order for AWS CodeDeploy to work?",
            "questionImage": null,
            "options": [
              {
                "text": "In the root of the application source code directory structure.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "In the `bin` folder along with all the complied code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In an S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the same folder as the application configuration files.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 12,
          "poolQNum": 92,
          "question": {
            "id": 12,
            "questionText": "An application takes 40 seconds to process instructions received in an Amazon SQS message. Assuming the SQS queue is configured with the default `VisibilityTimeout` value, what is the BEST way, upon receiving a message, to ensure that no other instances can retrieve a message that has already been processed or is currently being processed?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the `ChangeMessageVisibility` API to increase the `VisibilityTimeout`, then use the `DeleteMessage` API to delete the message.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use the `DeleteMessage` API call to delete the message from the queue, then call `DeleteQueue` API to remove the queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `ChangeMessageVisibility` API to decrease the timeout value, then use the `DeleteMessage` API to delete the message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `DeleteMessageVisibility` API to cancel the `VisibilityTimeout`, then use the `DeleteMessage` API to delete the message.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 13,
          "poolQNum": 308,
          "question": {
            "id": 13,
            "questionText": "A Development team has pushed out 10 applications running on several Amazon EC2 instances. The Operations team is asking for a graphical representation of one key performance metric for each application. These metrics should be available on one screen for easy monitoring. Which steps should the Developer take to accomplish this using Amazon CloudWatch?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a custom namespace with a unique metric name for each application.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a custom dimension with a unique metric name for each application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a custom event with a unique metric name for each application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a custom alarm with a unique metric name for each application.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 14,
          "poolQNum": 255,
          "question": {
            "id": 14,
            "questionText": "A meteorological system monitors 600 temperature gauges, obtaining temperature samples every minute and saving each sample to a DynamoDB table Each sample involves writing 1K of data and the writes are evenly distributed over time. How much write throughput is required for the target table?",
            "questionImage": null,
            "options": [
              {
                "text": "1 write capacity unit.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "10 write capacity units.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "60 write capacity units.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "600 write capacity units.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "3600 write capacity units.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 15,
          "poolQNum": 306,
          "question": {
            "id": 15,
            "questionText": "A company is providing services to many downstream consumers. Each consumer may connect to one or more services. This has resulted in a complex architecture that is difficult to manage and does not scale well. The company needs a single interface to manage these services to consumers. Which AWS service should be used to refactor this architecture?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS X-Ray.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SQS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon API Gateway.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 16,
          "poolQNum": 141,
          "question": {
            "id": 16,
            "questionText": "A developer has built a market application that stores pricing data in Amazon DynamoDB with Amazon ElastiCache in front. The prices of items in the market change frequently. Sellers have begun complaining that, after they update the price of an item, the price does not actually change in the product listing. What could be causing this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "The cache is not being invalidated when the price of the item is changed.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The price of the item is being retrieved using a write-through ElastiCache cluster.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The DynamoDB table was provisioned with insufficient read capacity.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The DynamoDB table was provisioned with insufficient write capacity.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 17,
          "poolQNum": 123,
          "question": {
            "id": 17,
            "questionText": "A development team wants to run their container workloads on Amazon ECS. Each application container needs to share data with another container to collect logs and metrics. What should the developer team do to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Create two pod specifications. Make one to include the application container and the other to include the other container. Link the two pods together.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create two task definitions. Make one to include the application container and the other to include the other container. Mount a shared volume between the two tasks.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create one task definition. Specify both containers in the definition. Mount a shared volume between those two containers.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a single pod specification. Include both containers in the specification. Mount a persistent volume to both containers.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 18,
          "poolQNum": 280,
          "question": {
            "id": 18,
            "questionText": "A company needs to ingest terabytes of data each hour from thousands of sources that are delivered almost continually throughout the day. The volume of messages generated varies over the course of the day. Messages must be delivered in real time for fraud detection and live operational dashboards. Which approach will meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Send the messages to an Amazon SQS queue, then process the messages by using a fleet of Amazon EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the Amazon S3 API to write messages to an S3 bucket, then process the messages by using Amazon Redshift.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Data Pipeline to automate the movement and transformation of data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Kinesis Data Streams with Kinesis Client Library to ingest and deliver messages.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 19,
          "poolQNum": 38,
          "question": {
            "id": 19,
            "questionText": "A website's page load times are gradually increasing as more users access the system at the same time. Analysis indicates that a user profile is being loaded from a database in all the web pages being visited by each user and this is increasing the database load and the page load latency. To address this issue the Developer decides to cache the user profile data. Which caching strategy will address this situation MOST efficiently?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a new Amazon EC2 Instance and run a NoSQL database on it. Cache the profile data within this database using the write-through caching strategy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon ElastiCache cluster to cache the user profile data. Use a cache-aside caching strategy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use a dedicated Amazon RDS instance for caching profile data. Use a write-through caching strategy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an ElastiCache cluster to cache the user profile data. Use a write-through caching strategy.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 20,
          "poolQNum": 362,
          "question": {
            "id": 20,
            "questionText": "A Developer has developed a web application and wants to deploy it quickly on a Tomcat server on AWS. The Developer wants to avoid having to manage the underlying infrastructure. What is the easiest way to deploy the application, based on these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS CloudFormation.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Elastic Beanstalk.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodePipeline",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 21,
          "poolQNum": 160,
          "question": {
            "id": 21,
            "questionText": "An application is using a single-node Amazon ElastiCache for Redis instance to improve read performance. Over time, demand for the application has increased exponentially, which has increased the load on the ElastiCache instance. It is critical that this cache layer handles the load and is resilient in case of node failures. What can the Developer do to address the load and resiliency requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Add a read replica instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Migrate to a Memcached cluster.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Migrate to an Amazon Elasticsearch Service cluster.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Vertically scale the ElastiCache instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 22,
          "poolQNum": 256,
          "question": {
            "id": 22,
            "questionText": "In DynamoDB, what type of HTTP response codes indicate that a problem was found with the client request sent to the service?",
            "questionImage": null,
            "options": [
              {
                "text": "5xx HTTP response code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "200 HTTP response code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "306 HTTP response code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "4xx HTTP response code.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 23,
          "poolQNum": 85,
          "question": {
            "id": 23,
            "questionText": "A Developer needs to use AWS X-Ray to monitor an application that is deployed on EC2 instances. What steps have to be executed to perform the monitoring?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy the X-Ray SDK with the application and use X-Ray annotation.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Install the X-Ray daemon and instrument the application code.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install the X-Ray daemon and configure it to forward data to Amazon CloudWatch Events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the X-Ray SDK with the application and instrument the application code.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 24,
          "poolQNum": 313,
          "question": {
            "id": 24,
            "questionText": "In a multi-container Docker environment in AWS Elastic Beanstalk, what is required to configure container instances in the environment?",
            "questionImage": null,
            "options": [
              {
                "text": "An Amazon ECS task definition.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An Amazon ECS cluster.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A Dockerfile in an application package.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A CLI for Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 25,
          "poolQNum": 24,
          "question": {
            "id": 25,
            "questionText": "A company is running an application built on AWS Lambda functions. One Lambda function has performance issues when it has to download a 50MB file from the Internet in every execution. This function is called multiple times a second. What solution would give the BEST performance increase?",
            "questionImage": null,
            "options": [
              {
                "text": "Cache the file in the `/tmp` directory.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Increase the Lambda maximum execution time.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Put an Elastic Load Balancer in front of the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Cache the file in Amazon S3.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 26,
          "poolQNum": 26,
          "question": {
            "id": 26,
            "questionText": "A Developer is writing a REST service that will add items to a shopping list. The service is built on Amazon API Gateway with AWS Lambda integrations. The shopping list items are send as query string parameters in the method request. How should the Developer convert the query string parameters to arguments for the Lambda function?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable request validation.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Include the Amazon Resource Name (ARN) of the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the integration type.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a mapping template.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 27,
          "poolQNum": 122,
          "question": {
            "id": 27,
            "questionText": "A development team is working on a mobile app that allows users to upload pictures to Amazon S3. The team expects the app will be used by hundreds of thousands of users during a single event simultaneously. Once the pictures are uploaded, the backend service will scan and parse the pictures for inappropriate content. Which approach is the MOST resilient way to achieve this goal, which also smooths out temporary volume spikes for the backend service?",
            "questionImage": null,
            "options": [
              {
                "text": "Develop an AWS Lambda function to check the upload folder in the S3 bucket. If new uploaded pictures are detected, the Lambda function will scan and parse them.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Once a picture is uploaded to Amazon S3, publish the event to an Amazon SQS queue. Use the queue as an event source to trigger an AWS Lambda function. In the Lambda function, scan and parse the picture.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "When the user uploads a picture, invoke an API hosted in Amazon API Gateway. The API will invoke an AWS Lambda function to scan and parse the picture.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a state machine in AWS Step Functions to check the upload folder in the S3 bucket. If a new picture is detected, invoke an AWS Lambda function to scan and parse it.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 28,
          "poolQNum": 98,
          "question": {
            "id": 28,
            "questionText": "For a deployment using AWS CodeDeploy, what is the run order of the hooks for in-place deployments?",
            "questionImage": null,
            "options": [
              {
                "text": "Before Install -> Application Stop -> Application Start -> After Install.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Application Stop -> Before Install -> After Install -> Application Start.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Before Install -> Application Stop -> Validate Service -> Application Start.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Application Stop -> Before Install -> Validate Service -> Application Start.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 29,
          "poolQNum": 317,
          "question": {
            "id": 29,
            "questionText": "A company has a multi-tiered web application on AWS. During a recent spike in traffic, one of the primary relational databases on Amazon RDS could not serve all the traffic. Some read queries for repeatedly accessed items failed, so users received error messages. What can be done to minimize the impact on database read queries MOST efficiently during future traffic spikes?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon S3 to cache database query results.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon RDS as a custom origin for Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use local storage and memory on Amazon EC2 instances to cache data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache in front of the primary database to cache data.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 30,
          "poolQNum": 72,
          "question": {
            "id": 30,
            "questionText": "An application will ingest data at a very high throughput from many sources and must store the data in an Amazon S3 bucket. Which service would BEST accomplish this task?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon Kinesis Firehose.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3 Acceleration Transfer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SQS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SNS.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 31,
          "poolQNum": 28,
          "question": {
            "id": 31,
            "questionText": "How is provisioned throughput affected by the chosen consistency model when reading data from a DynamoDB table?",
            "questionImage": null,
            "options": [
              {
                "text": "Strongly consistent reads use the same amount of throughput as eventually consistent reads.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Strongly consistent reads use more throughput than eventually consistent reads.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Strongly consistent reads use less throughput than eventually consistent reads.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Strongly consistent reads use variable throughput depending on read activity.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 32,
          "poolQNum": 296,
          "question": {
            "id": 32,
            "questionText": "A company is migrating a single-server, on-premises web application to AWS. The company intends to use multiple servers behind an Elastic Load Balancer (ELB) to balance the load, and will also store session data in memory on the web server. The company does not want to lose that session data if a server fails or goes offline, and it wants to minimize user's downtime. Where should the company move session data to MOST effectively reduce downtime and make users' session data more fault tolerant?",
            "questionImage": null,
            "options": [
              {
                "text": "An Amazon ElastiCache for Redis cluster.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "A second Amazon EBS volume.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The web server's primary disk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An Amazon EC2 instance dedicated to session data.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 33,
          "poolQNum": 326,
          "question": {
            "id": 33,
            "questionText": "An AWS Elastic Beanstalk application needs to be deployed in multiple regions and requires a different Amazon Machine Image (AMI) in each region. Which AWS CloudFormation template key can be used to specify the correct AMI for each region?",
            "questionImage": null,
            "options": [
              {
                "text": "`Parameters`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`Outputs`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`Mappings`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`Resources`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 34,
          "poolQNum": 320,
          "question": {
            "id": 34,
            "questionText": "A company is developing an application that will run on several Amazon EC2 instances in an Auto Scaling group and can access a database running on Amazon EC2. The application needs to store secrets required to connect to the database. The application must allow for periodic secret rotation, and there should be no changes to the application when a secret changes. What is the SAFEST way to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Associate an IAM role to the EC2 instance where the application is running with permission to access the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Systems Manager Parameter Store with the SecureString data type to store secrets.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure the application to store secrets in Amazon S3 object metadata.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Hard code the database secrets in the application code itself.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 35,
          "poolQNum": 287,
          "question": {
            "id": 35,
            "questionText": "An application writes items to an Amazon DynamoDB table. As the application scales to thousands of instances, calls to the DynamoDB API generate occasional `ThrottlingException` errors. The application is coded in a language incompatible with the AWS SDK. How should the error be handled?",
            "questionImage": null,
            "options": [
              {
                "text": "Add exponential backoff to the application logic.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Amazon SQS as an API message bus.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Pass API calls through Amazon API Gateway.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Send the items to DynamoDB through Amazon Kinesis Data Firehose.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 36,
          "poolQNum": 314,
          "question": {
            "id": 36,
            "questionText": "An application that runs on an Amazon EC2 instance needs to access and make API calls to multiple AWS services. What is the MOST secure way to provide access to the AWS services with MINIMAL management overhead?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS KMS to store and retrieve credentials.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use EC2 instance profiles.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS `root` user to make requests to the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store and retrieve credentials from AWS CodeCommit.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 37,
          "poolQNum": 231,
          "question": {
            "id": 37,
            "questionText": "What happens, by default, when one of the resources in a CloudFormation stack cannot be created?",
            "questionImage": null,
            "options": [
              {
                "text": "Previously-created resources are kept but the stack creation terminates.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Previously-created resources are deleted and the stack creation terminates.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The stack creation continues, and the final results indicate which steps failed.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "CloudFormation templates are parsed in advance so stack creation is guaranteed to succeed.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 38,
          "poolQNum": 331,
          "question": {
            "id": 38,
            "questionText": "A company needs to secure its existing website running behind an Elastic Load Balancer. The website's Amazon EC2 instances are CPU-constrained. What should be done to secure the website while not increasing the CPU load on the EC2 web servers? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Configure an Elastic Load Balancer with SSL pass-through.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure SSL certificates on an Elastic Load Balancer.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure an Elastic Load Balancer with a Loadable Storage System.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Install SSL certificates on the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure an Elastic Load Balancer with SSL termination.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 39,
          "poolQNum": 343,
          "question": {
            "id": 39,
            "questionText": "A Development team is working on a case management solution that allows medical claims to be processed and reviewed. Users log in to provide information related to their medical and financial situations. As part of the application, sensitive documents such as medical records, medical imaging, bank statements, and receipts are uploaded to Amazon S3. All documents must be securely transmitted and stored. All access to the documents must be recorded for auditing. What is the MOST secure approach?",
            "questionImage": null,
            "options": [
              {
                "text": "Use S3 default encryption using Advanced Encryption Standard-256 (AES-256) on the destination bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito for authorization and authentication to ensure the security of the application and documents.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Lambda to encrypt and decrypt objects as they are placed into the S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use client-side encryption/decryption with Amazon S3 and AWS KMS.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 40,
          "poolQNum": 334,
          "question": {
            "id": 40,
            "questionText": "In a move toward using microservices, a company's Management team has asked all Development teams to build their services so that API requests depend only on that service's data store. One team is building a Payments service which has its own database; the service needs data that originates in the Accounts database. Both are using Amazon DynamoDB. What approach will result in the simplest, decoupled, and reliable method to get near-real time updates from the Accounts database?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon Glue to perform frequent ETL updates from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache in Payments, with the cache updated by triggers in the Accounts database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Kinesis Data Firehose to deliver all changes from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon DynamoDB Streams to deliver all changes from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 41,
          "poolQNum": 41,
          "question": {
            "id": 41,
            "questionText": "A company stores all personally identifiable information (PII) in an Amazon DynamoDB table named PII in Account A. An application running on Amazon EC2 instances in Account B requires access to the PII table. An administrators in Account A created an IAM role named AccessPII with privileges to access the PII table, and made account B a trusted entity. Which combination of actional steps should Developers take to access the table? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Allow the EC2 IAM role the permission to assume the AccessPII role.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Allow the EC2 IAM role the permission to access the PII table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Include the AWS API in the application code logic to obtain temporary credentials from the EC2 IAM role to access the PII table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Include the `AssumeRole` API operation in the application code logic to obtain temporary credentials to access the PII table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Include the GetSessionToken API operation in the application code logic to obtain temporary credentials to access the PII table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 42,
          "poolQNum": 282,
          "question": {
            "id": 42,
            "questionText": "An AWS Lambda function must access an external site by using a regularly rotated user name and password. These items must be kept securely and cannot be stored in the function code. What combination of AWS services can be used to accomplish this? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "AWS Certificate Manager (ACM).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Systems Manager Parameter Store.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Trusted Advisor.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS KMS.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon GuardDuty.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 43,
          "poolQNum": 119,
          "question": {
            "id": 43,
            "questionText": "A company has 25,000 employees and is growing. The company is creating an application that will be accessible to its employees only. A developer is using Amazon S3 to store images and Amazon RDS to store application data. The company requires that all employee information remain in the legacy Security Assertion Markup Language (SAML) employee directory only and is not interested in mirroring any employee information on AWS. How can the developer provide authorized access for the employees who will be using this application so each employee can access their own application data only?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon VPC and keep all resources inside the VPC, and use a VPC link for the S3 bucket with the bucket policy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito user pools, federate with the SAML provider, and use user pool groups with an IAM policy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon Cognito identity pool, federate with the SAML provider, and use an IAM condition key with a value for the `cognito-identity.amazonaws.com:sub` variable to grant access to the employees.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a unique IAM role for each employee and have each employee assume the role to access the application so they can access their personal data only.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 44,
          "poolQNum": 335,
          "question": {
            "id": 44,
            "questionText": "A company needs a fully-managed source control service that will work in AWS. The service must ensure that revision control synchronizes multiple distributed repositories by exchanging sets of changes peer-to-peer. All users need to work productively even when not connected to a network. Which source control service should be used?",
            "questionImage": null,
            "options": [
              {
                "text": "Subversion.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeBuild.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeCommit.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS CodeStar.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 45,
          "poolQNum": 264,
          "question": {
            "id": 45,
            "questionText": "You are writing to a DynamoDB table and receive the following exception: `ProvisionedThroughputExceededException`. though according to your Cloudwatch metrics for the table, you are not exceeding your provisioned throughput. What could be an explanation for this?",
            "questionImage": null,
            "options": [
              {
                "text": "You haven't provisioned enough DynamoDB storage instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "You're exceeding your capacity on a particular `Range Key`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "You're exceeding your capacity on a particular `Hash Key`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "You're exceeding your capacity on a particular `Sort Key`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "You haven't configured DynamoDB Auto Scaling triggers.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 46,
          "poolQNum": 349,
          "question": {
            "id": 46,
            "questionText": "A stock market monitoring application uses Amazon Kinesis for data ingestion. During simulated tests of peak data rates, the Kinesis stream cannot keep up with the incoming data. What step will allow Kinesis to accommodate the traffic during peak hours?",
            "questionImage": null,
            "options": [
              {
                "text": "Install the Kinesis Producer Library (KPL) for ingesting data into the stream.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Reduce the data retention period to allow for more data ingestion using `DecreaseStreamRetentionPeriod`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the shard count of the stream using `UpdateShardCount`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Ingest multiple records into the stream in a single call using `PutRecords`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 47,
          "poolQNum": 40,
          "question": {
            "id": 47,
            "questionText": "A developer is writing an AWS Lambda function. The developer wants to log key events that occur during the Lambda function and include a unique identifier to associate the events with a specific function invocation. Which of the following will help the developer accomplish this objective?",
            "questionImage": null,
            "options": [
              {
                "text": "Obtain the request identifier from the Lambda context object. Architect the application to write logs to the console.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Obtain the request identifier from the Lambda event object. Architect the application to write logs to a file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Obtain the request identifier from the Lambda event object. Architect the application to write logs to the console.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Obtain the request identifier from the Lambda context object. Architect the application to write logs to a file.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 48,
          "poolQNum": 145,
          "question": {
            "id": 48,
            "questionText": "A developer converted an existing program to an AWS Lambda function in the console. The program runs properly on a local laptop, but shows an `Unable to import module` error when tested in the Lambda console. Which of the following can fix the error?",
            "questionImage": null,
            "options": [
              {
                "text": "Install the missing module and specify the current directory as the target. Create a `ZIP` file to include all files under the current directory, and upload the `ZIP` file.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install the missing module in a lib directory. Create a `ZIP` file to include all files under the lib directory, and upload the `ZIP` file as dependency file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the Lambda code, invoke a Linux command to install the missing modules under the `/usr/lib directory`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the Lambda console, create a `LB_LIBRARY_PATH` environment and specify the value for the system library plan.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 49,
          "poolQNum": 50,
          "question": {
            "id": 49,
            "questionText": "The release process workflow of an application requires a manual approval before the code is deployed into the production environment. What is the BEST way to achieve this using AWS CodePipeline?",
            "questionImage": null,
            "options": [
              {
                "text": "Use multiple pipelines to allow approval.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an approval action in a stage.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Disable the stage transition to allow manual approval.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disable a stage just prior the deployment stage.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 50,
          "poolQNum": 365,
          "question": {
            "id": 50,
            "questionText": "According to best practice, how should access keys be managed in AWS? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Use the same access key in all applications for consistency.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Delete all access keys for the account `root` user.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Leave unused access keys in the account for tracking purposes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Embed and encrypt access keys in code for continuous deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon IAM roles instead of access keys where possible.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 51,
          "poolQNum": 246,
          "question": {
            "id": 51,
            "questionText": "Company A has an S3 bucket containing premier content that they intend to make available to only paid subscribers of their website. The S3 bucket currently has default permissions of all objects being private to prevent inadvertent exposure of the premier content to non-paying website visitors. How can Company A provide only paid subscribers the ability to download a premier content file in the S3 bucket?",
            "questionImage": null,
            "options": [
              {
                "text": "Apply a bucket policy that grants anonymous users to download the content from the S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Generate a pre-signed object URL for the premier content file when a paid subscriber requests a download.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add a bucket policy that requires Multi-Factor Authentication for requests to access the S3 bucket objects.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable server side encryption on the S3 bucket for data protection against the non-paying website visitors.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 52,
          "poolQNum": 223,
          "question": {
            "id": 52,
            "questionText": "Which of the following are correct statements with policy evaluation logic in AWS Identity and Access Management? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "By default, all requests are denied.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An explicit allow overrides an explicit deny.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An explicit allow overrides default deny.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An explicit deny does not override an explicit allow.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "By default, all request are allowed.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 53,
          "poolQNum": 199,
          "question": {
            "id": 53,
            "questionText": "A Developer is leveraging a Border Gateway Protocol (BGP)-based AWS VPN connection to connect from on-premises to Amazon EC2 instances in the Developer's account. The Developer is able to access an EC2 instance in subnet A, but is unable to access an EC2 instance in subnet B in the same VPC. Which logs can the Developer use to verify whether the traffic is reaching subnet B?",
            "questionImage": null,
            "options": [
              {
                "text": "VPN logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "BGP logs",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "VPC Flow Logs.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS CloudTrail logs.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 54,
          "poolQNum": 284,
          "question": {
            "id": 54,
            "questionText": "A Developer is working on an application that handles 10MB documents that contain highly-sensitive data. The application will use AWS KMS to perform clientside encryption. What steps must be followed?",
            "questionImage": null,
            "options": [
              {
                "text": "Invoke the Encrypt API passing the plaintext data that must be encrypted, then reference the customer managed key ARN in the `KeyId` parameter.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Invoke the `GenerateRandom` API to get a data encryption key, then use the data encryption key to encrypt the data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Invoke the `GenerateDataKey` API to retrieve the encrypted version of the data encryption key to encrypt the data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Invoke the `GenerateDataKey` API to retrieve the plaintext version of the data encryption key to encrypt the data.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 55,
          "poolQNum": 374,
          "question": {
            "id": 55,
            "questionText": "A Developer must trigger an AWS Lambda function based on the item lifecycle activity in an Amazon DynamoDB table. How can the Developer create the solution?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable a DynamoDB stream that publishes an Amazon SNS message. Trigger the Lambda function synchronously from the SNS message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable a DynamoDB stream that publishes an SNS message. Trigger the Lambda function asynchronously from the SNS message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable a DynamoDB stream, and trigger the Lambda function synchronously from the stream.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Enable a DynamoDB stream, and trigger the Lambda function asynchronously from the stream.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 56,
          "poolQNum": 193,
          "question": {
            "id": 56,
            "questionText": "A Software Engineer developed an AWS Lambda function in Node.js to do some CPU-intensive data processing. With the default settings, the Lambda function takes about 5 minutes to complete. Which approach should a Developer take to increase the speed of completion?",
            "questionImage": null,
            "options": [
              {
                "text": "Instead of using Node.js, rewrite the Lambda function using Python.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Instead of packaging the libraries in the `ZIP` file with the function, move them to a Lambda layer and use the layer with the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Allocate the maximum available CPU units to the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the available memory to the function.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 57,
          "poolQNum": 234,
          "question": {
            "id": 57,
            "questionText": "EC2 instances are launched from Amazon Machine images (AMIs). A given public AMI can:",
            "questionImage": null,
            "options": [
              {
                "text": "Be used to launch EC2 Instances in any AWS region.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Only be used to launch EC2 instances in the same country as the AMI is stored.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Only be used to launch EC2 instances in the same AWS region as the AMI is stored.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Only be used to launch EC2 instances in the same AWS availability zone as the AMI is stored.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 58,
          "poolQNum": 93,
          "question": {
            "id": 58,
            "questionText": "A Developer is developing an application that manages financial transactions. To improve security, multi-factor authentication (MFA) will be required as part of the login protocol. What services can the Developer use to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon DynamoDB to store MFA session data, and Amazon SNS to send MFA codes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito with MFA.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Directory Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS IAM with MFA enabled.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 59,
          "poolQNum": 102,
          "question": {
            "id": 59,
            "questionText": "A Developer will be using the AWS CLI on a local development server to manage AWS services. What can be done to ensure that the CLI uses the Developer's IAM permissions when making commands?",
            "questionImage": null,
            "options": [
              {
                "text": "Specify the Developer's IAM access key ID and secret access key as parameters for each CLI command.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Run the `aws configure` CLI command, and provide the Developer's IAM access key ID and secret access key.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Specify the Developer's IAM user name and password as parameters for each CLI command.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the Developer's IAM role when making the CLI command.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 60,
          "poolQNum": 309,
          "question": {
            "id": 60,
            "questionText": "A company is creating an application that will require users to access AWS services and allow them to reset their own passwords. Which of the following would allow the company to manage users and authorization while allowing users to reset their own passwords?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon Cognito identify pools and AWS STS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito identity pools and AWS IAM.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito user pools and AWS KMS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito user pools and identity pools.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 61,
          "poolQNum": 95,
          "question": {
            "id": 61,
            "questionText": "A Developer has created an S3 bucket` s3://mycoolapp` and has enabled server across logging that points to the folder `s3://mycoolapp/logs`. The Developer moved 100 KB of Cascading Style Sheets (CSS) documents to the folder `s3://mycoolapp/css`, and then stopped work. When the developer came back a few days later, the bucket was 50 GB. What is the MOST likely cause of this situation?",
            "questionImage": null,
            "options": [
              {
                "text": "The CSS files were not compressed and S3 versioning was enabled.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "S3 replication was enabled on the bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Logging into the same bucket caused exponential log growth.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An S3 lifecycle policy has moved the entire CSS file to S3 Infrequent Access.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 62,
          "poolQNum": 221,
          "question": {
            "id": 62,
            "questionText": "What is the maximum number of S3 Buckets available per AWS account?",
            "questionImage": null,
            "options": [
              {
                "text": "100 per region.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "there is no limit.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1,000,000 per account.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "500 per account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "100 per IAM user.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 63,
          "poolQNum": 240,
          "question": {
            "id": 63,
            "questionText": "Which of the following statements about SWF are true? (Choose THREE)",
            "questionImage": null,
            "options": [
              {
                "text": "SWF tasks are assigned once and never duplicated.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SWF requires an S3 bucket for workflow storage.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SWF workflow executions can last up to a year.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SWF triggers SNS notifications on task assignment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SWF uses deciders and workers to complete tasks.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SWF requires at least 1 EC2 instance per domain.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 64,
          "poolQNum": 196,
          "question": {
            "id": 64,
            "questionText": "A Developer has a legacy application that is hosted on-premises. Other applications hosted on AWS depend on the on-premises application for proper functioning. In case of any application errors, the Developer wants to be able to use Amazon CloudWatch to monitor and troubleshoot all applications from one place. How can the Developer accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "Install an AWS SDK on the on-premises server to automatically send logs to CloudWatch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Download the CloudWatch agent to the on-premises server. Configure the agent to use IAM user credentials with permissions for CloudWatch.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload log files from the on-premises server to Amazon S3 and have CloudWatch read the files.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload log files from the on-premises server to an Amazon EC2 instance and have the instance forward the logs to CloudWatch.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 65,
          "poolQNum": 217,
          "question": {
            "id": 65,
            "questionText": "A Development team would like to migrate their existing application code from a GitHub repository to AWS CodeCommit. What needs to be created before they can migrate a cloned repository to CodeCommit over HTTPS?",
            "questionImage": null,
            "options": [
              {
                "text": "A GitHub secure authentication token.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A public and private SSH key file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A set of Git credentials generated from IAM.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An Amazon EC2 IAM role with CodeCommit permissions.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        }
      ],
      "questionMap": {
        "1": 386,
        "2": 337,
        "3": 5,
        "4": 45,
        "5": 275,
        "6": 321,
        "7": 133,
        "8": 329,
        "9": 278,
        "10": 210,
        "11": 71,
        "12": 92,
        "13": 308,
        "14": 255,
        "15": 306,
        "16": 141,
        "17": 123,
        "18": 280,
        "19": 38,
        "20": 362,
        "21": 160,
        "22": 256,
        "23": 85,
        "24": 313,
        "25": 24,
        "26": 26,
        "27": 122,
        "28": 98,
        "29": 317,
        "30": 72,
        "31": 28,
        "32": 296,
        "33": 326,
        "34": 320,
        "35": 287,
        "36": 314,
        "37": 231,
        "38": 331,
        "39": 343,
        "40": 334,
        "41": 41,
        "42": 282,
        "43": 119,
        "44": 335,
        "45": 264,
        "46": 349,
        "47": 40,
        "48": 145,
        "49": 50,
        "50": 365,
        "51": 246,
        "52": 223,
        "53": 199,
        "54": 284,
        "55": 374,
        "56": 193,
        "57": 234,
        "58": 93,
        "59": 102,
        "60": 309,
        "61": 95,
        "62": 221,
        "63": 240,
        "64": 196,
        "65": 217
      }
    }
  ]
}