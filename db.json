{
  "history": [
    {
      "id": "1763969933530",
      "timestamp": 1763969933530,
      "score": "0.00",
      "results": [
        {
          "qNum": 1,
          "poolQNum": 152,
          "question": {
            "id": 1,
            "questionText": "A company is using Amazon API Gateway to manage its public-facing API. The CISO requires that the APIs be used by test account users only. What is the MOST secure way to restrict API access to users of this particular AWS account?",
            "questionImage": null,
            "options": [
              {
                "text": "Client-side SSL certificates for authentication.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "API Gateway resource policies.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Cross-origin resource sharing (CORS).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Usage plans.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 2,
          "poolQNum": 225,
          "question": {
            "id": 2,
            "questionText": "If a message is retrieved from a queue in Amazon SQS, how long is the message inaccessible to other users by default?",
            "questionImage": null,
            "options": [
              {
                "text": "0 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1 hour.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1 day.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "forever.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "30 seconds.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 3,
          "poolQNum": 200,
          "question": {
            "id": 3,
            "questionText": "A Developer has created a new AWS IAM user that has `s3:putObject` permission to write to a specific Amazon S3 bucket. This S3 bucket uses server-side encryption with AWS KMS managed keys (SSE-KMS) as the default encryption. Using the access key and secret key of the IAM user, the application received an access denied error when calling the `PutObject` API. How can this issue be resolved?",
            "questionImage": null,
            "options": [
              {
                "text": "Update the policy of the IAM user to allow the `s3:EncryptionConfiguration` action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the bucket policy of the S3 bucket to allow the IAM user to upload objects.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the policy of the IAM user to allow the `kms:GenerateDataKey` action.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Update the ACL of the S3 bucket to allow the IAM user to upload objects.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 4,
          "poolQNum": 153,
          "question": {
            "id": 4,
            "questionText": "A Developer is migrating existing applications to AWS. These applications use MongoDB as their primary data store, and they will be deployed to Amazon EC2 instances. Management requires that the Developer minimize changes to applications while using AWS services. Which solution should the Developer use to host MongoDB in AWS?",
            "questionImage": null,
            "options": [
              {
                "text": "Install MongoDB on the same instance where the application is running.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy Amazon DocumentDB in MongoDB compatibility mode.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Amazon API Gateway to translate API calls from MongoDB to Amazon DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Replicate the existing MongoDB workload to Amazon DynamoDB.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 5,
          "poolQNum": 87,
          "question": {
            "id": 5,
            "questionText": "A Developer is working on an application that tracks hundreds of millions of product reviews in an Amazon DynamoDB table. The records include the data elements shown in the table. Which field, when used as the partition key, would result in the MOST consistent performance using DynamoDB?",
            "questionImage": "images/question87.jpg",
            "options": [
              {
                "text": "`starRating`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`reviewID`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`comment`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`productID`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 6,
          "poolQNum": 234,
          "question": {
            "id": 6,
            "questionText": "EC2 instances are launched from Amazon Machine images (AMIs). A given public AMI can:",
            "questionImage": null,
            "options": [
              {
                "text": "Be used to launch EC2 Instances in any AWS region.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Only be used to launch EC2 instances in the same country as the AMI is stored.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Only be used to launch EC2 instances in the same AWS region as the AMI is stored.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Only be used to launch EC2 instances in the same AWS availability zone as the AMI is stored.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 7,
          "poolQNum": 261,
          "question": {
            "id": 7,
            "questionText": "You run an ad-supported photo sharing website using S3 to serve photos to visitors of your site. At some point you find out that other sites have been linking to the photos on your site, causing loss to your business. What is an effective method to mitigate this?",
            "questionImage": null,
            "options": [
              {
                "text": "Store photos on an EBS volume of the web server.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Remove public read access and use signed URLs with expiry dates.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use CloudFront distributions for static content.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Block the IPs of the offending websites in Security Groups.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 8,
          "poolQNum": 137,
          "question": {
            "id": 8,
            "questionText": "A developer added a new feature to an application running on an Amazon EC2 instance that uses Amazon SQS. After deployment, the developer noticed a significant increase in Amazon SQS costs. When monitoring the Amazon SQS metrics on Amazon CloudWatch, the developer found that on average one message per minute is posted on this queue. What can be done to reduce Amazon SQS costs for this application?",
            "questionImage": null,
            "options": [
              {
                "text": "Increase the Amazon SQS queue polling timeout.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Scale down the Amazon SQS queue to the appropriate size for low traffic demand.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure push delivery via Amazon SNS instead of polling the Amazon SQS queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon SQS first-in, first-out (FIFO) queue instead of a standard queue.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 9,
          "poolQNum": 326,
          "question": {
            "id": 9,
            "questionText": "An AWS Elastic Beanstalk application needs to be deployed in multiple regions and requires a different Amazon Machine Image (AMI) in each region. Which AWS CloudFormation template key can be used to specify the correct AMI for each region?",
            "questionImage": null,
            "options": [
              {
                "text": "`Parameters`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`Outputs`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`Mappings`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`Resources`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 10,
          "poolQNum": 343,
          "question": {
            "id": 10,
            "questionText": "A Development team is working on a case management solution that allows medical claims to be processed and reviewed. Users log in to provide information related to their medical and financial situations. As part of the application, sensitive documents such as medical records, medical imaging, bank statements, and receipts are uploaded to Amazon S3. All documents must be securely transmitted and stored. All access to the documents must be recorded for auditing. What is the MOST secure approach?",
            "questionImage": null,
            "options": [
              {
                "text": "Use S3 default encryption using Advanced Encryption Standard-256 (AES-256) on the destination bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito for authorization and authentication to ensure the security of the application and documents.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Lambda to encrypt and decrypt objects as they are placed into the S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use client-side encryption/decryption with Amazon S3 and AWS KMS.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 11,
          "poolQNum": 108,
          "question": {
            "id": 11,
            "questionText": "What are the steps to using the AWS CLI to launch a templatized serverless application?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS CloudFormation get-template then CloudFormation execute-change-set.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CloudFormation validate-template then CloudFormation create-change-set.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CloudFormation package then CloudFormation deploy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS CloudFormation create-stack then CloudFormation update-stack.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 12,
          "poolQNum": 271,
          "question": {
            "id": 12,
            "questionText": "A team of Developers must migrate an application running inside an AWS Elastic Beanstalk environment from a Classic Load Balancer to an Application Load Balancer. Which steps should be taken to accomplish the task using the AWS Management Console?",
            "questionImage": null,
            "options": [
              {
                "text": "1. Update the application code in the existing deployment. 2. Select a new load balancer type before running the deployment. 3. Deploy the new version of the application code to the environment.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "1. Create a new environment with the same configurations except for the load balancer type. 2. Deploy the same application version as used in the original environment. 3. Run the `swap-environment-cnames` action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1. Clone the existing environment, changing the associated load balancer type. 2. Deploy the same application version as used in the original environment. 3. Run the `swap-environment-cnames` action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1. Edit the environment definitions in the existing deployment. 2. Change the associated load balancer type according to the requirements. 3. Rebuild the environment with the new load balancer type.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 13,
          "poolQNum": 30,
          "question": {
            "id": 13,
            "questionText": "A gaming application stores scores for players in an Amazon DynamoDB table that has four attributes: `user_id`, `user_name`, `user_score`, and `user_rank`. The users are allowed to update their names only if a user is authenticated by web identity federation. Which set of conditions should be added in the policy attached to the role for the `dynamodb:PutItem` API call?",
            "questionImage": null,
            "options": [
              {
                "text": "Option A.",
                "image": "images/question30_A.jpg",
                "isCorrect": true
              },
              {
                "text": "Option B.",
                "image": "images/question30_B.jpg",
                "isCorrect": false
              },
              {
                "text": "Option C.",
                "image": "images/question30_C.jpg",
                "isCorrect": false
              },
              {
                "text": "Option D.",
                "image": "images/question30_D.jpg",
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 14,
          "poolQNum": 335,
          "question": {
            "id": 14,
            "questionText": "A company needs a fully-managed source control service that will work in AWS. The service must ensure that revision control synchronizes multiple distributed repositories by exchanging sets of changes peer-to-peer. All users need to work productively even when not connected to a network. Which source control service should be used?",
            "questionImage": null,
            "options": [
              {
                "text": "Subversion.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeBuild.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeCommit.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS CodeStar.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 15,
          "poolQNum": 66,
          "question": {
            "id": 15,
            "questionText": "A company is developing a new online game that will run on top of Amazon ECS. Four distinct Amazon ECS services will be part of the architecture, each requiring specific permissions to various AWS services. The company wants to optimize the use of the underlying Amazon EC2 instances by bin packing the containers based on memory reservation. Which configuration would allow the Development team to meet these requirements MOST securely?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a new Identity and Access Management (IAM) instance profile containing the required permissions for the various ECS services, then associate that instance role with the underlying EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create four distinct IAM roles, each containing the required permissions for the associated ECS service, then configure each ECS service to reference the associated IAM role.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create four distinct IAM roles, each containing the required permissions for the associated ECS service, then, create an IAM group and configure the ECS cluster to reference that group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create four distinct IAM roles, each containing the required permissions for the associated ECS service, then configure each ECS task definition to referen—Åe the associated IAM role.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 16,
          "poolQNum": 14,
          "question": {
            "id": 16,
            "questionText": "An application deployed on AWS Elastic Beanstalk experiences increased error rates during deployments of new application versions, resulting in service degradation for users. The Development team believes that this is because of the reduction in capacity during the deployment steps. The team would like to change the deployment policy configuration of the environment to an option that maintains full capacity during deployment while using the existing instances. Which deployment policy will meet these requirements while using the existing instances?",
            "questionImage": null,
            "options": [
              {
                "text": "All at once.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling with additional batch.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Immutable.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 17,
          "poolQNum": 310,
          "question": {
            "id": 17,
            "questionText": "A company has three different environments: Development, QA, and Production. The company wants to deploy its code first in the Development environment, then QA, and then Production. Which AWS service can be used to meet this requirement?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS CodeCommit to create multiple repositories to deploy the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CodeBuild to create, configure, and deploy multiple build application projects.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Data Pipeline to create multiple data pipeline provisions to deploy the application.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS CodeDeploy to create multiple deployment groups.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 18,
          "poolQNum": 31,
          "question": {
            "id": 18,
            "questionText": "A developer wants the ability to roll back to a previous version of an AWS Lambda function in the event of errors caused by a new deployment. How can the developer achieve this with MINIMAL impact on users?",
            "questionImage": null,
            "options": [
              {
                "text": "Change the application to use an alias that points to the current version. Deploy the new version of the code. Update the alias to use the newly deployed version. If too many errors are encountered, point the alias back to the previous version.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the application to use an alias that points to the current version. Deploy the new version of the code. Update the alias to direct 10% of users to the newly deployed version. If too many errors are encountered, send 100% of traffic to the previous version.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Do not make any changes to the application Deploy the new version of the code. If too many errors are encountered, point the application back to the previous version using the version number in the Amazon Resource Name (ARN).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create three aliases: new, existing, and router. Point the existing alias to the current version. Have the router alias direct 100% of users to the existing alias. Update the application to use the router alias. Deploy the new version of the code. Point the new alias to this version. Update the router alias to direct 10% of users to the new alias. If too many errors are encountered, send 100% of traffic to the existing alias.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 19,
          "poolQNum": 86,
          "question": {
            "id": 19,
            "questionText": "A Developer is creating an Auto Scaling group whose instances need to publish a custom metric to Amazon CloudWatch. Which method would be the MOST secure way to authenticate a CloudWatch PUT request?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM user with `PutMetricData` permission and put the user credentials in a private repository; have applications pull the credentials as needed.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM user with `PutMetricData` permission, and modify the Auto Scaling launch configuration to inject the user credentials into the instance user data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the CloudWatch metric policies to allow the `PutMetricData` permission to instances from the Auto Scaling group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM role with `PutMetricData` permission and modify the Auto Scaling launching configuration to launch instances using that role.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 20,
          "poolQNum": 377,
          "question": {
            "id": 20,
            "questionText": "When a Developer tries to run an AWS CodeBuild project, it raises an error because the length of all environment variables exceeds the limit for the combined maximum of characters. What is the recommended solution?",
            "questionImage": null,
            "options": [
              {
                "text": "Add the export `LC_ALL=\"en_US.utf8\"` command to the `pre_build` section to ensure `POSIX` localization.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito to store key-value pairs for large numbers of environment variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the settings for the build project to use an Amazon S3 bucket for large numbers of environment variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Systems Manager Parameter Store to store large numbers of environment variables.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 21,
          "poolQNum": 112,
          "question": {
            "id": 21,
            "questionText": "A developer is testing an application that invokes an AWS Lambda function asynchronously. During the testing phase, the Lambda function fails to process after two retries. How can the developer troubleshoot the failure?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure AWS CloudTrail logging to investigate the invocation failures.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure Dead Letter Queues by sending events to Amazon SQS for investigatio.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure Amazon Simple Workflow Service to process any direct unprocessed events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure AWS Config to process any direct unprocessed events.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 22,
          "poolQNum": 346,
          "question": {
            "id": 22,
            "questionText": "Where can PortMapping be defined when launching containers in Amazon ECS?",
            "questionImage": null,
            "options": [
              {
                "text": "Security groups.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Elastic Container Registry (Amzon ECR).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Container agent.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Task definition.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 23,
          "poolQNum": 101,
          "question": {
            "id": 23,
            "questionText": "An application stops working with the following error: `The specified bucket does not exist`. Where is the BEST place to start the root cause analysis?",
            "questionImage": null,
            "options": [
              {
                "text": "Check the Elastic Load Balancer logs for `DeleteBucket` requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Check the application logs in Amazon CloudWatch Logs for Amazon S3 `DeleteBucket` errors.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Check AWS X-Ray for Amazon S3 `DeleteBucket` alarms.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Check AWS CloudTrail for a `DeleteBucket` event.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 24,
          "poolQNum": 245,
          "question": {
            "id": 24,
            "questionText": "When a Simple Queue Service message triggers a task that takes 5 minutes to complete, which process below will result in successful processing of the message and remove it from the queue while minimizing the chances of duplicate processing?",
            "questionImage": null,
            "options": [
              {
                "text": "Retrieve the message with an increased visibility timeout, process the message, delete the message from the queue.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Retrieve the message with an increased visibility timeout, delete the message from the queue, process the message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Retrieve the message with increased `DelaySeconds`, process the message, delete the message from the queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Retrieve the message with increased `DelaySeconds`, delete the message from the queue, process the message.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 25,
          "poolQNum": 119,
          "question": {
            "id": 25,
            "questionText": "A company has 25,000 employees and is growing. The company is creating an application that will be accessible to its employees only. A developer is using Amazon S3 to store images and Amazon RDS to store application data. The company requires that all employee information remain in the legacy Security Assertion Markup Language (SAML) employee directory only and is not interested in mirroring any employee information on AWS. How can the developer provide authorized access for the employees who will be using this application so each employee can access their own application data only?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon VPC and keep all resources inside the VPC, and use a VPC link for the S3 bucket with the bucket policy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito user pools, federate with the SAML provider, and use user pool groups with an IAM policy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon Cognito identity pool, federate with the SAML provider, and use an IAM condition key with a value for the `cognito-identity.amazonaws.com:sub` variable to grant access to the employees.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a unique IAM role for each employee and have each employee assume the role to access the application so they can access their personal data only.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 26,
          "poolQNum": 93,
          "question": {
            "id": 26,
            "questionText": "A Developer is developing an application that manages financial transactions. To improve security, multi-factor authentication (MFA) will be required as part of the login protocol. What services can the Developer use to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon DynamoDB to store MFA session data, and Amazon SNS to send MFA codes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito with MFA.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Directory Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS IAM with MFA enabled.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 27,
          "poolQNum": 253,
          "question": {
            "id": 27,
            "questionText": "Games-R-Us is launching a new game app for mobile devices. Users will log into the game using their existing Facebook account and the game will record player data and scoring information directly to a DynamoDB table. What is the most secure approach for signing requests to the DynamoDB API?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM user with access credentials that are distributed with the mobile app to sign the requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Distribute the AWS root account access credentials with the mobile app to sign the requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Request temporary security credentials using web identity federation to sign the requests.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Establish cross account access between the mobile app and the DynamoDB table to sign the requests",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 28,
          "poolQNum": 187,
          "question": {
            "id": 28,
            "questionText": "A Developer uses Amazon S3 buckets for static website hosting. The Developer creates one S3 bucket for the code and another S3 bucket for the assets, such as image and video files. Access is denied when a user attempts to access the assets bucket from the code bucket, with the website application showing a `403` error. How should the Developer solve this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM role and apply it to the assets bucket for the code bucket to be granted access.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Edit the bucket policy of the assets bucket to allow access from the code bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Edit the bucket policy of the assets bucket to open access to all principals.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the code bucket to use AWS Lambda functions instead of static website hosting.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 29,
          "poolQNum": 151,
          "question": {
            "id": 29,
            "questionText": "A developer is writing an application that will process data delivered into an Amazon S3 bucket. The data is delivered approximately 10 times a day, and the developer expects the data will be processed in less than 1 minute, on average. How can the developer deploy and invoke the application with the lowest cost and lowest latency?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an Amazon CloudWatch alarm triggered by an S3 object upload.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an S3 event notification.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an Amazon CloudWatch scheduled event.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the application onto an Amazon EC2 instance and have it poll the S3 bucket for new objects.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 30,
          "poolQNum": 309,
          "question": {
            "id": 30,
            "questionText": "A company is creating an application that will require users to access AWS services and allow them to reset their own passwords. Which of the following would allow the company to manage users and authorization while allowing users to reset their own passwords?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon Cognito identify pools and AWS STS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito identity pools and AWS IAM.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito user pools and AWS KMS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito user pools and identity pools.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 31,
          "poolQNum": 229,
          "question": {
            "id": 31,
            "questionText": "Which code snippet below returns the URL of a load balanced web site created in CloudFormation with an `AWS::ElasticLoadBalancing::LoadBalancer` resource name `ElasticLoad Balancer`?",
            "questionImage": null,
            "options": [
              {
                "text": "`\"Fn::Join\":[ \"\".[\"http://\", {Fn::GetAtt\": [ \"ElasticLoadBalancer\",\"DNSName\"]}]]`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`\"Fn::Join\":[ \"\".[\"http://\", {Fn::GetAtt\": [ \"ElasticLoadBalancer\",\"Url\"]}]]`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`\"Fn::Join\":[ \"\".[\"http://\", {\"Ref : \"ElasticLoadBalancerUrl\"}]]`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`\"Fn::Join\":[ \"\".[\"http://\", {\"Ref : \"ElasticLoadBalancer\",\"DNSName\"}]]`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 32,
          "poolQNum": 299,
          "question": {
            "id": 32,
            "questionText": "An e-commerce site allows returning users to log in to display customized web pages. The workflow is shown in the image below. An application is running on EC2 instances. Amazon RDS is used for the database that stores user accounts and preferences. The website freezes or is slow to load while waiting for the login step to complete. The remaining components of the site are well-optimized. Which of the following techniques will resolve this issue? (Select TWO)",
            "questionImage": "images/question299.jpeg",
            "options": [
              {
                "text": "Implement the user login page as an asynchronous Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache for MemCached to cache user data.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Amazon Application Load Balancer to load balance the traffic to the website.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Call the database asynchronously so the code can continue executing.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Batch login requests from hundreds of users together as a single read request to the database.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 33,
          "poolQNum": 235,
          "question": {
            "id": 33,
            "questionText": "Which EC2 API call would you use to retrieve a list of Amazon Machine Images (AMIs)?",
            "questionImage": null,
            "options": [
              {
                "text": "`DescribeInstances`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`DescribeAMIs`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`DescribeImages`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`GetAMIs`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "You cannot retrieve a list of AMIs as there are over 10,000 AMIs.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 34,
          "poolQNum": 273,
          "question": {
            "id": 34,
            "questionText": "A company is using continuous integration and continuous delivery systems. A Developer now needs to automate a software package deployment to both Amazon EC2 instances and virtual servers running on-premises. Which AWS service should be used to accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS CodePipeline.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeBuild.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeDeploy.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 35,
          "poolQNum": 263,
          "question": {
            "id": 35,
            "questionText": "You are providing AWS consulting services for a company developing a new mobile application that will be leveraging Amazon SNS Mobile Push for push notifications. In order to send direct notification messages to individual devices each device registration identifier or token needs to be registered with SNS; however the developers are not sure of the best way to do this. You advise them to:",
            "questionImage": null,
            "options": [
              {
                "text": "Bulk upload the device tokens contained in a CSV file via the AWS Management Console.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Let the push notification service (e.g. Amazon Device Messaging) handle the registration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement a token vending service to handle the registration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Call the `CreatePlatformEndPoint` API function to register multiple device tokens.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 36,
          "poolQNum": 313,
          "question": {
            "id": 36,
            "questionText": "In a multi-container Docker environment in AWS Elastic Beanstalk, what is required to configure container instances in the environment?",
            "questionImage": null,
            "options": [
              {
                "text": "An Amazon ECS task definition.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An Amazon ECS cluster.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A Dockerfile in an application package.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A CLI for Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 37,
          "poolQNum": 128,
          "question": {
            "id": 37,
            "questionText": "A company is developing a report executed by AWS Step Functions, Amazon CloudWatch shows errors in the Step Functions task state machine. To troubleshoot each task, the state input needs to be included along with the error message in the state output. Which coding practice can preserve both the original input and the error for the state?",
            "questionImage": null,
            "options": [
              {
                "text": "Use `ResultPath` in a `Catch` statement to include the error with the original input.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use `InputPath` in a `Catch` statement and set the value to `null`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use `Error Equals` in a `Retry` statement to include the error with the original input.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use `OutputPath` in a `Retry` statement and set the value to `$`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 38,
          "poolQNum": 46,
          "question": {
            "id": 38,
            "questionText": "A Developer needs to design an application running on AWS that will be used to consume Amazon SQS messages that range from 1 KB up to 1GB in size. How should the Amazon SQS messages be managed?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon S3 and the Amazon SQS CLI.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon S3 and the Amazon SQS Extended Client Library for Java.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Amazon EBS and the Amazon SQS CLI.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon EFS and the Amazon SQS CLI.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 39,
          "poolQNum": 64,
          "question": {
            "id": 39,
            "questionText": "When writing a Lambda function, what is the benefit of instantiating AWS clients outside the scope of the handler?",
            "questionImage": null,
            "options": [
              {
                "text": "Legibility and stylistic convention.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Taking advantage of connection re-use.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Better error handling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Creating a new instance per invocation.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 40,
          "poolQNum": 42,
          "question": {
            "id": 40,
            "questionText": "An AWS Lambda function accesses two Amazon DynamoDB tables. A developer wants to improve the performance of the Lambda function by identifying bottlenecks in the function. How can the developer inspect the timing of the DynamoDB API calls?",
            "questionImage": null,
            "options": [
              {
                "text": "Add DynamoDB as an event source to the Lambda function. View the performance with Amazon CloudWatch metrics.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Place an Application Load Balancer (ALB) in front of the two DynamoDB tables. Inspect the ALB logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Limit Lambda to no more than five concurrent invocations Monitor from the Lambda console.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable AWS X-Ray tracing for the function. View the traces from the X-Ray service.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 41,
          "poolQNum": 99,
          "question": {
            "id": 41,
            "questionText": "A Developer executed a AWS CLI command and received the error shown below. What action should the Developer perform to make this error human-readable?",
            "questionImage": "images/question99.jpg",
            "options": [
              {
                "text": "Make a call to AWS KMS to decode the message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS STS `decode-authorization-message` API to decode the message.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use an open source decoding library to decode the message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS IAM `decode-authorization-message` API to decode this message.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 42,
          "poolQNum": 176,
          "question": {
            "id": 42,
            "questionText": "A company is launching an ecommerce website and will host the static data in Amazon S3. The company expects approximately 1,000 transactions per second (TPS) for GET and PUT requests in total. Logging must be enabled to track all requests and must be retained for auditing purposes. What is the MOST cost-effective solution?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable AWS CloudTrail logging for the S3 bucket-level action and create a lifecycle policy to move the data from the log bucket to Amazon S3 Glacier in 90 days.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable S3 server access logging and create a lifecycle policy to expire the data in 90 days.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable AWS CloudTrail logging for the S3 bucket-level action and create a lifecycle policy to expire the data in 90 days.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable S3 server access logging and create a lifecycle policy to move the data to Amazon S3 Glacier in 90 days.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 43,
          "poolQNum": 349,
          "question": {
            "id": 43,
            "questionText": "A stock market monitoring application uses Amazon Kinesis for data ingestion. During simulated tests of peak data rates, the Kinesis stream cannot keep up with the incoming data. What step will allow Kinesis to accommodate the traffic during peak hours?",
            "questionImage": null,
            "options": [
              {
                "text": "Install the Kinesis Producer Library (KPL) for ingesting data into the stream.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Reduce the data retention period to allow for more data ingestion using `DecreaseStreamRetentionPeriod`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the shard count of the stream using `UpdateShardCount`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Ingest multiple records into the stream in a single call using `PutRecords`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 44,
          "poolQNum": 348,
          "question": {
            "id": 44,
            "questionText": "While developing an application that runs on Amazon EC2 in an Amazon VPC, a Developer identifies the need for centralized storage of application-level logs. Which AWS service can be used to securely store these logs?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon EC2 VPC Flow Logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon CloudWatch Logs.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon CloudSearch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CloudTrail",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 45,
          "poolQNum": 338,
          "question": {
            "id": 45,
            "questionText": "A Developer is creating a mobile application that will not require users to log in. What is the MOST efficient method to grant users access to AWS resources?",
            "questionImage": null,
            "options": [
              {
                "text": "Use an identity provider to securely authenticate with the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an AWS Lambda function to create an IAM user when a user accesses the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create credentials using AWS KMS and apply these credentials to users when using the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito to associate unauthenticated users with an IAM role that has limited access to resources.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 46,
          "poolQNum": 157,
          "question": {
            "id": 46,
            "questionText": "An application is experiencing performance issues based on increased demand. This increased demand is on read-only historical records pulled from an Amazon RDS-hosted database with custom views and queries. A Developer must improve performance without changing the database structure. Which approach will improve performance and MINIMIZE management overhead?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy Amazon DynamoDB, move all the data, and point to DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy Amazon ElastiCache for Redis and cache the data for the application.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Deploy Memcached on Amazon EC2 and cache the data for the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy Amazon DynamoDB Accelerator (DAX) on Amazon RDS to improve cache performance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 47,
          "poolQNum": 51,
          "question": {
            "id": 47,
            "questionText": "A Developer is asked to implement a caching layer in front of Amazon RDS. Cached content is expensive to regenerate in case of service failure. Which implementation below would work while maintaining maximum uptime?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement Amazon ElastiCache Redis in Cluster Mode.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install Redis on an Amazon EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement Amazon ElastiCache Memcached.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Migrate the database to Amazon Redshift.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 48,
          "poolQNum": 68,
          "question": {
            "id": 48,
            "questionText": "A mobile app stores blog posts in an Amazon DynamoDB table. Millions of posts are added every day, and each post represents a single item in the table. The mobile app requires only recent posts. Any post that is older than 48 hours can be removed. What is the MOST cost-effective way to delete posts that are older than 48 hours?",
            "questionImage": null,
            "options": [
              {
                "text": "For each item, add a new attribute of type `String` that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the `BatchWriteItem` API operation. Schedule a cron job on an Amazon EC2 instance once an hour to start the script.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "For each item, add a new attribute of type `String` that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the `BatchWriteItem` API operation. Place the script in a container image. Schedule an Amazon Elastic Container Service (Amazon ECS) task on AWS Fargate that invokes the container every 5 minutes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "For each item, add a new attribute of type `Date` that has a timestamp that is set to 48 hours after the blog post creation time. Create a Global Secondary Index (GSI) that uses the new attribute as a sort key. Create an AWS Lambda function that references the GSI and removes expired items by using the `BatchWriteItem` API operation. Schedule the function with an Amazon CloudWatch event every minute.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "For each item, add a new attribute of type `Number` that has a timestamp that is set to 48 hours after the blog post creation time. Configure the DynamoDB table with a TTL that references the new attribute.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 49,
          "poolQNum": 185,
          "question": {
            "id": 49,
            "questionText": "A Developer wants to insert a record into an Amazon DynamoDB table as soon as a new file is added to an Amazon S3 bucket. Which set of steps would be necessary to achieve this?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an event with Amazon CloudWatch Events that will monitor the S3 bucket and then insert the records into DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure an S3 event to invoke a Lambda function that inserts records into DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a Lambda function that will poll the S3 bucket and then insert the records into DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a cron job that will run at a scheduled time and insert the records into DynamoDB.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 50,
          "poolQNum": 78,
          "question": {
            "id": 50,
            "questionText": "A customer wants to deploy its source code on an AWS Elastic Beanstalk environment. The customer needs to perform deployment with minimal outage and should only use existing instances to retain application access log. What deployment policy would satisfy these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Rolling.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "All at once.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling with an additional batch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Immutable.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 51,
          "poolQNum": 376,
          "question": {
            "id": 51,
            "questionText": "The Developer for a retail company must integrate a fraud detection solution into the order processing solution. The fraud detection solution takes between ten and thirty minutes to verify an order. At peak, the web site can receive one hundred orders per minute. What is the most scalable method to add the fraud detection solution to the order processing pipeline?",
            "questionImage": null,
            "options": [
              {
                "text": "Add all new orders to an Amazon SQS queue. Configure a fleet of 10 EC2 instances spanning multiple AZs with the fraud detection solution installed on them to pull orders from this queue. Update the order with a pass or fails status.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add all new orders to an SQS queue. Configure an Auto Scaling group that uses the queue depth metric as its unit of scale to launch a dynamically-sized fleet of EC2 instances spanning multiple AZs with the fraud detection solution installed on them to pull orders from this queue. Update the order with a pass or fails status.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add all new orders to an Amazon Kinesis Stream. Subscribe a Lambda function to automatically read batches of records from the Kinesis Stream. The Lambda function includes the fraud detection software and will update the order with a pass or fail status.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write all new orders to Amazon DynamoDB. Configure DynamoDB Streams to include all new orders. Subscribe a Lambda function to automatically read batches of records from the Kinesis Stream. The Lambda function includes the fraud detection software and will update the order with a pass or fail status.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 52,
          "poolQNum": 237,
          "question": {
            "id": 52,
            "questionText": "When using a large Scan operation in DynamoDB, what technique can be used to minimize the impact of a scan on a table's provisioned throughput?",
            "questionImage": null,
            "options": [
              {
                "text": "Set a smaller page size for the scan.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use parallel scans.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Define a range index on the table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Prewarm the table by updating all items.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 53,
          "poolQNum": 129,
          "question": {
            "id": 53,
            "questionText": "A developer receives the following error message when trying to launch or terminate an Amazon EC2 instance using a boto3 script. What should the developer do to correct this error message?",
            "questionImage": "images/question129.jpg",
            "options": [
              {
                "text": "Assign an IAM role to the EC2 instance to allow necessary API calls on behalf of the client.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement an exponential backoff algorithm for optimizing the number of API requests made to Amazon EC2.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Increase the overall network bandwidth to handle higher API request rates.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upgrade to the latest AWS CLI version so that boto3 can handle higher request rates.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 54,
          "poolQNum": 190,
          "question": {
            "id": 54,
            "questionText": "A company wants to migrate an imaging service to Amazon EC2 while following security best practices. The images are sourced and read from a non-public Amazon S3 bucket. What should a Developer do to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM user with read-only permissions for the S3 bucket. Temporarily store the user credentials in the Amazon EBS volume of the EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM user with read-only permissions for the S3 bucket. Temporarily store the user credentials in the user data of the EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an EC2 service role with read-only permissions for the S3 bucket. Attach the role to the EC2 instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an S3 service role with read-only permissions for the S3 bucket. Attach the role to the EC2 instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 55,
          "poolQNum": 244,
          "question": {
            "id": 55,
            "questionText": "Which DynamoDB limits can be raised by contacting AWS support? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "The number of hash keys per account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The maximum storage used per account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The number of tables per account.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The number of local secondary indexes per account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The number of provisioned throughput units per account.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 56,
          "poolQNum": 293,
          "question": {
            "id": 56,
            "questionText": "To include objects defined by the AWS Serverless Application Model (SAM) in an AWS CloudFormation template, in addition to `Resources`, what section MUST be included in the document root?",
            "questionImage": null,
            "options": [
              {
                "text": "`Conditions`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`Globals`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`Transform`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`Properties`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 57,
          "poolQNum": 264,
          "question": {
            "id": 57,
            "questionText": "You are writing to a DynamoDB table and receive the following exception: `ProvisionedThroughputExceededException`. though according to your Cloudwatch metrics for the table, you are not exceeding your provisioned throughput. What could be an explanation for this?",
            "questionImage": null,
            "options": [
              {
                "text": "You haven't provisioned enough DynamoDB storage instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "You're exceeding your capacity on a particular `Range Key`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "You're exceeding your capacity on a particular `Hash Key`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "You're exceeding your capacity on a particular `Sort Key`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "You haven't configured DynamoDB Auto Scaling triggers.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 58,
          "poolQNum": 266,
          "question": {
            "id": 58,
            "questionText": "Which of the following statements about SQS is true?",
            "questionImage": null,
            "options": [
              {
                "text": "Messages will be delivered exactly once and messages will be delivered in First in, First out order.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered exactly once and message delivery order is indeterminate.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered one or more times and messages will be delivered in First in, First out order.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered one or more times and message delivery order is indeterminate.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 59,
          "poolQNum": 344,
          "question": {
            "id": 59,
            "questionText": "A company has an internet-facing application that uses Web Identity Federation to obtain a temporary credential from AWS Security Token Service (AWS STS). The app then uses the token to access AWS services. Review the following response: Based on the response displayed what permissions are associated with the call from the application?",
            "questionImage": "images/question344.jpg",
            "options": [
              {
                "text": "Permissions associated with the role `AROACLKWSDQRAOEXAMPLE:app1`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Permissions associated with the default role used when the AWS service was built.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Permission associated with the IAM principal that owns the `AccessKeyID` `ASgeIAIOSFODNN7EXAMPLE`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Permissions associated with the account that owns the AWS service.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 60,
          "poolQNum": 350,
          "question": {
            "id": 60,
            "questionText": "A company has an AWS CloudFormation template that is stored as a single file. The template is able to launch and create a full infrastructure stack. Which best practice would increase the maintainability of the template?",
            "questionImage": null,
            "options": [
              {
                "text": "Use nested stacks for common template patterns.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Embed credentials to prevent typos.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Remove mappings to decrease the number of variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use `AWS::Include` to reference publicly-hosted template files.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 61,
          "poolQNum": 154,
          "question": {
            "id": 61,
            "questionText": "A company requires that AWS Lambda functions written by Developers log errors so System Administrators can more effectively troubleshoot issues. What should the Developers implement to meet this need?",
            "questionImage": null,
            "options": [
              {
                "text": "Publish errors to a dedicated Amazon SQS queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon CloudWatch Events event trigger based on certain Lambda events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Report errors through logging statements in Lambda function code.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set up an Amazon SNS topic that sends logging statements upon failure.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 62,
          "poolQNum": 246,
          "question": {
            "id": 62,
            "questionText": "Company A has an S3 bucket containing premier content that they intend to make available to only paid subscribers of their website. The S3 bucket currently has default permissions of all objects being private to prevent inadvertent exposure of the premier content to non-paying website visitors. How can Company A provide only paid subscribers the ability to download a premier content file in the S3 bucket?",
            "questionImage": null,
            "options": [
              {
                "text": "Apply a bucket policy that grants anonymous users to download the content from the S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Generate a pre-signed object URL for the premier content file when a paid subscriber requests a download.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add a bucket policy that requires Multi-Factor Authentication for requests to access the S3 bucket objects.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable server side encryption on the S3 bucket for data protection against the non-paying website visitors.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 63,
          "poolQNum": 15,
          "question": {
            "id": 63,
            "questionText": "A Developer is creating an application that needs to locate the public IPv4 address of the Amazon EC2 instance on which it runs. How can the application locate this information?",
            "questionImage": null,
            "options": [
              {
                "text": "Get the instance metadata by retrieving `http://169.254.169.254/latest/metadata/`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Get the instance user data by retrieving `http://169.254.169.254/latest/userdata/`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Get the application to run `IFCONFIG` to get the public IP address.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Get the application to run `IPCONFIG` to get the public IP address.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 64,
          "poolQNum": 43,
          "question": {
            "id": 64,
            "questionText": "An Amazon RDS database instance is used by many applications to look up historical data. The query rate is relatively constant. When the historical data is updated each day, the resulting write traffic slows the read query performance and affects all application users. What can be done to eliminate the performance impact on application users?",
            "questionImage": null,
            "options": [
              {
                "text": "Make sure Amazon RDS is Multi-AZ so it can better absorb increased traffic.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an RDS Read Replica and direct all read traffic to the replica.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Implement Amazon ElastiCache in front of Amazon RDS to buffer the write traffic.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon DynamoDB instead of Amazon RDS to buffer the read traffic.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 65,
          "poolQNum": 278,
          "question": {
            "id": 65,
            "questionText": "A Developer has been asked to create an AWS Lambda function that is triggered any time updates are made to items in an Amazon DynamoDB table. The function has been created, and appropriate permissions have been added to the Lambda execution role. Amazon DynamoDB streams have been enabled for the table, but the function is still not being triggered. Which option would enable DynamoDB table updates to trigger the Lambda function?",
            "questionImage": null,
            "options": [
              {
                "text": "Change the `StreamViewType` parameter value to `NEW_AND_OLD_IMAGES` for the DynamoDB table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure event source mapping for the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Map an Amazon SNS topic to the DynamoDB streams.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the maximum execution time (timeout) setting of the Lambda function.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        }
      ],
      "questionMap": {
        "1": 152,
        "2": 225,
        "3": 200,
        "4": 153,
        "5": 87,
        "6": 234,
        "7": 261,
        "8": 137,
        "9": 326,
        "10": 343,
        "11": 108,
        "12": 271,
        "13": 30,
        "14": 335,
        "15": 66,
        "16": 14,
        "17": 310,
        "18": 31,
        "19": 86,
        "20": 377,
        "21": 112,
        "22": 346,
        "23": 101,
        "24": 245,
        "25": 119,
        "26": 93,
        "27": 253,
        "28": 187,
        "29": 151,
        "30": 309,
        "31": 229,
        "32": 299,
        "33": 235,
        "34": 273,
        "35": 263,
        "36": 313,
        "37": 128,
        "38": 46,
        "39": 64,
        "40": 42,
        "41": 99,
        "42": 176,
        "43": 349,
        "44": 348,
        "45": 338,
        "46": 157,
        "47": 51,
        "48": 68,
        "49": 185,
        "50": 78,
        "51": 376,
        "52": 237,
        "53": 129,
        "54": 190,
        "55": 244,
        "56": 293,
        "57": 264,
        "58": 266,
        "59": 344,
        "60": 350,
        "61": 154,
        "62": 246,
        "63": 15,
        "64": 43,
        "65": 278
      }
    },
    {
      "id": "1763970125361",
      "timestamp": 1763970125361,
      "score": "0.00",
      "results": [
        {
          "qNum": 1,
          "poolQNum": 317,
          "question": {
            "id": 1,
            "questionText": "A company has a multi-tiered web application on AWS. During a recent spike in traffic, one of the primary relational databases on Amazon RDS could not serve all the traffic. Some read queries for repeatedly accessed items failed, so users received error messages. What can be done to minimize the impact on database read queries MOST efficiently during future traffic spikes?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon S3 to cache database query results.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon RDS as a custom origin for Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use local storage and memory on Amazon EC2 instances to cache data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache in front of the primary database to cache data.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 2,
          "poolQNum": 142,
          "question": {
            "id": 2,
            "questionText": "A developer is provided with an HTTPS clone URL for an AWS CodeCommit repository. What needs to be configured before cloning this repository?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS KMS to set up public and private keys for use with AWS CodeCommit.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set up the Git credential helper to use an AWS credential profile, and enable the helper to send the path to the repositories.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS Certificate Manager to provision public and private SSL/TLS certificates.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Generate encryption keys using AWS CloudHSM, then export the key for use with AWS CodeCommit.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 3,
          "poolQNum": 116,
          "question": {
            "id": 3,
            "questionText": "A developer is creating an AWS Lambda function that generates a new file each time it runs. Each new file must be checked into an AWS CodeCommit repository hosted in the same AWS account. How should the developer accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "When the Lambda function starts, use the Git CLI to clone the repository. Check the new file into the cloned repository and push the change.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "After the new file is created in Lambda, use cURL to invoke the CodeCommit API. Send the file to the repository.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an AWS SDK to instantiate a CodeCommit client. Invoke the `put_file` method to add the file to the repository.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload the new to an Amazon S3 bucket. Create an AWS Step Function to accept S3 events. In the Step Function, add the new file to the repository.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 4,
          "poolQNum": 296,
          "question": {
            "id": 4,
            "questionText": "A company is migrating a single-server, on-premises web application to AWS. The company intends to use multiple servers behind an Elastic Load Balancer (ELB) to balance the load, and will also store session data in memory on the web server. The company does not want to lose that session data if a server fails or goes offline, and it wants to minimize user's downtime. Where should the company move session data to MOST effectively reduce downtime and make users' session data more fault tolerant?",
            "questionImage": null,
            "options": [
              {
                "text": "An Amazon ElastiCache for Redis cluster.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "A second Amazon EBS volume.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The web server's primary disk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An Amazon EC2 instance dedicated to session data.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 5,
          "poolQNum": 17,
          "question": {
            "id": 5,
            "questionText": "A company is migrating its on-premises database to Amazon RDS for MySQL. The company has read-heavy workloads, and wants to make sure it re-factors its code to achieve optimum read performance for its queries. How can this objective be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Add database retries to effectively use RDS with vertical scaling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use RDS with multi-AZ deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a connection string to use an RDS read replica for read queries.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add a connection string to use a read replica on an EC2 instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 6,
          "poolQNum": 26,
          "question": {
            "id": 6,
            "questionText": "A Developer is writing a REST service that will add items to a shopping list. The service is built on Amazon API Gateway with AWS Lambda integrations. The shopping list items are send as query string parameters in the method request. How should the Developer convert the query string parameters to arguments for the Lambda function?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable request validation.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Include the Amazon Resource Name (ARN) of the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the integration type.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a mapping template.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 7,
          "poolQNum": 274,
          "question": {
            "id": 7,
            "questionText": "A Developer created a new AWS account and must create a scalable AWS Lambda function that meets the following requirements for concurrent execution: Average execution time of 100 seconds 50 requests per second. Which step must be taken prior to deployment to prevent errors?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement dead-letter queues to capture invocation errors.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an event source from Amazon API Gateway to the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement error handling within the application code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Contact AWS Support to increase the concurrent execution limits.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 8,
          "poolQNum": 18,
          "question": {
            "id": 8,
            "questionText": "A developer needs to modify an application architecture to meet new functional requirements. Application data is stored in Amazon DynamoDB and processed for analysis in a nightly batch. The system analysts do not want to wait unit the next day to view the processed data and have asked to have it available in near-real time. Which application architect pattern would enables the data to be processed as it is received?",
            "questionImage": null,
            "options": [
              {
                "text": "Event driven.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client served driven.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Fan-out driven.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Schedule driven.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 9,
          "poolQNum": 256,
          "question": {
            "id": 9,
            "questionText": "In DynamoDB, what type of HTTP response codes indicate that a problem was found with the client request sent to the service?",
            "questionImage": null,
            "options": [
              {
                "text": "5xx HTTP response code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "200 HTTP response code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "306 HTTP response code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "4xx HTTP response code.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 10,
          "poolQNum": 282,
          "question": {
            "id": 10,
            "questionText": "An AWS Lambda function must access an external site by using a regularly rotated user name and password. These items must be kept securely and cannot be stored in the function code. What combination of AWS services can be used to accomplish this? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "AWS Certificate Manager (ACM).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Systems Manager Parameter Store.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Trusted Advisor.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS KMS.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon GuardDuty.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 11,
          "poolQNum": 223,
          "question": {
            "id": 11,
            "questionText": "Which of the following are correct statements with policy evaluation logic in AWS Identity and Access Management? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "By default, all requests are denied.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An explicit allow overrides an explicit deny.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An explicit allow overrides default deny.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An explicit deny does not override an explicit allow.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "By default, all request are allowed.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 12,
          "poolQNum": 191,
          "question": {
            "id": 12,
            "questionText": "A Development team wants to immediately build and deploy an application whenever there is a change to the source code. Which approaches could be used to trigger the deployment? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Store the source code in an Amazon S3 bucket. Configure AWS CodePipeline to start whenever a file in the bucket changes.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the source code in an encrypted Amazon EBS volume. Configure AWS CodePipeline to start whenever a file in the volume changes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the source code in an AWS CodeCommit repository. Configure AWS CodePipeline to start whenever a change is committed to the repository.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the source code in an Amazon S3 bucket. Configure AWS CodePipeline to start every 15 minutes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the source code in an Amazon EC2 instance's ephemeral storage. Configure the instance to start AWS CodePipeline whenever there are changes to the source code.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 13,
          "poolQNum": 81,
          "question": {
            "id": 13,
            "questionText": "An application is designed to use Amazon SQS to manage messages from many independent senders. Each sender's messages must be processed in the order they are received. Which SQS feature should be implemented by the Developer?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure each sender with a unique MessageGroupId.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Enable MessageDeduplicationIds on the SQS queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure each message with unique MessageGroupIds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable ContentBasedDeduplication on the SQS queue.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 14,
          "poolQNum": 245,
          "question": {
            "id": 14,
            "questionText": "When a Simple Queue Service message triggers a task that takes 5 minutes to complete, which process below will result in successful processing of the message and remove it from the queue while minimizing the chances of duplicate processing?",
            "questionImage": null,
            "options": [
              {
                "text": "Retrieve the message with an increased visibility timeout, process the message, delete the message from the queue.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Retrieve the message with an increased visibility timeout, delete the message from the queue, process the message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Retrieve the message with increased `DelaySeconds`, process the message, delete the message from the queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Retrieve the message with increased `DelaySeconds`, delete the message from the queue, process the message.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 15,
          "poolQNum": 208,
          "question": {
            "id": 15,
            "questionText": "A Developer has an e-commerce API hosted on Amazon ECS. Variable and spiking demand on the application is causing order processing to take too long. The application processes Amazon SQS queues. The `ApproximateNumberOfMessagesVisible` metric spikes at very high values throughout the day, which cause Amazon CloudWatch alarm breaches. Other ECS metrics for the API containers are well within limits. What can the Developer implement to improve performance while keeping costs low?",
            "questionImage": null,
            "options": [
              {
                "text": "Target tracking scaling policy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Docker Swarm.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Service scheduler.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Step scaling policy.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 16,
          "poolQNum": 8,
          "question": {
            "id": 16,
            "questionText": "A company uses a third-party tool to build, bundle, and package rts applications on-premises and store them locally. The company uses Amazon EC2 instances to run its front-end applications. How can an application be deployed from the source control system onto the EC2 instances?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS CodeDeploy and point it to the local storage to directly deploy a bundle m a zip. tar. or tar.gz format.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload the bundle to an Amazon S3 bucket and specify the S3 location when doing a deployment using AWS CodeDeploy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a repository using AWS CodeCommit to automatically trigger a deployment to the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CodeBuild to automatically deploy the latest build to the latest EC2 instances.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 17,
          "poolQNum": 31,
          "question": {
            "id": 17,
            "questionText": "A developer wants the ability to roll back to a previous version of an AWS Lambda function in the event of errors caused by a new deployment. How can the developer achieve this with MINIMAL impact on users?",
            "questionImage": null,
            "options": [
              {
                "text": "Change the application to use an alias that points to the current version. Deploy the new version of the code. Update the alias to use the newly deployed version. If too many errors are encountered, point the alias back to the previous version.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the application to use an alias that points to the current version. Deploy the new version of the code. Update the alias to direct 10% of users to the newly deployed version. If too many errors are encountered, send 100% of traffic to the previous version.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Do not make any changes to the application Deploy the new version of the code. If too many errors are encountered, point the application back to the previous version using the version number in the Amazon Resource Name (ARN).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create three aliases: new, existing, and router. Point the existing alias to the current version. Have the router alias direct 100% of users to the existing alias. Update the application to use the router alias. Deploy the new version of the code. Point the new alias to this version. Update the router alias to direct 10% of users to the new alias. If too many errors are encountered, send 100% of traffic to the existing alias.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 18,
          "poolQNum": 78,
          "question": {
            "id": 18,
            "questionText": "A customer wants to deploy its source code on an AWS Elastic Beanstalk environment. The customer needs to perform deployment with minimal outage and should only use existing instances to retain application access log. What deployment policy would satisfy these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Rolling.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "All at once.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling with an additional batch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Immutable.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 19,
          "poolQNum": 383,
          "question": {
            "id": 19,
            "questionText": "A company developed a set of APIs that are being served through the Amazon API Gateway. The API calls need to be authenticated based on OpenID identity providers such as Amazon or Facebook. The APIs should allow access based on a custom authorization model. Which is the simplest and MOST secure design to use to build an authentication and authorization model for the APIs?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon Cognito user pools and a custom authorizer to authenticate and authorize users based on JSON Web Tokens.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Build a OpenID token broker with Amazon and Facebook. Users will authenticate with these identify providers and pass the JSON Web Token to the API to authenticate each API call.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store user credentials in Amazon DynamoDB and have the application retrieve temporary credentials from AWS STS. Make API calls by passing user credentials to the APIs for authentication and authorization.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon RDS to store user credentials and pass them to the APIs for authentications and authorization.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 20,
          "poolQNum": 345,
          "question": {
            "id": 20,
            "questionText": "A Developer is using AWS CLI, but when running list commands on a large number of resources, it is timing out. What can be done to avoid this time-out?",
            "questionImage": null,
            "options": [
              {
                "text": "Use pagination.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use shorthand syntax.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use parameter values.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use quoting strings.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 21,
          "poolQNum": 7,
          "question": {
            "id": 21,
            "questionText": "An application is being developed to audit several AWS accounts. The application will run in Account A and must access AWS services in Accounts B and C. What is the MOST secure way to allow the application to call AWS services in each audited account?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure cross-account roles in each audited account. Write code in Account A that assumes those roles.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use S3 cross-region replication to communicate among accounts, with Amazon S3 event notifications to trigger Lambda functions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy an application in each audited account with its own role. Have Account A authenticate with the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM user with an access key in each audited account. Write code in Account A that uses those access keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 22,
          "poolQNum": 103,
          "question": {
            "id": 22,
            "questionText": "An application stores images in an S3 bucket. Amazon S3 event notifications are used to trigger a Lambda function that resizes the images. Processing each image takes less than a second. How will AWS Lambda handle the additional traffic?",
            "questionImage": null,
            "options": [
              {
                "text": "Lambda will scale out to execute the requests concurrently.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Lambda will handle the requests sequentially in the order received.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Lambda will process multiple images in a single execution.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Lambda will add more compute to each execution to reduce processing time.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 23,
          "poolQNum": 1,
          "question": {
            "id": 23,
            "questionText": "Which of the following are good use cases for how Amazon ElastiCache can help an application? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Improve the performance of S3 PUT operations.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Improve the latency of deployments performed by AWS CodeDeploy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Improve latency and throughput for read-heavy application workloads.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Reduce the time required to merge AWS CodeCommit branches.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Improve performance of compute-intensive applications.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 24,
          "poolQNum": 267,
          "question": {
            "id": 24,
            "questionText": "A corporate web application is deployed within an Amazon VPC, and is connected to the corporate data center via IPSec VPN. The application must authenticate against the on-premise LDAP server. Once authenticated, logged-in users can only access an S3 keyspace specific to the user. Which two approaches can satisfy the objectives? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "The application authenticates against LDAP. The application then calls the IAM Security Service to login to IAM using the LDAP credentials. The application can use the 1AM temporary credentials to access the appropriate S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The application authenticates against LDAP, and retrieves the name of an IAM role associated with the user. The application then calls the IAM Security Token Service to assume that IAM Role. The application can use the temporary credentials to access the appropriate S3 bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The application authenticates against IAM Security Token Service using the LDAP credentials. The application uses those temporary AWS security credentials to access the appropriate S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Develop an identity broker which authenticates against LDAP, and then calls IAM Security Token Service to get IAM federated user credentials. The application calls the identity broker to get IAM federated user credentials with access to the appropriate S3 bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Develop an identity broker which authenticates against IAM Security Token Service to assume an IAM Role to get temporary AWS security credentials. The application calls the identity broker to get AWS temporary security credentials with access to the appropriate S3 bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 25,
          "poolQNum": 152,
          "question": {
            "id": 25,
            "questionText": "A company is using Amazon API Gateway to manage its public-facing API. The CISO requires that the APIs be used by test account users only. What is the MOST secure way to restrict API access to users of this particular AWS account?",
            "questionImage": null,
            "options": [
              {
                "text": "Client-side SSL certificates for authentication.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "API Gateway resource policies.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Cross-origin resource sharing (CORS).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Usage plans.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 26,
          "poolQNum": 258,
          "question": {
            "id": 26,
            "questionText": "An Amazon S3 bucket, `myawsbucket` is configured with website hosting in Tokyo region, what is the region-specific website endpoint?",
            "questionImage": null,
            "options": [
              {
                "text": "`www.myawsbucket.ap-northeast-1.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`myawsbucket.s3-website-ap-northeast-1.amazonaws.com`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`myawsbucket.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`myawsbucket.tokyo.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 27,
          "poolQNum": 342,
          "question": {
            "id": 27,
            "questionText": "A company recently migrated its web, application and NoSQL database tiers to AWS. The company is using Auto Scaling to scale the web and application tiers. More than 95 percent of the Amazon DynamoDB requests are repeated read requests. How can the DynamoDB NoSQL tier be scaled up to cache these repeated requests?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon EMR.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon DynamoDB Accelerator.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon SQS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 28,
          "poolQNum": 58,
          "question": {
            "id": 28,
            "questionText": "A Developer is creating a web application that requires authentication, but also needs to support guest access to provide users limited access without having to authenticate. What service can provide support for the application to allow guest access?",
            "questionImage": null,
            "options": [
              {
                "text": "IAM temporary credentials using AWS STS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Directory Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito with unauthenticated access enabled.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "IAM with SAML integration",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 29,
          "poolQNum": 354,
          "question": {
            "id": 29,
            "questionText": "The upload of a 15 GB object to Amazon S3 fails. The error message reads: `Your proposed upload exceeds the maximum allowed object size.`. What technique will allow the Developer to upload this object?",
            "questionImage": null,
            "options": [
              {
                "text": "Upload the object using the multi-part upload API.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload the object over an AWS Direct Connect connection.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Contact AWS Support to increase the object size limit.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload the object to another AWS region.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 30,
          "poolQNum": 193,
          "question": {
            "id": 30,
            "questionText": "A Software Engineer developed an AWS Lambda function in Node.js to do some CPU-intensive data processing. With the default settings, the Lambda function takes about 5 minutes to complete. Which approach should a Developer take to increase the speed of completion?",
            "questionImage": null,
            "options": [
              {
                "text": "Instead of using Node.js, rewrite the Lambda function using Python.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Instead of packaging the libraries in the `ZIP` file with the function, move them to a Lambda layer and use the layer with the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Allocate the maximum available CPU units to the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the available memory to the function.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 31,
          "poolQNum": 326,
          "question": {
            "id": 31,
            "questionText": "An AWS Elastic Beanstalk application needs to be deployed in multiple regions and requires a different Amazon Machine Image (AMI) in each region. Which AWS CloudFormation template key can be used to specify the correct AMI for each region?",
            "questionImage": null,
            "options": [
              {
                "text": "`Parameters`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`Outputs`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`Mappings`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`Resources`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 32,
          "poolQNum": 50,
          "question": {
            "id": 32,
            "questionText": "The release process workflow of an application requires a manual approval before the code is deployed into the production environment. What is the BEST way to achieve this using AWS CodePipeline?",
            "questionImage": null,
            "options": [
              {
                "text": "Use multiple pipelines to allow approval.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an approval action in a stage.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Disable the stage transition to allow manual approval.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disable a stage just prior the deployment stage.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 33,
          "poolQNum": 169,
          "question": {
            "id": 33,
            "questionText": "A Developer is preparing a deployment package using AWS CloudFormation. The package consists of two separate templates: one for the infrastructure and one for the application. The application has to be inside the VPC that is created from the infrastructure template. How can the application stack refer to the VPC created from the infrastructure template?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the Ref function to import the VPC into the application stack from the infrastructure template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the export flag in the infrastructure template, and then use the `Fn::ImportValue` function in the application template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use the `DependsOn` attribute to specify that the application instance depends on the VPC in the application template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `Fn::GetAtt` function to include the attribute of the VPC in the application template.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 34,
          "poolQNum": 160,
          "question": {
            "id": 34,
            "questionText": "An application is using a single-node Amazon ElastiCache for Redis instance to improve read performance. Over time, demand for the application has increased exponentially, which has increased the load on the ElastiCache instance. It is critical that this cache layer handles the load and is resilient in case of node failures. What can the Developer do to address the load and resiliency requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Add a read replica instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Migrate to a Memcached cluster.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Migrate to an Amazon Elasticsearch Service cluster.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Vertically scale the ElastiCache instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 35,
          "poolQNum": 360,
          "question": {
            "id": 35,
            "questionText": "An application uses Lambda functions to extract metadata from files uploaded to an S3 bucket; the metadata is stored in Amazon DynamoDB. The application starts behaving unexpectedly, and the Developer wants to examine the logs of the Lambda function code for errors. Based on this system configuration, where would the Developer find the logs?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CloudTrail.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon CloudWatch.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon DynamoDB",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 36,
          "poolQNum": 307,
          "question": {
            "id": 36,
            "questionText": "A Developer is creating a serverless website with content that includes HTML files, images, videos, and JavaScript (client-side scripts). Which combination of services should the Developer use to create the website?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon S3 and Amazon CloudFront.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon EC2 and Amazon ElastiCache.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon ECS and Redis.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Lambda and Amazon API Gateway.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 37,
          "poolQNum": 144,
          "question": {
            "id": 37,
            "questionText": "A development team is building a new application that will run on Amazon EC2 and use Amazon DynamoDB as a storage layer. The developers all have assigned IAM user accounts in the same IAM group. The developers currently can launch EC2 instances, and they need to be able to launch EC2 instances with an instance role allowing access to Amazon DynamoDB. Which AWS IAM changes are needed when creating an instance role to provide this functionality?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM permission policy attached to the role that allows access to DynamoDB. Add a trust policy to the role that allows DynamoDB to assume the role. Attach a permissions policy to the development group in AWS IAM that allows developers to use the iam:GetRole and iam:PassRole permissions for the role.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM permissions policy attached to the role that allows access to DynamoDB. Add a trust policy to the role that allows Amazon EC2 to assume the role. Attach a permissions policy to the development group in AWS IAM that allows developers to use the iam:PassRole permission for the role.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an IAM permission policy attached to the role that allows access to Amazon EC2. Add a trust policy to the role that allows DynamoDB to assume the role. Attach a permissions policy to the development group in AWS IAM that allows developers to use the iam:PassRole permission for the role.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM permissions policy attached to the role that allows access to DynamoDB. Add a trust policy to the role that allows Amazon EC2 to assume the role. Attach a permissions policy to the development group in AWS IAM that allows developers to use the iam:GetRole permission for the role.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 38,
          "poolQNum": 121,
          "question": {
            "id": 38,
            "questionText": "An application needs to encrypt data that is written to Amazon S3 where the keys are managed in an on-premises data center, and the encryption is handled by S3. Which type of encryption should be used?",
            "questionImage": null,
            "options": [
              {
                "text": "Use server-side encryption with Amazon S3-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use server-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use client-side encryption with customer master keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use server-side encryption with customer-provided keys.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 39,
          "poolQNum": 249,
          "question": {
            "id": 39,
            "questionText": "What is one key difference between an Amazon EBS-backed and an instance-store backed instance?",
            "questionImage": null,
            "options": [
              {
                "text": "Virtual Private Cloud requires EBS backed instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon EBS-backed instances can be stopped and restarted.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Auto scaling requires using Amazon EBS-backed instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Instance-store backed instances can be stopped and restarted.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 40,
          "poolQNum": 370,
          "question": {
            "id": 40,
            "questionText": "A social media company is using Amazon Cognito in order to synchronize profiles across different mobile devices, to enable end users to have a seamless experience. Which of the following configurations can be used to silently notify users whenever an update is available on all other devices?",
            "questionImage": null,
            "options": [
              {
                "text": "Modify the user pool to include all the devices which keep them in sync.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the SyncCallback interface to receive notifications on the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon Cognito stream to analyze the data and push the notifications.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the push synchronization feature with the appropriate IAM role.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 41,
          "poolQNum": 387,
          "question": {
            "id": 41,
            "questionText": "Amazon S3 has the following structure: `S3://BUCKET/FOLDERNAME/FILENAME.zip`. Which S3 best practice would optimize performance with thousands of PUT request each second to a single bucket?",
            "questionImage": null,
            "options": [
              {
                "text": "Prefix folder names with user id; for example, `s3://BUCKET/2013-FOLDERNAME/FILENAME.zip`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Prefix file names with timestamps; for example, `s3://BUCKET/FOLDERNAME/2013-26-05-15-00-00-FILENAME.zip`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Prefix file names with random hex hashes; for example, `s3://BUCKET/FOLDERNAME/23a6-FILENAME.zip`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Prefix folder names with random hex hashes; for example, `s3://BUCKET/23a6-FOLDERNAME/FILENAME.zip`.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 42,
          "poolQNum": 181,
          "question": {
            "id": 42,
            "questionText": "A Developer has written an Amazon Kinesis Data Streams application. As usage grows and traffic increases over time, the application is regularly receiving `ProvisionedThroughputExceededException` error messages. Which steps should the Developer take to resolve the error? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Use Auto Scaling to scale the stream for better performance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the delay between the `GetRecords` call and the `PutRecords` call.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the number of shards in the data stream.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Specify a shard iterator using the `ShardIterator` parameter.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement exponential backoff on the `GetRecords` call and the `PutRecords` call.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 43,
          "poolQNum": 21,
          "question": {
            "id": 43,
            "questionText": "An application uses Amazon Kinesis Data Streams to ingest and process large streams of data records in real time. Amazon EC2 instances consume and process the data from the shards of the Kinesis data stream by using Amazon Kinesis Client Library (KCL). The application handles the failure scenarios and does not require standby workers. The application reports that a specific shard is receiving more data than expected. To adapt to the changes in the rate of data flow, the `hot` shard is resharded. Assuming that the initial number of shards in the Kinesis data stream is 4, and after resharding the number of shards increased to 6, what is the maximum number of EC2 instances that can be deployed to process data from all the shards?",
            "questionImage": null,
            "options": [
              {
                "text": "12.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "6.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "4.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 44,
          "poolQNum": 210,
          "question": {
            "id": 44,
            "questionText": "A company wants to implement authentication for its new REST service using Amazon API Gateway. To authenticate the calls, each request must include HTTP headers with a client ID and user ID. These credentials must be compared to authentication data in an Amazon DynamoDB table. What MUST the company do to implement this authentication in API Gateway?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement an AWS Lambda authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a model that requires the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the integration requests to require the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement an Amazon Cognito authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 45,
          "poolQNum": 295,
          "question": {
            "id": 45,
            "questionText": "A Developer is investigating an issue whereby certain requests are passing through an Amazon API Gateway endpoint /MyAPI, but the requests do not reach the AWS Lambda function backing /MyAPI. The Developer found that a second Lambda function sometimes runs at maximum concurrency allowed for the given AWS account. How can the Developer address this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Manually reduce the concurrent execution limit at the account level.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add another API Gateway stage for /MyAPI, and shard the requests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure the second Lambda function's concurrency execution limit.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Reduce the throttling limits in the API Gateway /MyAPI endpoint",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 46,
          "poolQNum": 2,
          "question": {
            "id": 46,
            "questionText": "Which of the following services are key/value stores? (Choose 3 answers)",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon ElastiCache.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Simple Notification Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Simple Workflow Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Simple Storage Service.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 47,
          "poolQNum": 305,
          "question": {
            "id": 47,
            "questionText": "A company has an application that logs all information to Amazon S3. Whenever there is a new log file, an AWS Lambda function is invoked to process the log files. The code works, gathering all of the necessary information. However, when checking the Lambda function logs, duplicate entries with the same request ID are found. What is causing the duplicate entries?",
            "questionImage": null,
            "options": [
              {
                "text": "The S3 bucket name was specified incorrectly.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The Lambda function failed, and the Lambda service retired the invocation with a delay.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "There was an S3 outage, which caused duplicate entries of the sale log file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The application stopped intermittently and then resumed.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 48,
          "poolQNum": 341,
          "question": {
            "id": 48,
            "questionText": "A company has multiple Developers located across the globe who are updating code incrementally for a development project. When Developers upload code concurrently, internet connectivity is slow and it is taking a long time to upload code for deployment in AWS Elastic Beanstalk. Which step will result in minimized upload and deployment time with the LEAST amount of administrative effort?",
            "questionImage": null,
            "options": [
              {
                "text": "Allow the Developers to upload the code to an Amazon S3 bucket, and deploy it directly to Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Allow the Developers to upload the code to a central FTP server to deploy the application to Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an AWS CodeCommit repository, allow the Developers to commit code to it, and then directly deploy the code to Elastic Beanstalk.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a code repository on an Amazon EC2 instance so that all Developers can update the code, and deploy the application from the instance to Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 49,
          "poolQNum": 297,
          "question": {
            "id": 49,
            "questionText": "A Developer created configuration specifications for an AWS Elastic Beanstalk application in a file named healthcheckurl.yaml in the `.ebextensions/directory` of their application source bundle. The file contains the following: After the application launches, the health check is not being run on the correct path, even though it is valid. What can be done to correct this configuration file?",
            "questionImage": "images/question297.jpeg",
            "options": [
              {
                "text": "Convert the file to JSON format.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rename the file to a `.config` extension.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Change the configuration section from `options_settings` to resources.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the namespace of the option settings to a custom namespace.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 50,
          "poolQNum": 140,
          "question": {
            "id": 50,
            "questionText": "A development team uses AWS Elastic Beanstalk for application deployment. The team has configured the application version lifecycle policy to limit the number of application versions to 25. However, even with the lifecycle policy, the source bundle is deleted from the Amazon S3 source bucket. What should a developer do in the Elastic Beanstalk application version lifecycle settings to retain the source code in the S3 bucket?",
            "questionImage": null,
            "options": [
              {
                "text": "Change the Set the application versions limit by total count setting to zero.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disable the Lifecycle policy setting.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the Set the application version limit by age setting to zero.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set Retention to Retain source bundle in S3.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 51,
          "poolQNum": 72,
          "question": {
            "id": 51,
            "questionText": "An application will ingest data at a very high throughput from many sources and must store the data in an Amazon S3 bucket. Which service would BEST accomplish this task?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon Kinesis Firehose.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3 Acceleration Transfer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SQS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SNS.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 52,
          "poolQNum": 340,
          "question": {
            "id": 52,
            "questionText": "What does an Amazon SQS delay queue accomplish?",
            "questionImage": null,
            "options": [
              {
                "text": "Messages are hidden for a configurable amount of time when they are first added to the queue.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Messages are hidden for a configurable amount of time after they are consumed from the queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The consumer can poll the queue for a configurable amount of time before retrieving a message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Message cannot be deleted for a configurable amount of time after they are consumed from the queue.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 53,
          "poolQNum": 93,
          "question": {
            "id": 53,
            "questionText": "A Developer is developing an application that manages financial transactions. To improve security, multi-factor authentication (MFA) will be required as part of the login protocol. What services can the Developer use to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon DynamoDB to store MFA session data, and Amazon SNS to send MFA codes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito with MFA.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Directory Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS IAM with MFA enabled.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 54,
          "poolQNum": 257,
          "question": {
            "id": 54,
            "questionText": "Company B provides an online image recognition service and utilizes SQS to decouple system components for scalability The SQS consumers poll the imaging queue as often as possible to keep end-to-end throughput as high as possible. However, Company B is realizing that polling in tight loops is burning CPU cycles and increasing costs with empty responses. How can Company B reduce the number of empty responses?",
            "questionImage": null,
            "options": [
              {
                "text": "Set the imaging queue visibility `Timeout` attribute to 20 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set the Imaging queue `ReceiveMessageWaitTimeSeconds` attribute to 20 seconds.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set the imaging queue `MessageRetentionPeriod` attribute to 20 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set the `DelaySeconds` parameter of a message to 20 seconds.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 55,
          "poolQNum": 111,
          "question": {
            "id": 55,
            "questionText": "An application under development is required to store hundreds of video files. The data must be encrypted within the application prior to storage, with a unique key for each video file. How should the Developer code the application?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the `KMS Encrypt` API to encrypt the data. Store the encrypted data key and data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use a cryptography library to generate an encryption key for the application. Use the encryption key to encrypt the data. Store the encrypted data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `KMS GenerateDataKey` API to get a data key. Encrypt the data with the data key. Store the encrypted data key and data.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload the data to an S3 bucket using server side-encryption with an AWS KMS key.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 56,
          "poolQNum": 328,
          "question": {
            "id": 56,
            "questionText": "A Developer has published an update to an application that is served to a global user base using Amazon CloudFront. After deploying the application, users are not able to see the updated changes. How can the Developer resolve this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Remove the origin from the CloudFront configuration and add it again.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disable forwarding of query strings and request headers from the CloudFront distribution configuration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Invalidate all the application objects from the edge caches.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Disable the CloudFront distribution and enable it again to update all the edge locations.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 57,
          "poolQNum": 106,
          "question": {
            "id": 57,
            "questionText": "A Developer wants to use AWS X-Ray to trace a user request end-to-end throughput the software stack. The Developer made the necessary changes in the application tested it, and found that the application is able to send the traces to AWS X-Ray. However, when the application is deployed to an EC2 instance, the traces are not availableWhich of the following could create this situation? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "The traces are reaching X-Ray, but the Developer does not have access to view the records.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The X-Ray daemon is not installed on the EC2 instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The X-Ray endpoint specified in the application configuration is incorrect.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The instance role does not have `xray:BatchGetTraces` and `xray:GetTraceGraph` permissions.The instance role does not have `xray:PutTraceSegments` and `xray:PutTelemetryRecords` permissions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The instance role does not have `xray:PutTraceSegments` and `xray:PutTelemetryRecords` permissions.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 58,
          "poolQNum": 343,
          "question": {
            "id": 58,
            "questionText": "A Development team is working on a case management solution that allows medical claims to be processed and reviewed. Users log in to provide information related to their medical and financial situations. As part of the application, sensitive documents such as medical records, medical imaging, bank statements, and receipts are uploaded to Amazon S3. All documents must be securely transmitted and stored. All access to the documents must be recorded for auditing. What is the MOST secure approach?",
            "questionImage": null,
            "options": [
              {
                "text": "Use S3 default encryption using Advanced Encryption Standard-256 (AES-256) on the destination bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito for authorization and authentication to ensure the security of the application and documents.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Lambda to encrypt and decrypt objects as they are placed into the S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use client-side encryption/decryption with Amazon S3 and AWS KMS.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 59,
          "poolQNum": 123,
          "question": {
            "id": 59,
            "questionText": "A development team wants to run their container workloads on Amazon ECS. Each application container needs to share data with another container to collect logs and metrics. What should the developer team do to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Create two pod specifications. Make one to include the application container and the other to include the other container. Link the two pods together.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create two task definitions. Make one to include the application container and the other to include the other container. Mount a shared volume between the two tasks.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create one task definition. Specify both containers in the definition. Mount a shared volume between those two containers.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a single pod specification. Include both containers in the specification. Mount a persistent volume to both containers.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 60,
          "poolQNum": 205,
          "question": {
            "id": 60,
            "questionText": "A company is developing a web application that allows its employees to upload a profile picture to a private Amazon S3 bucket. There is no size limit for the profile pictures, which should be displayed every time an employee logs in. For security reasons, the pictures cannot be publicly accessible. What is a viable long-term solution for this scenario?",
            "questionImage": null,
            "options": [
              {
                "text": "Generate a presigned URL when a picture is uploaded. Save the URL in an Amazon DynamoDB table. Return the URL to the browser when the employee logs in.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Save the picture's S3 key in an Amazon DynamoDB table. Create an Amazon S3 VPC endpoint to allow the employees to download pictures once they log in.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Encode a picture using base64. Save the base64 string in an Amazon DB table. Allow the browser to retrieve the string and convert it to a picture.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Save the picture's S3 key in an Amazon DynamoDB table. Use a function to generate a presigned URL every time an employee logs in. Return the URL to the browser.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 61,
          "poolQNum": 381,
          "question": {
            "id": 61,
            "questionText": "An existing serverless application processes uploaded image files. The process currently uses a single Lambda function that takes an image file, performs the processing, and stores the file in Amazon S3. Users of the application now require thumbnail generation of the images. Users want to avoid any impact to the time it takes to perform the image uploads. How can thumbnail generation be added to the application, meeting user requirements while minimizing changes to existing code?",
            "questionImage": null,
            "options": [
              {
                "text": "Change the existing Lambda function handling the uploads to create thumbnails at the time of upload. Have the function store both the image and thumbnail in Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a second Lambda function that handles thumbnail generation and storage. Change the existing Lambda function to invoke it asynchronously.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an S3 event notification with a Lambda function destination. Create a new Lambda function to generate and store thumbnails.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an S3 event notification to an SQS Queue. Create a scheduled Lambda function that processes the queue, and generates and stores thumbnails.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 62,
          "poolQNum": 33,
          "question": {
            "id": 62,
            "questionText": "A company is using AWS CloudFormation templates to deploy AWS resources. The company needs to update one of its AWS CloudFormation stacks. What can the company do to find out how the changes will impact the resources that are running?",
            "questionImage": null,
            "options": [
              {
                "text": "Investigate the change sets.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Investigate the stack policies.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Investigate the `Metadata` section.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Investigate the `Resources` section.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 63,
          "poolQNum": 38,
          "question": {
            "id": 63,
            "questionText": "A website's page load times are gradually increasing as more users access the system at the same time. Analysis indicates that a user profile is being loaded from a database in all the web pages being visited by each user and this is increasing the database load and the page load latency. To address this issue the Developer decides to cache the user profile data. Which caching strategy will address this situation MOST efficiently?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a new Amazon EC2 Instance and run a NoSQL database on it. Cache the profile data within this database using the write-through caching strategy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon ElastiCache cluster to cache the user profile data. Use a cache-aside caching strategy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use a dedicated Amazon RDS instance for caching profile data. Use a write-through caching strategy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an ElastiCache cluster to cache the user profile data. Use a write-through caching strategy.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 64,
          "poolQNum": 351,
          "question": {
            "id": 64,
            "questionText": "An on-premises application makes repeated calls to store files to Amazon S3. As usage of the application has increased, `LimitExceeded` errors are being logged. What should be changed to fix this error?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement exponential backoffs in the application.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Load balance the application to multiple servers.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Move the application to Amazon EC2.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a one second delay to each API call.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 65,
          "poolQNum": 348,
          "question": {
            "id": 65,
            "questionText": "While developing an application that runs on Amazon EC2 in an Amazon VPC, a Developer identifies the need for centralized storage of application-level logs. Which AWS service can be used to securely store these logs?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon EC2 VPC Flow Logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon CloudWatch Logs.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon CloudSearch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CloudTrail",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        }
      ],
      "questionMap": {
        "1": 317,
        "2": 142,
        "3": 116,
        "4": 296,
        "5": 17,
        "6": 26,
        "7": 274,
        "8": 18,
        "9": 256,
        "10": 282,
        "11": 223,
        "12": 191,
        "13": 81,
        "14": 245,
        "15": 208,
        "16": 8,
        "17": 31,
        "18": 78,
        "19": 383,
        "20": 345,
        "21": 7,
        "22": 103,
        "23": 1,
        "24": 267,
        "25": 152,
        "26": 258,
        "27": 342,
        "28": 58,
        "29": 354,
        "30": 193,
        "31": 326,
        "32": 50,
        "33": 169,
        "34": 160,
        "35": 360,
        "36": 307,
        "37": 144,
        "38": 121,
        "39": 249,
        "40": 370,
        "41": 387,
        "42": 181,
        "43": 21,
        "44": 210,
        "45": 295,
        "46": 2,
        "47": 305,
        "48": 341,
        "49": 297,
        "50": 140,
        "51": 72,
        "52": 340,
        "53": 93,
        "54": 257,
        "55": 111,
        "56": 328,
        "57": 106,
        "58": 343,
        "59": 123,
        "60": 205,
        "61": 381,
        "62": 33,
        "63": 38,
        "64": 351,
        "65": 348
      }
    },
    {
      "id": "1763970263270",
      "timestamp": 1763970263270,
      "score": "0.00",
      "results": [
        {
          "qNum": 1,
          "poolQNum": 339,
          "question": {
            "id": 1,
            "questionText": "An application running on Amazon EC2 instances must access objects within an Amaon S3 busket that are encrypted using server-side encryption using AWS KMS encryption keys (SSE-KMS). The application must have access to the customer master key (CMK) to decrypt the objects. Which combination of steps will grant the application access? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Write an S3 bucket policy that grants the bucket access to the key.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Grant access to the key in the IAM EC2 role attached to the application's EC2 instances.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Write a key policy that enables IAM policies to grant access to the key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Grant access to the key in the S3 bucket's ACL.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a Systems Manager parameter that exposes the KMS key to the EC2 instances.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 2,
          "poolQNum": 271,
          "question": {
            "id": 2,
            "questionText": "A team of Developers must migrate an application running inside an AWS Elastic Beanstalk environment from a Classic Load Balancer to an Application Load Balancer. Which steps should be taken to accomplish the task using the AWS Management Console?",
            "questionImage": null,
            "options": [
              {
                "text": "1. Update the application code in the existing deployment. 2. Select a new load balancer type before running the deployment. 3. Deploy the new version of the application code to the environment.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "1. Create a new environment with the same configurations except for the load balancer type. 2. Deploy the same application version as used in the original environment. 3. Run the `swap-environment-cnames` action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1. Clone the existing environment, changing the associated load balancer type. 2. Deploy the same application version as used in the original environment. 3. Run the `swap-environment-cnames` action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1. Edit the environment definitions in the existing deployment. 2. Change the associated load balancer type according to the requirements. 3. Rebuild the environment with the new load balancer type.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 3,
          "poolQNum": 6,
          "question": {
            "id": 3,
            "questionText": "A Developer wants to encrypt new objects that are being uploaded to an Amazon S3 bucket by an application. There must be an audit trail of who has used the key during this process. There should be no change to the performance of the application. Which type of encryption meets these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Server-side encryption using S3-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client-side encryption with a client-side symmetric master key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Client-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 4,
          "poolQNum": 152,
          "question": {
            "id": 4,
            "questionText": "A company is using Amazon API Gateway to manage its public-facing API. The CISO requires that the APIs be used by test account users only. What is the MOST secure way to restrict API access to users of this particular AWS account?",
            "questionImage": null,
            "options": [
              {
                "text": "Client-side SSL certificates for authentication.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "API Gateway resource policies.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Cross-origin resource sharing (CORS).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Usage plans.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 5,
          "poolQNum": 203,
          "question": {
            "id": 5,
            "questionText": "A Developer is storing sensitive data generated by an application in Amazon S3. The Developer wants to encrypt the data at rest. A company policy requires an audit trail of when the master key was used and by whom. Which encryption option will meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Server-side encryption with Amazon S3 managed keys (SSE-S3).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with AWS KMS managed keys (SSE-KMS).",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Server-side encryption with customer-provided keys (SSE-C).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with self-managed keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 6,
          "poolQNum": 183,
          "question": {
            "id": 6,
            "questionText": "A Developer has code running on Amazon EC2 instances that needs read-only access to an Amazon DynamoDB table. What is the MOST secure approach the Developer should take to accomplish this task?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a user access key for each EC2 instance with read-only access to DynamoDB. Place the keys in the code. Redeploy the code as keys rotate.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an IAM role with an AmazonDynamoDBReadOnlyAccess policy applied to the EC2 instances.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Run all code with only AWS account root user access keys to ensure maximum access to services.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an IAM role with Administrator access applied to the EC2 instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 7,
          "poolQNum": 278,
          "question": {
            "id": 7,
            "questionText": "A Developer has been asked to create an AWS Lambda function that is triggered any time updates are made to items in an Amazon DynamoDB table. The function has been created, and appropriate permissions have been added to the Lambda execution role. Amazon DynamoDB streams have been enabled for the table, but the function is still not being triggered. Which option would enable DynamoDB table updates to trigger the Lambda function?",
            "questionImage": null,
            "options": [
              {
                "text": "Change the `StreamViewType` parameter value to `NEW_AND_OLD_IMAGES` for the DynamoDB table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure event source mapping for the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Map an Amazon SNS topic to the DynamoDB streams.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the maximum execution time (timeout) setting of the Lambda function.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 8,
          "poolQNum": 157,
          "question": {
            "id": 8,
            "questionText": "An application is experiencing performance issues based on increased demand. This increased demand is on read-only historical records pulled from an Amazon RDS-hosted database with custom views and queries. A Developer must improve performance without changing the database structure. Which approach will improve performance and MINIMIZE management overhead?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy Amazon DynamoDB, move all the data, and point to DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy Amazon ElastiCache for Redis and cache the data for the application.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Deploy Memcached on Amazon EC2 and cache the data for the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy Amazon DynamoDB Accelerator (DAX) on Amazon RDS to improve cache performance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 9,
          "poolQNum": 261,
          "question": {
            "id": 9,
            "questionText": "You run an ad-supported photo sharing website using S3 to serve photos to visitors of your site. At some point you find out that other sites have been linking to the photos on your site, causing loss to your business. What is an effective method to mitigate this?",
            "questionImage": null,
            "options": [
              {
                "text": "Store photos on an EBS volume of the web server.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Remove public read access and use signed URLs with expiry dates.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use CloudFront distributions for static content.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Block the IPs of the offending websites in Security Groups.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 10,
          "poolQNum": 359,
          "question": {
            "id": 10,
            "questionText": "An application is using Amazon DynamoDB as its data store, and should be able to read 100 items per second as strongly consistent reads. Each item is 5 KB in size. To what value should the table's provisioned read throughput be set?",
            "questionImage": null,
            "options": [
              {
                "text": "50 read capacity units.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "100 read capacity units.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "200 read capacity units.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "500 read capacity units.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 11,
          "poolQNum": 48,
          "question": {
            "id": 11,
            "questionText": "The Lambda function below is being called through an API using Amazon API Gateway. The average execution time for the Lambda function is about 1 second. The pseudocode for the Lambda function is as shown in the exhibit. What two actions can be taken to improve the performance of this Lambda function without increasing the cost of the solution? (Select TWO)",
            "questionImage": "images/question48.jpg",
            "options": [
              {
                "text": "Package only the modules the Lambda function requires.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Amazon DynamoDB instead of Amazon RDS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Move the initialization of the variable Amazon RDS connection outside of the handler function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Implement custom database connection pooling with the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement local caching of Amazon RDS data so Lambda can re-use the cache.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 12,
          "poolQNum": 282,
          "question": {
            "id": 12,
            "questionText": "An AWS Lambda function must access an external site by using a regularly rotated user name and password. These items must be kept securely and cannot be stored in the function code. What combination of AWS services can be used to accomplish this? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "AWS Certificate Manager (ACM).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Systems Manager Parameter Store.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Trusted Advisor.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS KMS.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon GuardDuty.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 13,
          "poolQNum": 77,
          "question": {
            "id": 13,
            "questionText": "A Developer has an application that can upload tens of thousands of objects per second to Amazon S3 in parallel within a single AWS account. As part of new requirements, data stored in S3 must use server side encryption with AWS KMS (SSE-KMS). After creating this change, performance of the application is slower. Which of the following is MOST likely the cause of the application latency?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon S3 throttles the rate at which uploaded objects can be encrypted using Customer Master Keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The AWS KMS API calls limit is less than needed to achieve the desired performance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The client encryption of the objects is using a poor algorithm.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "KMS requires that an alias be used to create an independent display name that can be mapped to a CM.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 14,
          "poolQNum": 175,
          "question": {
            "id": 14,
            "questionText": "A Developer is writing an application in AWS Lambda. To simplify testing and deployments, the Developer needs the database connection string to be easily changed without modifying the Lambda code. How can this requirement be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Store the connection string as a secret in AWS Secrets Manager.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the connection string in an IAM user account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the connection string in AWS KMS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the connection string as a Lambda layer.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 15,
          "poolQNum": 55,
          "question": {
            "id": 15,
            "questionText": "A company wants to migrate its web application to AWS and leverage Auto Scaling to handle peak workloads. The Solutions Architect determined that the best metric for an Auto Scaling event is the number of concurrent users. Based on this information, what should the Developer use to autoscale based on concurrent users?",
            "questionImage": null,
            "options": [
              {
                "text": "An Amazon SNS topic to be triggered when a concurrent user threshold is met.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An Amazon Cloudwatch NetworkIn metric.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon CloudFront to leverage AWS Edge Locations.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A Custom Amazon CloudWatch metric for concurrent users.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 16,
          "poolQNum": 279,
          "question": {
            "id": 16,
            "questionText": "A company is running a Docker application on Amazon ECS. The application must scale based on user load in the last 15 seconds. How should a Developer instrument the code so that the requirement can be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 30 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a standard-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 30 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a standard-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 17,
          "poolQNum": 333,
          "question": {
            "id": 17,
            "questionText": "A Developer is designing a fault-tolerant environment where client sessions will be saved. How can the Developer ensure that no sessions are lost if an Amazon EC2 instance fails?",
            "questionImage": null,
            "options": [
              {
                "text": "Use sticky sessions with an Elastic Load Balancer target group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon SQS to save session data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon DynamoDB to perform scalable session handling.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Elastic Load Balancer connection draining to stop sending requests to failing instances.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 18,
          "poolQNum": 337,
          "question": {
            "id": 18,
            "questionText": "A company is building an application to track athlete performance using an Amazon DynamoDB table. Each item in the table is identified by a partition key (`user_id`) and a sort key (`sport_name`). The table design is shown below. (Note: Not all table attributes are shown) A Developer is asked to write a leaderboard application to display the top performers (`user_id`) based on the score for each `sport_name`. What process will allow the Developer to extract results MOST efficiently from the DynamoDB table?",
            "questionImage": "images/question337.jpg",
            "options": [
              {
                "text": "Use a DynamoDB query operation with the key attributes of `user_id` and `sport_name` and order the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a global secondary index with a partition key of `sport_name` and a sort key of score, and get the results.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use a DynamoDB scan operation to retrieve scores and `user_id` based on `sport_name`, and order the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a local secondary index with a primary key of `sport_name` and a sort key of score and get the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 19,
          "poolQNum": 221,
          "question": {
            "id": 19,
            "questionText": "What is the maximum number of S3 Buckets available per AWS account?",
            "questionImage": null,
            "options": [
              {
                "text": "100 per region.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "there is no limit.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1,000,000 per account.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "500 per account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "100 per IAM user.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 20,
          "poolQNum": 121,
          "question": {
            "id": 20,
            "questionText": "An application needs to encrypt data that is written to Amazon S3 where the keys are managed in an on-premises data center, and the encryption is handled by S3. Which type of encryption should be used?",
            "questionImage": null,
            "options": [
              {
                "text": "Use server-side encryption with Amazon S3-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use server-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use client-side encryption with customer master keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use server-side encryption with customer-provided keys.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 21,
          "poolQNum": 184,
          "question": {
            "id": 21,
            "questionText": "A Developer migrated a web application to AWS. As part of the migration, the Developer implemented an automated continuous integration/continuous improvement (CI/CD) process using a blue/green deployment. The deployment provisions new Amazon EC2 instances in an Auto Scaling group behind a new Application Load Balancer. After the migration was completed, the Developer began receiving complaints from users getting booted out of the system. The system also requires users to log in after every new deployment. How can these issues be resolved?",
            "questionImage": null,
            "options": [
              {
                "text": "Use rolling updates instead of a blue/green deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Externalize the user sessions to Amazon ElastiCache.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Turn on sticky sessions in the Application Load Balancer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use multicast to replicate session information.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 22,
          "poolQNum": 328,
          "question": {
            "id": 22,
            "questionText": "A Developer has published an update to an application that is served to a global user base using Amazon CloudFront. After deploying the application, users are not able to see the updated changes. How can the Developer resolve this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Remove the origin from the CloudFront configuration and add it again.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disable forwarding of query strings and request headers from the CloudFront distribution configuration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Invalidate all the application objects from the edge caches.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Disable the CloudFront distribution and enable it again to update all the edge locations.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 23,
          "poolQNum": 78,
          "question": {
            "id": 23,
            "questionText": "A customer wants to deploy its source code on an AWS Elastic Beanstalk environment. The customer needs to perform deployment with minimal outage and should only use existing instances to retain application access log. What deployment policy would satisfy these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Rolling.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "All at once.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling with an additional batch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Immutable.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 24,
          "poolQNum": 164,
          "question": {
            "id": 24,
            "questionText": "A Developer must allow guest users without logins to access an Amazon Cognito-enabled site to view files stored within an Amazon S3 bucket. How should the Developer meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a blank user ID in a user pool, add to the user group, and grant access to AWS resources.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a new identity pool, enable access to unauthenticated identities, and grant access to AWS resources.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a new user pool, enable access to authenticated identifies, and grant access to AWS resources.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a new user pool, disable authentication access, and grant access to AWS resources.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 25,
          "poolQNum": 217,
          "question": {
            "id": 25,
            "questionText": "A Development team would like to migrate their existing application code from a GitHub repository to AWS CodeCommit. What needs to be created before they can migrate a cloned repository to CodeCommit over HTTPS?",
            "questionImage": null,
            "options": [
              {
                "text": "A GitHub secure authentication token.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A public and private SSH key file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A set of Git credentials generated from IAM.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An Amazon EC2 IAM role with CodeCommit permissions.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 26,
          "poolQNum": 173,
          "question": {
            "id": 26,
            "questionText": "A Development team decides to adopt a continuous integration/continuous delivery (CI/CD) process using AWS CodePipeline and AWS CodeCommit for a new application. However, management wants a person to review and approve the code before it is deployed to production. How can the Development team add a manual approver to the CI/CD pipeline?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS SES to send an email to approvers when their action is required. Develop a simple application that allows approvers to accept or reject a build. Invoke an AWS Lambda function to advance the pipeline when a build is accepted.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "If approved, add an approved tag when pushing changes to the CodeCommit repository. CodePipeline will proceed to build and deploy approved commits without interruption.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an approval step to CodeCommit. Commits will not be saved until approved.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an approval action to the pipeline. Configure the approval action to publish to an Amazon SNS topic when approval is required. The pipeline execution will stop and wait for an approval.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 27,
          "poolQNum": 19,
          "question": {
            "id": 27,
            "questionText": "A developer has built an application that inserts data into an Amazon DynamoDB table. The table is configured to use provisioned capacity. The application is deployed on a burstable nano Amazon EC2 Instance. The application logs show that the application has been failing because of a `ProvisionedThroughputExceedException` error. Which actions should the developer take to resolve this issue? (Choose two.)",
            "questionImage": null,
            "options": [
              {
                "text": "Move the application to a larger EC instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the number or read capacity units (RCUs) that are provisioned for the DynamoDB table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Reduce the frequency of requests to DynamoDB by implement ng exponential backoff.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Increase the frequency of requests to DynamoDB by decreasing the retry delay.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the capacity mode of the DynamoDB table from provisioned to on-demand.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 28,
          "poolQNum": 139,
          "question": {
            "id": 28,
            "questionText": "An IAM role is attached to an Amazon EC2 instance that explicitly denies access to all Amazon S3 API actions. The EC2 instance credentials file specifies the IAM access key and secret access key, which allow full administrative access. Given that multiple modes of IAM access are present for this EC2 instance, which of the following is correct?",
            "questionImage": null,
            "options": [
              {
                "text": "The EC2 instance will only be able to list the S3 buckets.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The EC2 instance will only be able to list the contents of one S3 bucket at a time.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The EC2 instance will be able to perform all actions on any S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The EC2 instance will not be able to perform any S3 action on any S3 bucket.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 29,
          "poolQNum": 181,
          "question": {
            "id": 29,
            "questionText": "A Developer has written an Amazon Kinesis Data Streams application. As usage grows and traffic increases over time, the application is regularly receiving `ProvisionedThroughputExceededException` error messages. Which steps should the Developer take to resolve the error? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Use Auto Scaling to scale the stream for better performance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the delay between the `GetRecords` call and the `PutRecords` call.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the number of shards in the data stream.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Specify a shard iterator using the `ShardIterator` parameter.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement exponential backoff on the `GetRecords` call and the `PutRecords` call.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 30,
          "poolQNum": 41,
          "question": {
            "id": 30,
            "questionText": "A company stores all personally identifiable information (PII) in an Amazon DynamoDB table named PII in Account A. An application running on Amazon EC2 instances in Account B requires access to the PII table. An administrators in Account A created an IAM role named AccessPII with privileges to access the PII table, and made account B a trusted entity. Which combination of actional steps should Developers take to access the table? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Allow the EC2 IAM role the permission to assume the AccessPII role.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Allow the EC2 IAM role the permission to access the PII table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Include the AWS API in the application code logic to obtain temporary credentials from the EC2 IAM role to access the PII table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Include the `AssumeRole` API operation in the application code logic to obtain temporary credentials to access the PII table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Include the GetSessionToken API operation in the application code logic to obtain temporary credentials to access the PII table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 31,
          "poolQNum": 192,
          "question": {
            "id": 31,
            "questionText": "An application ingests a large number of small messages and stores them in a database. The application uses AWS Lambda. A Development team is making changes to the application's processing logic. In testing, it is taking more than 15 minutes to process each message. The team is concerned the current backend may time out. Which changes should be made to the backend system to ensure each message is processed in the MOST scalable way?",
            "questionImage": null,
            "options": [
              {
                "text": "Add the messages to an Amazon SQS queue. Set up and Amazon EC2 instance to poll the queue and process messages as they arrive.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add the messages to an Amazon SQS queue. Set up Amazon EC2 instances in an Auto Scaling group to poll the queue and process the messages as they arrive.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a support ticket to increase the Lambda timeout to 60 minutes to allow for increased processing time.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the application to directly insert the body of the message into an Amazon RDS database.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 32,
          "poolQNum": 377,
          "question": {
            "id": 32,
            "questionText": "When a Developer tries to run an AWS CodeBuild project, it raises an error because the length of all environment variables exceeds the limit for the combined maximum of characters. What is the recommended solution?",
            "questionImage": null,
            "options": [
              {
                "text": "Add the export `LC_ALL=\"en_US.utf8\"` command to the `pre_build` section to ensure `POSIX` localization.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito to store key-value pairs for large numbers of environment variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the settings for the build project to use an Amazon S3 bucket for large numbers of environment variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Systems Manager Parameter Store to store large numbers of environment variables.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 33,
          "poolQNum": 171,
          "question": {
            "id": 33,
            "questionText": "A Developer is trying to monitor an application's status by running a cron job that returns 1 if the service is up and 0 if the service is down. The Developer created code that uses an AWS CLI `put-metric-alarm` command to publish the custom metrics to Amazon CloudWatch and create an alarm. However, the Developer is unable to create an alarm as the custom metrics do not appear in the CloudWatch console. What is causing this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Sending custom metrics using the CLI is not supported.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The Developer needs to use the `put-metric-data` command.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The Developer must use a unified CloudWatch agent to publish custom metrics.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The code is not running on an Amazon EC2 instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 34,
          "poolQNum": 298,
          "question": {
            "id": 34,
            "questionText": "A Developer has created a Lambda function and is finding that the function is taking longer to complete than expected. After some debugging, the Developer has discovered that increasing compute capacity would improve performance. How can the Developer increase the Lambda compute resources?",
            "questionImage": null,
            "options": [
              {
                "text": "Run on a larger instance size with more compute capacity.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the maximum execution time.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Specify a larger compute capacity when calling the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the allocated memory for the Lambda function.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 35,
          "poolQNum": 194,
          "question": {
            "id": 35,
            "questionText": "An online retail company has deployed a serverless application with AWS Lambda, Amazon API Gateway, Amazon S3, and Amazon DynamoDB using AWS CloudFormation. The company rolled out a new release with major upgrades to the Lambda function and deployed the release to production. Subsequently, the application stopped working. Which solution should bring the application back up as quickly as possible?",
            "questionImage": null,
            "options": [
              {
                "text": "Redeploy the application on Amazon EC2 so the Lambda function can resolve dependencies.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Migrate DynamoDB to Amazon RDS and redeploy the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Roll back the Lambda function to the previous version.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Deploy the latest Lambda function in a different Region.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 36,
          "poolQNum": 91,
          "question": {
            "id": 36,
            "questionText": "A company wants to implement a continuous integration for its workloads on AWS. The company wants to trigger unit test in its pipeline for commits-on its code repository, and wants to be notified of failure events in the pipeline. How can these requirements be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Store the source code in AWS CodeCommit. Create a CodePipeline to automate unit testing. Use Amazon SNS to trigger notifications of failure events.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the source code in GitHub. Create a CodePipeline to automate unit testing. Use Amazon SES to trigger notifications of failure events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the source code on GitHub. Create a CodePipeline to automate unit testing. Use Amazon CloudWatch to trigger notifications of failure events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the source code in AWS CodeCommit. Create a CodePipeline to automate unit testing. Use Amazon CloudWatch to trigger notification of failure events.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 37,
          "poolQNum": 365,
          "question": {
            "id": 37,
            "questionText": "According to best practice, how should access keys be managed in AWS? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Use the same access key in all applications for consistency.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Delete all access keys for the account `root` user.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Leave unused access keys in the account for tracking purposes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Embed and encrypt access keys in code for continuous deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon IAM roles instead of access keys where possible.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 38,
          "poolQNum": 103,
          "question": {
            "id": 38,
            "questionText": "An application stores images in an S3 bucket. Amazon S3 event notifications are used to trigger a Lambda function that resizes the images. Processing each image takes less than a second. How will AWS Lambda handle the additional traffic?",
            "questionImage": null,
            "options": [
              {
                "text": "Lambda will scale out to execute the requests concurrently.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Lambda will handle the requests sequentially in the order received.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Lambda will process multiple images in a single execution.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Lambda will add more compute to each execution to reduce processing time.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 39,
          "poolQNum": 112,
          "question": {
            "id": 39,
            "questionText": "A developer is testing an application that invokes an AWS Lambda function asynchronously. During the testing phase, the Lambda function fails to process after two retries. How can the developer troubleshoot the failure?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure AWS CloudTrail logging to investigate the invocation failures.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure Dead Letter Queues by sending events to Amazon SQS for investigatio.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure Amazon Simple Workflow Service to process any direct unprocessed events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure AWS Config to process any direct unprocessed events.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 40,
          "poolQNum": 97,
          "question": {
            "id": 40,
            "questionText": "A company is using AWS CodeBuild to compile a website from source code stored in AWS CodeCommit. A recent change to the source code has resulted in the CodeBuild project being unable to successfully compile the website. How should the Developer identify the cause of the failures?",
            "questionImage": null,
            "options": [
              {
                "text": "Modify the `buildspec.yml` file to include steps to send the output of build commands to Amazon CloudWatch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use a custom Docker image that includes the AWS X-Ray agent in the AWS CodeBuild project configuration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Check the build logs of the failed phase in the last build attempt in the AWS CodeBuild project build history.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Manually re-run the build process on a local machine so that the output can be visualized.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 41,
          "poolQNum": 148,
          "question": {
            "id": 41,
            "questionText": "A Developer needs to deploy an application running on AWS Fargate using Amazon ECS. The application has environment variables that must be passed to a container for the application to initialize. How should the environment variables be passed to the container?",
            "questionImage": null,
            "options": [
              {
                "text": "Define an array that includes the environment variables under the environment parameter within the service definition.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Define an array that includes the environment variables under the environment parameter within the task definition.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Define an array that includes the environment variables under the entryPoint parameter within the task definition.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Define an array that includes the environment variables under the entryPoint parameter within the service definition.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 42,
          "poolQNum": 36,
          "question": {
            "id": 42,
            "questionText": "A supplier is writing a new RESTful API for customers to query the status of orders. The customers requested the following API endpoint `http://www.supplierdomain.com/status/customerID`. Which of the following application designs meet the requirements? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon SQS; Amazon SNS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Elastic Load Balancing; Amazon EC2.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon ElastiCache; Amazon Elacticsearch Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon API Gateway; AWS Lambda.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3; Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 43,
          "poolQNum": 72,
          "question": {
            "id": 43,
            "questionText": "An application will ingest data at a very high throughput from many sources and must store the data in an Amazon S3 bucket. Which service would BEST accomplish this task?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon Kinesis Firehose.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3 Acceleration Transfer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SQS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SNS.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 44,
          "poolQNum": 354,
          "question": {
            "id": 44,
            "questionText": "The upload of a 15 GB object to Amazon S3 fails. The error message reads: `Your proposed upload exceeds the maximum allowed object size.`. What technique will allow the Developer to upload this object?",
            "questionImage": null,
            "options": [
              {
                "text": "Upload the object using the multi-part upload API.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload the object over an AWS Direct Connect connection.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Contact AWS Support to increase the object size limit.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload the object to another AWS region.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 45,
          "poolQNum": 373,
          "question": {
            "id": 45,
            "questionText": "An on-premises legacy application is caching data files locally and writing shared images to local disks. What is necessary to allow for horizontal scaling when migrating the application to AWS?",
            "questionImage": null,
            "options": [
              {
                "text": "Modify the application to have both shared images and caching data written to Amazon EBS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the application to read and write cache data on Amazon S3, and also store shared images on S3.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Modify the application to use Amazon S3 for serving shared images; cache data can then be written to local disks.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the application to read and write cache data on Amazon S3, while continuing to write shared images to local disks.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 46,
          "poolQNum": 135,
          "question": {
            "id": 46,
            "questionText": "Two containerized microservices are hosted on Amazon EC2 ECS. The first microservice reads an Amazon RDS Aurora database instance, and the second microservice reads an Amazon DynamoDB table. How can each microservice be granted the minimum privileges?",
            "questionImage": null,
            "options": [
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `false` on EC2 instance boot in ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the second microservice with an IAM role for ECS tasks with read-only access to DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `false` on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `true` on EC2 instance boot in the ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the secondmicroservice with an IAM role for ECS tasks with read-only access to DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `true` on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 47,
          "poolQNum": 236,
          "question": {
            "id": 47,
            "questionText": "In AWS, which security aspects are the customer's responsibility? (Choose FOUR)",
            "questionImage": null,
            "options": [
              {
                "text": "Life-cycle management of IAM credentials.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Decommissioning storage devices.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Security Group and ACL (Access Control List) settings.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Encryption of EBS (Elastic Block Storage) volumes.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Controlling physical access to compute resources.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Patch management on the EC2 instance's operating system.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3",
            "4",
            "6"
          ],
          "isCorrect": false
        },
        {
          "qNum": 48,
          "poolQNum": 379,
          "question": {
            "id": 48,
            "questionText": "A Developer has been asked to build a real-time dashboard web application to visualize the key prefixes and storage size of objects in Amazon S3 buckets. Amazon DynamoDB will be used to store the Amazon S3 metadata. What is the optimal and MOST cost-effective design to ensure that the real-time dashboard is kept up to date with the state of the objects in the Amazon S3 buckets?",
            "questionImage": null,
            "options": [
              {
                "text": "Use an Amazon CloudWatch event backed by an AWS Lambda function. Issue an Amazon S3 API call to get a list of all Amazon S3 objects and persist the metadata within DynamoDB. Have the web application poll the DynamoDB table to reflect this change.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon S3 Event Notification backed by a Lambda function to persist the metadata into DynamoDB. Have the web application poll the DynamoDB table to reflect this change.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Run a cron job within an Amazon EC2 instance to list all objects within Amazon S3 and persist the metadata into DynamoDB. Have the web application poll the DynamoDB table to reflect this change.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a new Amazon EMR cluster to get all the metadata about Amazon S3 objects; persist the metadata into DynamoDB. Have the web application poll the DynamoDB table to reflect this change.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 49,
          "poolQNum": 292,
          "question": {
            "id": 49,
            "questionText": "A Developer wants to debug an application by searching and filtering log data. The application logs are stored in Amazon CloudWatch Logs. The Developer creates a new metric filter to count exceptions in the application logs. However, no results are returned from the logs. What is the reason that no filtered results are being returned?",
            "questionImage": null,
            "options": [
              {
                "text": "A setup of the Amazon CloudWatch interface VPC endpoint is required for filtering the CloudWatch Logs in the VPC.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "CloudWatch Logs only publishes metric data for events that happen after the filter is created.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The log group for CloudWatch Logs should be first streamed to Amazon Elasticsearch Service before metric filtering returns the results.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Metric data points for logs groups can be filtered only after they are exported to an Amazon S3 bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 50,
          "poolQNum": 243,
          "question": {
            "id": 50,
            "questionText": "Company C has recently launched an online commerce site for bicycles on AWS. They have a `Product` DynamoDB table that stores details for each bicycle, such as, manufacturer, color, price, quantity and size to display in the online store. Due to customer demand, they want to include an image for each bicycle along with the existing details. Which approach below provides the least impact to provisioned throughput on the `Product` table?",
            "questionImage": null,
            "options": [
              {
                "text": "Serialize the image and store it in multiple DynamoDB tables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an `Images` DynamoDB table to store the Image with a foreign key constraint to the `Product` table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an image data type to the `Product` table to store the images in binary format.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the images in Amazon S3 and add an S3 URL pointer to the `Product` table item for each image.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 51,
          "poolQNum": 100,
          "question": {
            "id": 51,
            "questionText": "A Developer uses AWS CodeDeploy to automate application deployment that connects to an external MySQL database. The Developer wants to securely access the encrypted secrets, such as API keys and database passwords. Which of the following solutions would involve the LEAST administrative effort?",
            "questionImage": null,
            "options": [
              {
                "text": "Save the secrets in Amazon S3 with AWS KMS server-side encryption, and use a signed URL to access them by using the IAM role from Amazon EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the instance metadata to store the secrets and to programmatically access the secrets from EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the Amazon DynamoDB client-side encryption library to save the secrets in DynamoDB and to programmatically access the secrets from EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS SSM Parameter Store to store the secrets and to programmatically access them by using the IAM role from EC2 instances.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 52,
          "poolQNum": 114,
          "question": {
            "id": 52,
            "questionText": "A developer is refactoring a monolithic application. The application takes a POST request and performs several operations. Some of the operations are in parallel while others run sequentially. These operations have been refactored into individual AWS Lambda functions. The POST request will be processed by Amazon API Gateway. How should the developer invoke the Lambda functions in the same sequence using API Gateway?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon SQS to invoke the Lambda functions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an AWS Step Functions activity to run the Lambda functions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon SNS to trigger the Lambda functions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an AWS Step Functions state machine to orchestrate the Lambda functions.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 53,
          "poolQNum": 364,
          "question": {
            "id": 53,
            "questionText": "A company is migrating from a monolithic architecture to a microservices-based architecture. The Developers need to refactor the application so that the many microservices can asynchronously communicate with each other without impacting performance. Use of which managed AWS services will enable asynchronous message passing? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon SQS.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon Cognito.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Kinesis.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SNS.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon ElastiCache.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 54,
          "poolQNum": 199,
          "question": {
            "id": 54,
            "questionText": "A Developer is leveraging a Border Gateway Protocol (BGP)-based AWS VPN connection to connect from on-premises to Amazon EC2 instances in the Developer's account. The Developer is able to access an EC2 instance in subnet A, but is unable to access an EC2 instance in subnet B in the same VPC. Which logs can the Developer use to verify whether the traffic is reaching subnet B?",
            "questionImage": null,
            "options": [
              {
                "text": "VPN logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "BGP logs",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "VPC Flow Logs.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS CloudTrail logs.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 55,
          "poolQNum": 367,
          "question": {
            "id": 55,
            "questionText": "An application needs to use the IP address of the client in its processing. The application has been moved into AWS and has been placed behind an Application Load Balancer (ALB). However, all the client IP addresses now appear to be the same. The application must maintain the ability to scale horizontally. Based on this scenario, what is the MOST cost-effective solution to this problem?",
            "questionImage": null,
            "options": [
              {
                "text": "Remove the application from the ALB. Delete the ALB and change Amazon Route 53 to direct traffic to the instance running the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Remove the application from the ALB. Create a Classic Load Balancer in its place. Direct traffic to the application using the HTTP protocol.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Alter the application code to inspect the `X-Forwarded-For` header. Ensure that the code can work properly if a list of IP addresses is passed in the header.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Alter the application code to inspect a custom header. Alter the client code to pass the IP address in the custom header.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 56,
          "poolQNum": 345,
          "question": {
            "id": 56,
            "questionText": "A Developer is using AWS CLI, but when running list commands on a large number of resources, it is timing out. What can be done to avoid this time-out?",
            "questionImage": null,
            "options": [
              {
                "text": "Use pagination.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use shorthand syntax.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use parameter values.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use quoting strings.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 57,
          "poolQNum": 154,
          "question": {
            "id": 57,
            "questionText": "A company requires that AWS Lambda functions written by Developers log errors so System Administrators can more effectively troubleshoot issues. What should the Developers implement to meet this need?",
            "questionImage": null,
            "options": [
              {
                "text": "Publish errors to a dedicated Amazon SQS queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon CloudWatch Events event trigger based on certain Lambda events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Report errors through logging statements in Lambda function code.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set up an Amazon SNS topic that sends logging statements upon failure.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 58,
          "poolQNum": 231,
          "question": {
            "id": 58,
            "questionText": "What happens, by default, when one of the resources in a CloudFormation stack cannot be created?",
            "questionImage": null,
            "options": [
              {
                "text": "Previously-created resources are kept but the stack creation terminates.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Previously-created resources are deleted and the stack creation terminates.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The stack creation continues, and the final results indicate which steps failed.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "CloudFormation templates are parsed in advance so stack creation is guaranteed to succeed.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 59,
          "poolQNum": 299,
          "question": {
            "id": 59,
            "questionText": "An e-commerce site allows returning users to log in to display customized web pages. The workflow is shown in the image below. An application is running on EC2 instances. Amazon RDS is used for the database that stores user accounts and preferences. The website freezes or is slow to load while waiting for the login step to complete. The remaining components of the site are well-optimized. Which of the following techniques will resolve this issue? (Select TWO)",
            "questionImage": "images/question299.jpeg",
            "options": [
              {
                "text": "Implement the user login page as an asynchronous Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache for MemCached to cache user data.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Amazon Application Load Balancer to load balance the traffic to the website.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Call the database asynchronously so the code can continue executing.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Batch login requests from hundreds of users together as a single read request to the database.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 60,
          "poolQNum": 330,
          "question": {
            "id": 60,
            "questionText": "How should custom libraries be utilized in AWS Lambda?",
            "questionImage": null,
            "options": [
              {
                "text": "Host the library on Amazon S3 and reference to it from the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Install the library locally and upload a `ZIP` file of the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Import the necessary Lambda blueprint when creating the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the function runtime to include the necessary library.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 61,
          "poolQNum": 305,
          "question": {
            "id": 61,
            "questionText": "A company has an application that logs all information to Amazon S3. Whenever there is a new log file, an AWS Lambda function is invoked to process the log files. The code works, gathering all of the necessary information. However, when checking the Lambda function logs, duplicate entries with the same request ID are found. What is causing the duplicate entries?",
            "questionImage": null,
            "options": [
              {
                "text": "The S3 bucket name was specified incorrectly.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The Lambda function failed, and the Lambda service retired the invocation with a delay.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "There was an S3 outage, which caused duplicate entries of the sale log file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The application stopped intermittently and then resumed.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 62,
          "poolQNum": 18,
          "question": {
            "id": 62,
            "questionText": "A developer needs to modify an application architecture to meet new functional requirements. Application data is stored in Amazon DynamoDB and processed for analysis in a nightly batch. The system analysts do not want to wait unit the next day to view the processed data and have asked to have it available in near-real time. Which application architect pattern would enables the data to be processed as it is received?",
            "questionImage": null,
            "options": [
              {
                "text": "Event driven.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client served driven.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Fan-out driven.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Schedule driven.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 63,
          "poolQNum": 235,
          "question": {
            "id": 63,
            "questionText": "Which EC2 API call would you use to retrieve a list of Amazon Machine Images (AMIs)?",
            "questionImage": null,
            "options": [
              {
                "text": "`DescribeInstances`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`DescribeAMIs`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`DescribeImages`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`GetAMIs`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "You cannot retrieve a list of AMIs as there are over 10,000 AMIs.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 64,
          "poolQNum": 239,
          "question": {
            "id": 64,
            "questionText": "Which of the following is chosen as the default region when making an API call with an AWS SDK?",
            "questionImage": null,
            "options": [
              {
                "text": "`ap-northeast-1`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`us-west-2`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`us-east-1`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`eu-west-1`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`us-central-1`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 65,
          "poolQNum": 319,
          "question": {
            "id": 65,
            "questionText": "A Developer is creating an AWS Lambda function to process a stream of data from an Amazon Kinesis Data Stream. When the Lambda function parses the data and encounters a missing field, it exits the function with an error. The function is generating duplicate records from the Kinesis stream. When the Developer looks at the stream output without the Lambda function, there are no duplicate records. What is the reason for the duplicates?",
            "questionImage": null,
            "options": [
              {
                "text": "The Lambda function did not advance the Kinesis stream pointer to the next record after the error.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The Lambda event source used asynchronous invocation, resulting in duplicate records.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The Lambda function did not handle the error, and the Lambda service attempted to reprocess the data.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The Lambda function is not keeping up with the amount of data coming from the stream.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        }
      ],
      "questionMap": {
        "1": 339,
        "2": 271,
        "3": 6,
        "4": 152,
        "5": 203,
        "6": 183,
        "7": 278,
        "8": 157,
        "9": 261,
        "10": 359,
        "11": 48,
        "12": 282,
        "13": 77,
        "14": 175,
        "15": 55,
        "16": 279,
        "17": 333,
        "18": 337,
        "19": 221,
        "20": 121,
        "21": 184,
        "22": 328,
        "23": 78,
        "24": 164,
        "25": 217,
        "26": 173,
        "27": 19,
        "28": 139,
        "29": 181,
        "30": 41,
        "31": 192,
        "32": 377,
        "33": 171,
        "34": 298,
        "35": 194,
        "36": 91,
        "37": 365,
        "38": 103,
        "39": 112,
        "40": 97,
        "41": 148,
        "42": 36,
        "43": 72,
        "44": 354,
        "45": 373,
        "46": 135,
        "47": 236,
        "48": 379,
        "49": 292,
        "50": 243,
        "51": 100,
        "52": 114,
        "53": 364,
        "54": 199,
        "55": 367,
        "56": 345,
        "57": 154,
        "58": 231,
        "59": 299,
        "60": 330,
        "61": 305,
        "62": 18,
        "63": 235,
        "64": 239,
        "65": 319
      }
    }
  ]
}