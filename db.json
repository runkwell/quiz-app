{
  "history": [
    {
      "id": "1762865459326",
      "date": "12:50:59 11/11/2025",
      "score": "3.08",
      "results": [
        {
          "qNum": 1,
          "question": {
            "id": 187,
            "questionText": "A Developer uses Amazon S3 buckets for static website hosting. The Developer creates one S3 bucket for the code and another S3 bucket for the assets, such as image and video files. Access is denied when a user attempts to access the assets bucket from the code bucket, with the website application showing a `403` error. How should the Developer solve this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM role and apply it to the assets bucket for the code bucket to be granted access.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Edit the bucket policy of the assets bucket to allow access from the code bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Edit the bucket policy of the assets bucket to open access to all principals.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the code bucket to use AWS Lambda functions instead of static website hosting.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 2,
          "question": {
            "id": 32,
            "questionText": "An application contains two components: one component to handle HTTP requests, and another component to handle background processing tasks. Each component must scale independently. The developer wants to deploy this application using AWS Elastic Beanstalk. How should this application be deployed, based on these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy the application in a single Elastic Beanstalk environment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy each component in a separate Elastic Beanstalk environment.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use multiple Elastic Beanstalk environments for the HTTP component but one environment for the background task component.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use multiple Elastic Beanstalk environments for the background task component but one environment for the HTTP component.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 3,
          "question": {
            "id": 248,
            "questionText": "An application stores payroll information nightly in DynamoDB for a large number of employees across hundreds of offices. Item attributes consist of individual name, office identifier, and cumulative daily hours. Managers run reports for ranges of names working in their office. One query is: `Return all Items in this office for names starting with A through E`. Which table configuration will result in the lowest impact on provisioned throughput for this query?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure the table to have a hash index on the name attribute, and a range index on the office identifier.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure the table to have a range index on the name attribute, and a hash index on the office identifier.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure a hash index on the name attribute and no range index.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure a hash index on the office identifier attribute and no range index.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 4,
          "question": {
            "id": 210,
            "questionText": "A company wants to implement authentication for its new REST service using Amazon API Gateway. To authenticate the calls, each request must include HTTP headers with a client ID and user ID. These credentials must be compared to authentication data in an Amazon DynamoDB table. What MUST the company do to implement this authentication in API Gateway?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement an AWS Lambda authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a model that requires the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the integration requests to require the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement an Amazon Cognito authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 5,
          "question": {
            "id": 155,
            "questionText": "A Developer is writing an application that runs on Amazon EC2 instances in an Auto Scaling group. The application data is stored in an Amazon DynamoDB table and records are constantly updated by all instances. An instance sometimes retrieves old data. The Developer wants to correct this by making sure the reads are strongly consistent. How can the Developer accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "Set `ConsistentRead` to `true` when calling `GetItem`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a new DynamoDB Accelerator (DAX) table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set Consistency to strong when calling `UpdateTable`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `GetShardIterator` command.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 6,
          "question": {
            "id": 335,
            "questionText": "A company needs a fully-managed source control service that will work in AWS. The service must ensure that revision control synchronizes multiple distributed repositories by exchanging sets of changes peer-to-peer. All users need to work productively even when not connected to a network. Which source control service should be used?",
            "questionImage": null,
            "options": [
              {
                "text": "Subversion.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeBuild.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeCommit.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS CodeStar.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 7,
          "question": {
            "id": 252,
            "questionText": "What AWS products and features can be deployed by Elastic Beanstalk? (Choose THREE)",
            "questionImage": null,
            "options": [
              {
                "text": "Auto scaling groups.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Route 53 hosted zones.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Elastic Load Balancers.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "RDS Instances.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Elastic IP addresses.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SQS Queues.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 8,
          "question": {
            "id": 250,
            "questionText": "Which of the following services are included at no additional cost with the use of the AWS platform?",
            "questionImage": null,
            "options": [
              {
                "text": "Simple Storage Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Elastic Compute Cloud.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Auto Scaling.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Elastic Load Balancing.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "CloudFormation.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Simple Workflow Service.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 9,
          "question": {
            "id": 91,
            "questionText": "A company wants to implement a continuous integration for its workloads on AWS. The company wants to trigger unit test in its pipeline for commits-on its code repository, and wants to be notified of failure events in the pipeline. How can these requirements be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Store the source code in AWS CodeCommit. Create a CodePipeline to automate unit testing. Use Amazon SNS to trigger notifications of failure events.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the source code in GitHub. Create a CodePipeline to automate unit testing. Use Amazon SES to trigger notifications of failure events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the source code on GitHub. Create a CodePipeline to automate unit testing. Use Amazon CloudWatch to trigger notifications of failure events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the source code in AWS CodeCommit. Create a CodePipeline to automate unit testing. Use Amazon CloudWatch to trigger notification of failure events.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 10,
          "question": {
            "id": 270,
            "questionText": "A Development team wants to instrument their code to provide more detailed information to AWS X-Ray than simple outgoing and incoming requests. This will generate large amounts of data, so the Development team wants to implement indexing so they can filter the data. What should the Development team do to achieve this?",
            "questionImage": null,
            "options": [
              {
                "text": "Add annotations to the segment document and the code.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add metadata to the segment document and the code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure the necessary X-Ray environment variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Install required plugins for the appropriate AWS SDK.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 11,
          "question": {
            "id": 198,
            "questionText": "A Developer is working on a serverless project based in Java. Initial testing shows a cold start takes about 8 seconds on average for AWS Lambda functions. What should the Developer do to reduce the cold start time? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Add the Spring Framework to the project and enable dependency injection.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Reduce the deployment package by including only needed modules from the AWS SDK for Java.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Increase the memory allocation setting for the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Increase the timeout setting for the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the Lambda invocation mode from synchronous to asynchronous.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 12,
          "question": {
            "id": 221,
            "questionText": "What is the maximum number of S3 Buckets available per AWS account?",
            "questionImage": null,
            "options": [
              {
                "text": "100 per region.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "there is no limit.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1,000,000 per account.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "500 per account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "100 per IAM user.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 13,
          "question": {
            "id": 368,
            "questionText": "A development team is using AWS Elastic Beanstalk to deploy a two-tier application that consists of a load-balanced web tier and an Amazon RDS database tier in production. The team would like to separate the RDS instance from the Elastic Beanstalk. How can this be accomplished?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the Elastic Beanstalk CLI to disassociate the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS CLI to disassociate the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the deployment policy to disassociate the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Recreate a new Elastic Beanstalk environment without Amazon RDS.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 14,
          "question": {
            "id": 126,
            "questionText": "A developer is updating an application deployed on AWS Elastic Beanstalk. The new version is incompatible with the old version. To successfully deploy the update, a full cutover to the new, updated version must be performed on all instances at one time, with the ability to roll back changes in case of a deployment failure in the new version. How can this be performed with the LEAST amount of downtime?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the Elastic Beanstalk All at once deployment policy to update all instances simultaneously.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Perform an Elastic Beanstalk Rolling with additional batch deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the new version in a new Elastic Beanstalk environment and swap environment URLs.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Perform an Elastic Beanstalk Rolling deployment.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 15,
          "question": {
            "id": 378,
            "questionText": "A set of APIs are exposed to customers using the Amazon API Gateway. These APIs have caching enabled on the API Gateway. Customers have asked for an option to invalidate this cache for each of the APIs. What action can be taken to allow API customers to invalidate the API Cache?",
            "questionImage": null,
            "options": [
              {
                "text": "Ask customers to use AWS credentials to call the `InvalidateCache` API.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Ask customers to invoke an AWS API endpoint which invalidates the cache.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Ask customers to pass an HTTP header called `Cache-Control:max-age=0`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Ask customers to add a query string parameter called `INVALIDATE_CACHE` when making an API call.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 16,
          "question": {
            "id": 148,
            "questionText": "A Developer needs to deploy an application running on AWS Fargate using Amazon ECS. The application has environment variables that must be passed to a container for the application to initialize. How should the environment variables be passed to the container?",
            "questionImage": null,
            "options": [
              {
                "text": "Define an array that includes the environment variables under the environment parameter within the service definition.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Define an array that includes the environment variables under the environment parameter within the task definition.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Define an array that includes the environment variables under the entryPoint parameter within the task definition.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Define an array that includes the environment variables under the entryPoint parameter within the service definition.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 17,
          "question": {
            "id": 273,
            "questionText": "A company is using continuous integration and continuous delivery systems. A Developer now needs to automate a software package deployment to both Amazon EC2 instances and virtual servers running on-premises. Which AWS service should be used to accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS CodePipeline.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeBuild.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeDeploy.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 18,
          "question": {
            "id": 219,
            "questionText": "After launching an instance that you intend to serve as a NAT (Network Address Translation) device in a public subnet you modify your route tables to have the NAT device be the target of internet bound traffic of your private subnet. When you try and make an outbound connection to the Internet from an instance in the private subnet, you are not successful. NAT device be the target of internet bound traffic of your private subnet. Which of the following steps could resolve the issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Attaching a second Elastic Network interface (ENI) to the NAT instance, and placing it in the private subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Attaching a second Elastic Network Interface (ENI) to the instance in the private subnet, and placing it in the public subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disabling the `Source/Destination Check` attribute on the NAT instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Attaching an Elastic IP address to the instance in the private subnet.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 19,
          "question": {
            "id": 103,
            "questionText": "An application stores images in an S3 bucket. Amazon S3 event notifications are used to trigger a Lambda function that resizes the images. Processing each image takes less than a second. How will AWS Lambda handle the additional traffic?",
            "questionImage": null,
            "options": [
              {
                "text": "Lambda will scale out to execute the requests concurrently.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Lambda will handle the requests sequentially in the order received.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Lambda will process multiple images in a single execution.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Lambda will add more compute to each execution to reduce processing time.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 20,
          "question": {
            "id": 333,
            "questionText": "A Developer is designing a fault-tolerant environment where client sessions will be saved. How can the Developer ensure that no sessions are lost if an Amazon EC2 instance fails?",
            "questionImage": null,
            "options": [
              {
                "text": "Use sticky sessions with an Elastic Load Balancer target group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon SQS to save session data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon DynamoDB to perform scalable session handling.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Elastic Load Balancer connection draining to stop sending requests to failing instances.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 21,
          "question": {
            "id": 300,
            "questionText": "A Developer is building a mobile application and needs any update to user profile data to be pushed to all devices accessing the specific identity. The Developer does not want to manage a back end to maintain the user profile data. What is the MOST efficient way for the Developer to achieve these requirements using Amazon Cognito?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Cognito federated identities.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use a Cognito user pool.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Cognito Sync.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Cognito events.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 22,
          "question": {
            "id": 331,
            "questionText": "A company needs to secure its existing website running behind an Elastic Load Balancer. The website's Amazon EC2 instances are CPU-constrained. What should be done to secure the website while not increasing the CPU load on the EC2 web servers? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Configure an Elastic Load Balancer with SSL pass-through.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure SSL certificates on an Elastic Load Balancer.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure an Elastic Load Balancer with a Loadable Storage System.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Install SSL certificates on the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure an Elastic Load Balancer with SSL termination.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 23,
          "question": {
            "id": 324,
            "questionText": "A Developer wants to enable AWS X-Ray for a secure application that runs in an Amazon ECS environment. What combination of steps will enable X-Ray? (Select THREE)",
            "questionImage": null,
            "options": [
              {
                "text": "Create a Docker image that runs the X-Ray daemon.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add instrumentation to the application code for X-Ray.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install the X-Ray daemon on the underlying EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure and use an IAM EC2 instance role.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Register the application with X-Ray.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure and use an IAM role for tasks.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "2",
            "6"
          ],
          "isCorrect": false
        },
        {
          "qNum": 24,
          "question": {
            "id": 67,
            "questionText": "A Developer must re-implement the business logic for an order fulfilment system. The business logic has to make requests to multiple vendors to decide where to purchase an item. The whole process can take up to a week to complete. What is the MOST efficient and SIMPLEST way to implement a system that meets these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS Step Functions to execute parallel Lambda functions, and join the results.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an AWS SQS for each vendor, poll the queue from a worker instance, and joint the results.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Lambda to asynchronously call a Lambda function for each vendor, and join the results.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudWatch Events to orchestrate the Lambda functions.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 25,
          "question": {
            "id": 183,
            "questionText": "A Developer has code running on Amazon EC2 instances that needs read-only access to an Amazon DynamoDB table. What is the MOST secure approach the Developer should take to accomplish this task?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a user access key for each EC2 instance with read-only access to DynamoDB. Place the keys in the code. Redeploy the code as keys rotate.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an IAM role with an AmazonDynamoDBReadOnlyAccess policy applied to the EC2 instances.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Run all code with only AWS account root user access keys to ensure maximum access to services.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an IAM role with Administrator access applied to the EC2 instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 26,
          "question": {
            "id": 268,
            "questionText": "Company C is currently hosting their corporate site in an Amazon S3 bucket with Static Website Hosting enabled. Currently, when visitors go to `http://www.companyc.com` the `index.html` page is returned. Company C now would like a new page welcome.html to be returned when a visitor enters `http://www.companyc.com` in the browser. Which of the following steps will allow Company C to meet this requirement? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Upload an html page named welcome.html to their S3 bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a welcome subfolder in their S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set the Index Document property to welcome.html.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Move the `index.html` page to a welcome subfolder.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set the Error Document property to welcome.html.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 27,
          "question": {
            "id": 171,
            "questionText": "A Developer is trying to monitor an application's status by running a cron job that returns 1 if the service is up and 0 if the service is down. The Developer created code that uses an AWS CLI `put-metric-alarm` command to publish the custom metrics to Amazon CloudWatch and create an alarm. However, the Developer is unable to create an alarm as the custom metrics do not appear in the CloudWatch console. What is causing this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Sending custom metrics using the CLI is not supported.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The Developer needs to use the `put-metric-data` command.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The Developer must use a unified CloudWatch agent to publish custom metrics.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The code is not running on an Amazon EC2 instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 28,
          "question": {
            "id": 262,
            "questionText": "Which statements about DynamoDB are true? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "DynamoDB uses a pessimistic locking model.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "DynamoDB uses optimistic concurrency control.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "DynamoDB uses conditional writes for consistency.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "DynamoDB restricts item access during reads.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "DynamoDB restricts item access during writes.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 29,
          "question": {
            "id": 162,
            "questionText": "A Company runs continuous integration/continuous delivery (CI/CD) pipelines for its application on AWS CodePipeline. A Developer must write unit tests and run them as part of the pipelines before staging the artifacts for testing. How should the Developer incorporate unit tests as part of CI/CD pipelines?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a separate CodePipeline pipeline to run unit tests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the AWS CodeBuild specification to include a phase for running unit tests.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install the AWS CodeDeploy agent on an Amazon EC2 instance to run unit tests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a testing branch in AWS CodeCommit to run unit tests.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 30,
          "question": {
            "id": 94,
            "questionText": "A Developer is writing transactions into a DynamoDB table called `SystemUpdates` that has 5 write capacity units. Which option has the highest read throughput?",
            "questionImage": null,
            "options": [
              {
                "text": "Eventually consistent reads of 5 read capacity units reading items that are 4 KB in size.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Strongly consistent reads of 5 read capacity units reading items that are 4 KB in size.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Eventually consistent reads of 15 read capacity units reading items that are 1 KB in size.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Strongly consistent reads of 15 read capacity units reading items that are 1 KB in size.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 31,
          "question": {
            "id": 5,
            "questionText": "A Developer wants to upload data to Amazon S3 and must encrypt the data in transit. Which of the following solutions will accomplish this task? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Set up hardware VPN tunnels to a VPC and access S3 through a VPC endpoint.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set up Client-Side Encryption with an AWS KMS-Managed Customer Master Key.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set up Server-Side Encryption with AWS KMS-Managed Keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Transfer the data over an SSL connection.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set up Server-Side Encryption with S3-Managed Keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 32,
          "question": {
            "id": 160,
            "questionText": "An application is using a single-node Amazon ElastiCache for Redis instance to improve read performance. Over time, demand for the application has increased exponentially, which has increased the load on the ElastiCache instance. It is critical that this cache layer handles the load and is resilient in case of node failures. What can the Developer do to address the load and resiliency requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Add a read replica instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Migrate to a Memcached cluster.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Migrate to an Amazon Elasticsearch Service cluster.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Vertically scale the ElastiCache instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 33,
          "question": {
            "id": 281,
            "questionText": "A Developer accesses AWS CodeCommit over SSH. The SSH keys configured to access AWS CodeCommit are tied to a user with the following permissions. The Developer needs to create/delete branches. Which specific IAM permissions need to be added, based on the principle of least privilege?",
            "questionImage": null,
            "options": [
              {
                "text": "`\"codecommit:CreateBranch\" \"codecommit:DeleteBranch\"`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`\"codecommit:Put*\"`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`\"codecommit:Update*\"`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`\"codecommit:*\"`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 34,
          "question": {
            "id": 108,
            "questionText": "What are the steps to using the AWS CLI to launch a templatized serverless application?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS CloudFormation get-template then CloudFormation execute-change-set.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CloudFormation validate-template then CloudFormation create-change-set.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CloudFormation package then CloudFormation deploy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS CloudFormation create-stack then CloudFormation update-stack.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 35,
          "question": {
            "id": 52,
            "questionText": "A company has written a Java AWS Lambda function to be triggered whenever a user uploads an image to an Amazon S3 bucket. The function converts the original image to several different formats and then copies the resulting images to another Amazon S3 bucket. The Developers find that no images are being copied to the second Amazon S3 bucket. They have tested the code on an Amazon EC2 instance with 1GB of RAM, and it takes an average of 500 seconds to complete. What is the MOST likely cause of the problem?",
            "questionImage": null,
            "options": [
              {
                "text": "The Lambda function has insufficient memory and needs to be increased to 1 GB to match the Amazon EC2 instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Files need to be copied to the same Amazon S3 bucket for processing, so the second bucket needs to be deleted.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Lambda functions have a maximum execution limit of 15 minutes, therefore the function is not completing.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "There is a problem with the Java runtime for Lambda, and the function needs to be converted to node.js.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 36,
          "question": {
            "id": 237,
            "questionText": "When using a large Scan operation in DynamoDB, what technique can be used to minimize the impact of a scan on a table's provisioned throughput?",
            "questionImage": null,
            "options": [
              {
                "text": "Set a smaller page size for the scan.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use parallel scans.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Define a range index on the table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Prewarm the table by updating all items.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 37,
          "question": {
            "id": 27,
            "questionText": "A development team is creating a new application designed to run on AWS. While the test and production environments will run on Amazon EC2 instances, developers will each run their own environment on their laptops. Which of the following is the simplest and MOST secure way to access AWS services from the local development machines?",
            "questionImage": null,
            "options": [
              {
                "text": "Use an IAM role to assume a role and execute API calls using the role.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM user to be shared with the entire development team, provide the development team with the access key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM user for each developer on the team: provide each developer with a unique access key.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set up a federation through an Amazon Cognito user pool.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 38,
          "question": {
            "id": 23,
            "questionText": "A Developer is making changes to a custom application that is currently using AWS Elastic Beanstalk. After the Developer completes the changes, what solutions will update the Elastic Beanstalk environment with the new application version? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Package the application code into a `.zip` file, and upload, then deploy the packaged application from the AWS Management Console.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Package the application code into a `.tar` file, create a new application version from the AWS Management Console, then update the environment by using AWS CLI.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Package the application code into a `.tar` file, and upload and deploy the packaged application from the AWS Management Console.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Package the application code into a `.zip` file, create a new application version from the packaged application by using AWS CLI, then update the environment by using AWS CLI.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Package the application code into a `.zip` file, create a new application version from the AWS Management Console, then rebuild the environment by using AWS CLI.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 39,
          "question": {
            "id": 206,
            "questionText": "A Developer is going to deploy an AWS Lambda function that requires significant CPU utilization. Which approach will MINIMIZE the average runtime of the function?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy the function into multiple AWS Regions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the function into multiple Availability Zones.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the function using Lambda layers.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the function with its memory allocation set to the maximum amount.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 40,
          "question": {
            "id": 128,
            "questionText": "A company is developing a report executed by AWS Step Functions, Amazon CloudWatch shows errors in the Step Functions task state machine. To troubleshoot each task, the state input needs to be included along with the error message in the state output. Which coding practice can preserve both the original input and the error for the state?",
            "questionImage": null,
            "options": [
              {
                "text": "Use `ResultPath` in a `Catch` statement to include the error with the original input.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use `InputPath` in a `Catch` statement and set the value to `null`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use `Error Equals` in a `Retry` statement to include the error with the original input.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use `OutputPath` in a `Retry` statement and set the value to `$`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 41,
          "question": {
            "id": 72,
            "questionText": "An application will ingest data at a very high throughput from many sources and must store the data in an Amazon S3 bucket. Which service would BEST accomplish this task?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon Kinesis Firehose.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3 Acceleration Transfer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SQS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SNS.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 42,
          "question": {
            "id": 381,
            "questionText": "An existing serverless application processes uploaded image files. The process currently uses a single Lambda function that takes an image file, performs the processing, and stores the file in Amazon S3. Users of the application now require thumbnail generation of the images. Users want to avoid any impact to the time it takes to perform the image uploads. How can thumbnail generation be added to the application, meeting user requirements while minimizing changes to existing code?",
            "questionImage": null,
            "options": [
              {
                "text": "Change the existing Lambda function handling the uploads to create thumbnails at the time of upload. Have the function store both the image and thumbnail in Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a second Lambda function that handles thumbnail generation and storage. Change the existing Lambda function to invoke it asynchronously.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an S3 event notification with a Lambda function destination. Create a new Lambda function to generate and store thumbnails.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an S3 event notification to an SQS Queue. Create a scheduled Lambda function that processes the queue, and generates and stores thumbnails.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 43,
          "question": {
            "id": 278,
            "questionText": "A Developer has been asked to create an AWS Lambda function that is triggered any time updates are made to items in an Amazon DynamoDB table. The function has been created, and appropriate permissions have been added to the Lambda execution role. Amazon DynamoDB streams have been enabled for the table, but the function is still not being triggered. Which option would enable DynamoDB table updates to trigger the Lambda function?",
            "questionImage": null,
            "options": [
              {
                "text": "Change the `StreamViewType` parameter value to `NEW_AND_OLD_IMAGES` for the DynamoDB table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure event source mapping for the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Map an Amazon SNS topic to the DynamoDB streams.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the maximum execution time (timeout) setting of the Lambda function.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 44,
          "question": {
            "id": 2,
            "questionText": "Which of the following services are key/value stores? (Choose 3 answers)",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon ElastiCache.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Simple Notification Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Simple Workflow Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Simple Storage Service.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 45,
          "question": {
            "id": 18,
            "questionText": "A developer needs to modify an application architecture to meet new functional requirements. Application data is stored in Amazon DynamoDB and processed for analysis in a nightly batch. The system analysts do not want to wait unit the next day to view the processed data and have asked to have it available in near-real time. Which application architect pattern would enables the data to be processed as it is received?",
            "questionImage": null,
            "options": [
              {
                "text": "Event driven.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client served driven.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Fan-out driven.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Schedule driven.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 46,
          "question": {
            "id": 68,
            "questionText": "A mobile app stores blog posts in an Amazon DynamoDB table. Millions of posts are added every day, and each post represents a single item in the table. The mobile app requires only recent posts. Any post that is older than 48 hours can be removed. What is the MOST cost-effective way to delete posts that are older than 48 hours?",
            "questionImage": null,
            "options": [
              {
                "text": "For each item, add a new attribute of type `String` that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the `BatchWriteItem` API operation. Schedule a cron job on an Amazon EC2 instance once an hour to start the script.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "For each item, add a new attribute of type `String` that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the `BatchWriteItem` API operation. Place the script in a container image. Schedule an Amazon Elastic Container Service (Amazon ECS) task on AWS Fargate that invokes the container every 5 minutes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "For each item, add a new attribute of type `Date` that has a timestamp that is set to 48 hours after the blog post creation time. Create a Global Secondary Index (GSI) that uses the new attribute as a sort key. Create an AWS Lambda function that references the GSI and removes expired items by using the `BatchWriteItem` API operation. Schedule the function with an Amazon CloudWatch event every minute.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "For each item, add a new attribute of type `Number` that has a timestamp that is set to 48 hours after the blog post creation time. Configure the DynamoDB table with a TTL that references the new attribute.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 47,
          "question": {
            "id": 227,
            "questionText": "When uploading an object, what request header can be explicitly specified in a request to Amazon S3 to encrypt object data when saved on the server side?",
            "questionImage": null,
            "options": [
              {
                "text": "`x-amz-storage-class`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`Content-MD5`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`x-amz-security-token`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`x-amz-server-side-encryption`.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 48,
          "question": {
            "id": 200,
            "questionText": "A Developer has created a new AWS IAM user that has `s3:putObject` permission to write to a specific Amazon S3 bucket. This S3 bucket uses server-side encryption with AWS KMS managed keys (SSE-KMS) as the default encryption. Using the access key and secret key of the IAM user, the application received an access denied error when calling the `PutObject` API. How can this issue be resolved?",
            "questionImage": null,
            "options": [
              {
                "text": "Update the policy of the IAM user to allow the `s3:EncryptionConfiguration` action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the bucket policy of the S3 bucket to allow the IAM user to upload objects.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the policy of the IAM user to allow the `kms:GenerateDataKey` action.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Update the ACL of the S3 bucket to allow the IAM user to upload objects.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 49,
          "question": {
            "id": 203,
            "questionText": "A Developer is storing sensitive data generated by an application in Amazon S3. The Developer wants to encrypt the data at rest. A company policy requires an audit trail of when the master key was used and by whom. Which encryption option will meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Server-side encryption with Amazon S3 managed keys (SSE-S3).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with AWS KMS managed keys (SSE-KMS).",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Server-side encryption with customer-provided keys (SSE-C).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with self-managed keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 50,
          "question": {
            "id": 54,
            "questionText": "A Developer is creating a mobile application with a limited budget. The solution requires a scalable service that will enable customers to sign up and authenticate into the mobile application while using the organization's current SAML 2.0 identity provider. Which AWS service should be used to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS IAM.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon EC2.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 51,
          "question": {
            "id": 125,
            "questionText": "An application running on Amazon EC2 opens connections to an Amazon RDS SQL Server database. The developer does not want to store the user name and password for the database in the code. The developer would also like to automatically rotate the credentials. What is the MOST secure way to store and access the database credentials?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM role that has permissions to access the database. Attach the role to the EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Secrets Manager to store the credentials. Retrieve the credentials from Secrets Manager as needed.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the credentials in an encrypted text file in an Amazon S3 bucket. Configure the EC2 instance's user data to download the credentials from Amazon S3 as the instance boots.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the user name and password credentials directly in the source code. No further action is needed because the source code is stored in a private repository.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 52,
          "question": {
            "id": 83,
            "questionText": "A Lambda function is packaged for deployment to multiple environments, including development, test, production, etc. Each environment has unique set of resources such as databases, etc. How can the Lambda function use the resources for the current environment?",
            "questionImage": null,
            "options": [
              {
                "text": "Apply tags to the Lambda functions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Hardcore resources in the source code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use environment variables for the Lambda functions.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use separate function for development and production.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 53,
          "question": {
            "id": 382,
            "questionText": "A company is using Amazon API Gateway to manage access to a set of microservices implemented as AWS Lambda functions. Following a bug report, the company makes a minor breaking change to one of the APIs. In order to avoid impacting existing clients when the new API is deployed, the company wants to allow clients six months to migrate from v1 to v2. Which approach should the Developer use to handle this change?",
            "questionImage": null,
            "options": [
              {
                "text": "Update the underlying Lambda function and provide clients with the new Lambda invocation URL.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use API Gateway to automatically propagate the change to clients, specifying 180 days in the phased deployment parameter.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use API Gateway to deploy a new stage named v2 to the API and provide users with its URL.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Update the underlying Lambda function, create an Amazon CloudFront distribution with the updated Lambda function as its origin.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 54,
          "question": {
            "id": 57,
            "questionText": "A game stores user game data in an Amazon DynamoDB table. Individual users should not have access to other users' game data. How can this be accomplished?",
            "questionImage": null,
            "options": [
              {
                "text": "Encrypt the game data with individual user keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Restrict access to specific items based on certain primary key values.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Stage data in SQS queues to inject metadata before accessing DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Read records from DynamoDB and discard irrelevant data client-side.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 55,
          "question": {
            "id": 102,
            "questionText": "A Developer will be using the AWS CLI on a local development server to manage AWS services. What can be done to ensure that the CLI uses the Developer's IAM permissions when making commands?",
            "questionImage": null,
            "options": [
              {
                "text": "Specify the Developer's IAM access key ID and secret access key as parameters for each CLI command.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Run the `aws configure` CLI command, and provide the Developer's IAM access key ID and secret access key.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Specify the Developer's IAM user name and password as parameters for each CLI command.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the Developer's IAM role when making the CLI command.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 56,
          "question": {
            "id": 315,
            "questionText": "A company maintains an application responsible for processing several thousand external callbacks each day. The company's System administrators want to know how many callbacks are being received on a rolling basis, and they want this data available for 10 days. The company also wants the ability to issue automated alerts if the number of callbacks exceeds the defined thresholds. What is the MOST cost-effective way to address the need to track and alert on these statistics?",
            "questionImage": null,
            "options": [
              {
                "text": "Push callback data to an Amazon RDS database that can be queried to show historical data and to alert on exceeded thresholds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Push callback data to AWS X-Ray and use AWS Lambda to query, display, and alert on exceeded thresholds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Push callback data to Amazon Kinesis Data Streams and invoke an AWS Lambda function that stores data in Amazon DynamoDB and sends the required alerts.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Push callback data to Amazon CloudWatch as a custom metric and use the CloudWatch alerting mechanisms to alert System Administrators.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 57,
          "question": {
            "id": 208,
            "questionText": "A Developer has an e-commerce API hosted on Amazon ECS. Variable and spiking demand on the application is causing order processing to take too long. The application processes Amazon SQS queues. The `ApproximateNumberOfMessagesVisible` metric spikes at very high values throughout the day, which cause Amazon CloudWatch alarm breaches. Other ECS metrics for the API containers are well within limits. What can the Developer implement to improve performance while keeping costs low?",
            "questionImage": null,
            "options": [
              {
                "text": "Target tracking scaling policy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Docker Swarm.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Service scheduler.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Step scaling policy.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 58,
          "question": {
            "id": 275,
            "questionText": "A Developer is building a three-tier web application that should be able to handle a minimum of 5000 requests per minute. Requirements state that the web tier should be completely stateless while the application maintains session state for the users. How can session data be externalized, keeping latency at the LOWEST possible value?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an Amazon RDS instance, then implement session handling at the application level to leverage a database inside the RDS database instance for session data storage.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement a shared file system solution across the underlying Amazon EC2 instances, then implement session handling at the application level to leverage the shared file system for session data storage.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon ElastiCache Memcached cluster, then implement session handling at the application level to leverage the cluster for session data storage.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an Amazon DynamoDB table, then implement session handling at the application level to leverage the table for session data storage.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 59,
          "question": {
            "id": 369,
            "questionText": "A company is using AWS CodePipeline to deliver one of its applications. The delivery pipeline is triggered by changes to the master branch of an AWS CodeCommit repository and uses AWS CodeBuild to implement the test and build stages of the process and AWS CodeDeploy to deploy the application. The pipeline has been operating successfully for several months and there have been no modifications. Following a recent change to the application's source code, AWS CodeDeploy has not deployed the updates application as expected. What are the possible causes? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "The change was not made in the master branch of the AWS CodeCommit repository.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "One of the earlier stages in the pipeline failed and the pipeline has terminated.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "One of the Amazon EC2 instances in the company's AWS CodePipeline cluster is inactive.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The AWS CodePipeline is incorrectly configured and is not executing AWS CodeDeploy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodePipeline does not have permissions to access AWS CodeCommit.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 60,
          "question": {
            "id": 347,
            "questionText": "An organization is storing large files in Amazon S3, and is writing a web application to display meta-data about the files to end-users. Based on the metadata a user selects an object to download. The organization needs a mechanism to index the files and provide single-digit millisecond latency retrieval for the metadata. What AWS service should be used to accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon EC2.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon RDS.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 61,
          "question": {
            "id": 365,
            "questionText": "According to best practice, how should access keys be managed in AWS? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Use the same access key in all applications for consistency.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Delete all access keys for the account `root` user.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Leave unused access keys in the account for tracking purposes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Embed and encrypt access keys in code for continuous deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon IAM roles instead of access keys where possible.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 62,
          "question": {
            "id": 64,
            "questionText": "When writing a Lambda function, what is the benefit of instantiating AWS clients outside the scope of the handler?",
            "questionImage": null,
            "options": [
              {
                "text": "Legibility and stylistic convention.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Taking advantage of connection re-use.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Better error handling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Creating a new instance per invocation.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 63,
          "question": {
            "id": 6,
            "questionText": "A Developer wants to encrypt new objects that are being uploaded to an Amazon S3 bucket by an application. There must be an audit trail of who has used the key during this process. There should be no change to the performance of the application. Which type of encryption meets these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Server-side encryption using S3-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client-side encryption with a client-side symmetric master key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Client-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 64,
          "question": {
            "id": 17,
            "questionText": "A company is migrating its on-premises database to Amazon RDS for MySQL. The company has read-heavy workloads, and wants to make sure it re-factors its code to achieve optimum read performance for its queries. How can this objective be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Add database retries to effectively use RDS with vertical scaling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use RDS with multi-AZ deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a connection string to use an RDS read replica for read queries.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add a connection string to use a read replica on an EC2 instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 65,
          "question": {
            "id": 320,
            "questionText": "A company is developing an application that will run on several Amazon EC2 instances in an Auto Scaling group and can access a database running on Amazon EC2. The application needs to store secrets required to connect to the database. The application must allow for periodic secret rotation, and there should be no changes to the application when a secret changes. What is the SAFEST way to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Associate an IAM role to the EC2 instance where the application is running with permission to access the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Systems Manager Parameter Store with the SecureString data type to store secrets.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure the application to store secrets in Amazon S3 object metadata.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Hard code the database secrets in the application code itself.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        }
      ]
    },
    {
      "id": "1762889572232",
      "date": "19:32:52 11/11/2025",
      "score": "0.00",
      "results": [
        {
          "qNum": 1,
          "question": {
            "id": 365,
            "questionText": "According to best practice, how should access keys be managed in AWS? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Use the same access key in all applications for consistency.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Delete all access keys for the account `root` user.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Leave unused access keys in the account for tracking purposes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Embed and encrypt access keys in code for continuous deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon IAM roles instead of access keys where possible.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 2,
          "question": {
            "id": 154,
            "questionText": "A company requires that AWS Lambda functions written by Developers log errors so System Administrators can more effectively troubleshoot issues. What should the Developers implement to meet this need?",
            "questionImage": null,
            "options": [
              {
                "text": "Publish errors to a dedicated Amazon SQS queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon CloudWatch Events event trigger based on certain Lambda events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Report errors through logging statements in Lambda function code.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set up an Amazon SNS topic that sends logging statements upon failure.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 3,
          "question": {
            "id": 37,
            "questionText": "A developer Is designing an AWS Lambda function that create temporary files that are less than 10 MB during execution. The temporary files will be accessed and modified multiple times during execution. The developer has no need to save or retrieve these files in the future. Where should the temporary file be stored?",
            "questionImage": null,
            "options": [
              {
                "text": "the `/tmp` directory.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon EFS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon EBS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon S3.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 4,
          "question": {
            "id": 363,
            "questionText": "An application runs on multiple EC2 instances behind an ELB. Where is the session data best written so that it can be served reliably across multiple requests?",
            "questionImage": null,
            "options": [
              {
                "text": "Write data to Amazon ElastiCache.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Write data to Amazon Elastic Block Store.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write data to Amazon EC2 Instance Store.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write data to the `root` filesystem.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 5,
          "question": {
            "id": 146,
            "questionText": "A front-end web application is using Amazon Cognito user pools to handle the user authentication flow. A developer is integrating Amazon DynamoDB into the application using the AWS SDK for JavaScript. How would the developer securely call the API without exposing the access or secret keys?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure Amazon Cognito identity pools and exchange the JSON Web Token (JWT) for temporary credentials.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Run the web application in an Amazon EC2 instance with the instance profile configured.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Hardcore the credentials, use Amazon S3 to host the web application, and enable server-side encryption.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito user pool JSON Web Tokens (JWITs) to access the DynamoDB APIs.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 6,
          "question": {
            "id": 382,
            "questionText": "A company is using Amazon API Gateway to manage access to a set of microservices implemented as AWS Lambda functions. Following a bug report, the company makes a minor breaking change to one of the APIs. In order to avoid impacting existing clients when the new API is deployed, the company wants to allow clients six months to migrate from v1 to v2. Which approach should the Developer use to handle this change?",
            "questionImage": null,
            "options": [
              {
                "text": "Update the underlying Lambda function and provide clients with the new Lambda invocation URL.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use API Gateway to automatically propagate the change to clients, specifying 180 days in the phased deployment parameter.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use API Gateway to deploy a new stage named v2 to the API and provide users with its URL.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Update the underlying Lambda function, create an Amazon CloudFront distribution with the updated Lambda function as its origin.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 7,
          "question": {
            "id": 75,
            "questionText": "A large e-commerce site is being designed to deliver static objects from Amazon S3. The Amazon S3 bucket will server more than 300 GET requests per second. What should be done to optimize performance? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Integrate Amazon CloudFront with Amazon S3.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Enable Amazon S3 cross-region replication.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Delete expired Amazon S3 server log files.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure Amazon S3 lifecycle rules.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Randomize Amazon S3 key name prefixes.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 8,
          "question": {
            "id": 209,
            "questionText": "A Developer wants to build an application that will allow new users to register and create new user accounts. The application must also allow users with social media accounts to log in using their social media credentials. Which AWS service or feature can be used to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS IAM.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito identity pools.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito user pools.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Directory Service.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 9,
          "question": {
            "id": 125,
            "questionText": "An application running on Amazon EC2 opens connections to an Amazon RDS SQL Server database. The developer does not want to store the user name and password for the database in the code. The developer would also like to automatically rotate the credentials. What is the MOST secure way to store and access the database credentials?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM role that has permissions to access the database. Attach the role to the EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Secrets Manager to store the credentials. Retrieve the credentials from Secrets Manager as needed.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the credentials in an encrypted text file in an Amazon S3 bucket. Configure the EC2 instance's user data to download the credentials from Amazon S3 as the instance boots.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the user name and password credentials directly in the source code. No further action is needed because the source code is stored in a private repository.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 10,
          "question": {
            "id": 165,
            "questionText": "A Developer has written code for an application and wants to share it with other Developers on the team to receive feedback. The shared application code needs to be stored long-term with multiple versions and batch change tracking. Which AWS service should the Developer use?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS CodeBuild.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeCommit.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Cloud9.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 11,
          "question": {
            "id": 236,
            "questionText": "In AWS, which security aspects are the customer's responsibility? (Choose FOUR)",
            "questionImage": null,
            "options": [
              {
                "text": "Life-cycle management of IAM credentials.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Decommissioning storage devices.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Security Group and ACL (Access Control List) settings.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Encryption of EBS (Elastic Block Storage) volumes.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Controlling physical access to compute resources.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Patch management on the EC2 instance's operating system.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3",
            "4",
            "6"
          ],
          "isCorrect": false
        },
        {
          "qNum": 12,
          "question": {
            "id": 386,
            "questionText": "A static website is hosted in an Amazon S3 bucket. Several HTML pages on the site use JavaScript to download images from another Amazon S3 bucket. These images are not displayed when users browse the site. What is the possible cause for the issue?",
            "questionImage": null,
            "options": [
              {
                "text": "The referenced Amazon S3 bucket is in another region.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The images must be stored in the same Amazon S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Port 80 must be opened on the security group in which the Amazon S3 bucket is located.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Cross Origin Resource Sharing must be enabled on the Amazon S3 bucket.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 13,
          "question": {
            "id": 323,
            "questionText": "A Developer has been asked to make changes to the source code of an AWS Lambda function. The function is managed using an AWS CloudFormation template. The template is configured to load the source code from an Amazon S3 bucket. The Developer manually created a `.ZIP` file deployment package containing the changes and put the file into the correct location on Amazon S3. When the function is invoked, the code changes have not been applied. What step is required to update the function with the changes?",
            "questionImage": null,
            "options": [
              {
                "text": "Delete the `.ZIP` file on S3, and re-upload by using a different object key name.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the CloudFormation stack with the correct values for the function code properties S3Bucket, S3Key, or S3ObjectVersion.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Ensure that the function source code is base64-encoded before uploading the deployment package to S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the execution role of the Lambda function to allow S3 access permission to the deployment package `.ZIP` file.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 14,
          "question": {
            "id": 204,
            "questionText": "A company's website runs on an Amazon EC2 instance and uses Auto Scaling to scale the environment during peak times. Website users across the world are experiencing high latency due to static content on the EC2 instance, even during non-peak hours. Which combination of steps will resolve the latency issue? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Double the Auto Scaling group's maximum number of servers.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Host the application code on AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Scale vertically by resizing the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon CloudFront distribution to cache the static content.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the application's static content in Amazon S3.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "4",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 15,
          "question": {
            "id": 199,
            "questionText": "A Developer is leveraging a Border Gateway Protocol (BGP)-based AWS VPN connection to connect from on-premises to Amazon EC2 instances in the Developer's account. The Developer is able to access an EC2 instance in subnet A, but is unable to access an EC2 instance in subnet B in the same VPC. Which logs can the Developer use to verify whether the traffic is reaching subnet B?",
            "questionImage": null,
            "options": [
              {
                "text": "VPN logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "BGP logs",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "VPC Flow Logs.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS CloudTrail logs.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 16,
          "question": {
            "id": 193,
            "questionText": "A Software Engineer developed an AWS Lambda function in Node.js to do some CPU-intensive data processing. With the default settings, the Lambda function takes about 5 minutes to complete. Which approach should a Developer take to increase the speed of completion?",
            "questionImage": null,
            "options": [
              {
                "text": "Instead of using Node.js, rewrite the Lambda function using Python.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Instead of packaging the libraries in the `ZIP` file with the function, move them to a Lambda layer and use the layer with the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Allocate the maximum available CPU units to the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the available memory to the function.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 17,
          "question": {
            "id": 279,
            "questionText": "A company is running a Docker application on Amazon ECS. The application must scale based on user load in the last 15 seconds. How should a Developer instrument the code so that the requirement can be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 30 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a high-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a standard-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 30 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a standard-resolution custom Amazon CloudWatch metric for user activity data, then publish data every 5 seconds.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 18,
          "question": {
            "id": 230,
            "questionText": "Which features can be used to restrict access to data in S3? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Use S3 Virtual Hosting.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set an S3 Bucket policy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Enable IAM Identity Federation.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set an S3 ACL on the bucket or the object.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a CloudFront distribution for the bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 19,
          "question": {
            "id": 249,
            "questionText": "What is one key difference between an Amazon EBS-backed and an instance-store backed instance?",
            "questionImage": null,
            "options": [
              {
                "text": "Virtual Private Cloud requires EBS backed instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon EBS-backed instances can be stopped and restarted.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Auto scaling requires using Amazon EBS-backed instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Instance-store backed instances can be stopped and restarted.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 20,
          "question": {
            "id": 200,
            "questionText": "A Developer has created a new AWS IAM user that has `s3:putObject` permission to write to a specific Amazon S3 bucket. This S3 bucket uses server-side encryption with AWS KMS managed keys (SSE-KMS) as the default encryption. Using the access key and secret key of the IAM user, the application received an access denied error when calling the `PutObject` API. How can this issue be resolved?",
            "questionImage": null,
            "options": [
              {
                "text": "Update the policy of the IAM user to allow the `s3:EncryptionConfiguration` action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the bucket policy of the S3 bucket to allow the IAM user to upload objects.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the policy of the IAM user to allow the `kms:GenerateDataKey` action.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Update the ACL of the S3 bucket to allow the IAM user to upload objects.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 21,
          "question": {
            "id": 292,
            "questionText": "A Developer wants to debug an application by searching and filtering log data. The application logs are stored in Amazon CloudWatch Logs. The Developer creates a new metric filter to count exceptions in the application logs. However, no results are returned from the logs. What is the reason that no filtered results are being returned?",
            "questionImage": null,
            "options": [
              {
                "text": "A setup of the Amazon CloudWatch interface VPC endpoint is required for filtering the CloudWatch Logs in the VPC.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "CloudWatch Logs only publishes metric data for events that happen after the filter is created.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The log group for CloudWatch Logs should be first streamed to Amazon Elasticsearch Service before metric filtering returns the results.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Metric data points for logs groups can be filtered only after they are exported to an Amazon S3 bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 22,
          "question": {
            "id": 60,
            "questionText": "A Developer has created a large Lambda function, and deployment is failing with the following error: `ClientError: An error occurred (InvalidParameterValueException) when calling the CreateFunction operation: Unzipped size must be smaller than XXXXXXXXX bytes.`, where `XXXXXXXXX` is the current Lambda limit. What can the Developer do to fix this problem?",
            "questionImage": null,
            "options": [
              {
                "text": "Submit a limit increase request to AWS Support to increase the function to the size needed.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use a compression algorithm that is more efficient than `ZIP`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Break the function into multiple smaller Lambda functions.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "ZIP the `ZIP` file twice to compress it further.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 23,
          "question": {
            "id": 324,
            "questionText": "A Developer wants to enable AWS X-Ray for a secure application that runs in an Amazon ECS environment. What combination of steps will enable X-Ray? (Select THREE)",
            "questionImage": null,
            "options": [
              {
                "text": "Create a Docker image that runs the X-Ray daemon.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add instrumentation to the application code for X-Ray.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install the X-Ray daemon on the underlying EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure and use an IAM EC2 instance role.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Register the application with X-Ray.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure and use an IAM role for tasks.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "2",
            "6"
          ],
          "isCorrect": false
        },
        {
          "qNum": 24,
          "question": {
            "id": 275,
            "questionText": "A Developer is building a three-tier web application that should be able to handle a minimum of 5000 requests per minute. Requirements state that the web tier should be completely stateless while the application maintains session state for the users. How can session data be externalized, keeping latency at the LOWEST possible value?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an Amazon RDS instance, then implement session handling at the application level to leverage a database inside the RDS database instance for session data storage.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement a shared file system solution across the underlying Amazon EC2 instances, then implement session handling at the application level to leverage the shared file system for session data storage.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon ElastiCache Memcached cluster, then implement session handling at the application level to leverage the cluster for session data storage.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an Amazon DynamoDB table, then implement session handling at the application level to leverage the table for session data storage.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 25,
          "question": {
            "id": 258,
            "questionText": "An Amazon S3 bucket, `myawsbucket` is configured with website hosting in Tokyo region, what is the region-specific website endpoint?",
            "questionImage": null,
            "options": [
              {
                "text": "`www.myawsbucket.ap-northeast-1.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`myawsbucket.s3-website-ap-northeast-1.amazonaws.com`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`myawsbucket.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`myawsbucket.tokyo.amazonaws.com`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 26,
          "question": {
            "id": 9,
            "questionText": "A company is building a compute-intensive application that will run on a fleet of Amazon EC2 instances. The application uses attached Amazon EBS disks for storing data. The application will process sensitive information and all the data must be encrypted. What should a developer do to ensure the data is encrypted on disk without impacting performance?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure the Amazon EC2 instance fleet to use encrypted EBS volumes for storing data.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add logic to write all data to an encrypted Amazon S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a custom encryption algorithm to the application that will encrypt and decrypt all data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a new Amazon Machine Image (AMI) with an encrypted root volume and store the data to ephemeral disks.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 27,
          "question": {
            "id": 163,
            "questionText": "An application has the following requirements: Performance efficiency of seconds with up to a minute of latency. The data storage size may grow up to thousands of terabytes. Per-message sizes may vary between 100 KB and 100 MB. Data can be stored as key/value stores supporting eventual consistency. What is the MOST cost-effective AWS service to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon RDS (with a MySQL engine).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon ElastiCache.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 28,
          "question": {
            "id": 385,
            "questionText": "A Developer has implemented a Lambda function that needs to add new customers to an RDS database that is expected to run hundreds of times per hour. The Lambda function is configured to use 512MB of RAM and is based on the following pseudo code. After testing the Lambda function, the Developer notices that the Lambda execution time is much longer than expected. What should the Developer do to improve performance?",
            "questionImage": "images/question385.jpg",
            "options": [
              {
                "text": "Increase the amount of RAM allocated to the Lambda function, which will increase the number of threads the Lambda can use.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the size of the RDS database to allow for an increased number of database connections each hour.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Move the database connection and close statement out of the handler. Place the connection in the global space.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Replace RDS wit Amazon DynamoDB to implement control over the number of writes per second.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 29,
          "question": {
            "id": 169,
            "questionText": "A Developer is preparing a deployment package using AWS CloudFormation. The package consists of two separate templates: one for the infrastructure and one for the application. The application has to be inside the VPC that is created from the infrastructure template. How can the application stack refer to the VPC created from the infrastructure template?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the Ref function to import the VPC into the application stack from the infrastructure template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the export flag in the infrastructure template, and then use the `Fn::ImportValue` function in the application template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use the `DependsOn` attribute to specify that the application instance depends on the VPC in the application template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `Fn::GetAtt` function to include the attribute of the VPC in the application template.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 30,
          "question": {
            "id": 265,
            "questionText": "If an application is storing hourly log files from thousands of instances from a high traffic web site, which naming scheme would give optimal performance on S3?",
            "questionImage": null,
            "options": [
              {
                "text": "Sequential.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`instanceID_log-HH-DD-MM-YYYY`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`instanceIDLog-YYYY-MM-DD-HH`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`HH-DD-MM-YYYY-log_instanceID`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`YYYY-MM-DD-HH-logInstanceID`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 31,
          "question": {
            "id": 337,
            "questionText": "A company is building an application to track athlete performance using an Amazon DynamoDB table. Each item in the table is identified by a partition key (`user_id`) and a sort key (`sport_name`). The table design is shown below. (Note: Not all table attributes are shown) A Developer is asked to write a leaderboard application to display the top performers (`user_id`) based on the score for each `sport_name`. What process will allow the Developer to extract results MOST efficiently from the DynamoDB table?",
            "questionImage": "images/question337.jpg",
            "options": [
              {
                "text": "Use a DynamoDB query operation with the key attributes of `user_id` and `sport_name` and order the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a global secondary index with a partition key of `sport_name` and a sort key of score, and get the results.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use a DynamoDB scan operation to retrieve scores and `user_id` based on `sport_name`, and order the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a local secondary index with a primary key of `sport_name` and a sort key of score and get the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 32,
          "question": {
            "id": 207,
            "questionText": "A company has a legacy application that was migrated to a fleet of Amazon EC2 instances. The application stores data in a MySQL database that is currently installed on a single EC2 instance. The company has decided to migrate the database from the EC2 instance to MySQL on Amazon RDS. What should the Developer do to update the application to support data storage in Amazon RDS?",
            "questionImage": null,
            "options": [
              {
                "text": "Update the database connection parameters in the application to point to the new RDS instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add a script to the EC2 instance that implements an AWS SDK for requesting database credentials.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a new EC2 instance with an IAM role that allows access to the new RDS database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an AWS Lambda function that will route traffic, from the EC2 instance to the RDS database.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 33,
          "question": {
            "id": 352,
            "questionText": "A company caches session information for a web application in an Amazon DynamoDB table. The company wants an automated way to delete old items from the table. What is the simplest way to do this?",
            "questionImage": null,
            "options": [
              {
                "text": "Write a script that deletes old records; schedule the scripts as a cron job on an Amazon EC2 instance.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an attribute with the expiration time; enable the `Time To Live` feature based on that attribute.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Each day, create a new table to hold session data; delete the previous day's table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an attribute with the expiration time; name the attribute `ItemExpiration`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 34,
          "question": {
            "id": 7,
            "questionText": "An application is being developed to audit several AWS accounts. The application will run in Account A and must access AWS services in Accounts B and C. What is the MOST secure way to allow the application to call AWS services in each audited account?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure cross-account roles in each audited account. Write code in Account A that assumes those roles.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use S3 cross-region replication to communicate among accounts, with Amazon S3 event notifications to trigger Lambda functions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy an application in each audited account with its own role. Have Account A authenticate with the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM user with an access key in each audited account. Write code in Account A that uses those access keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 35,
          "question": {
            "id": 194,
            "questionText": "An online retail company has deployed a serverless application with AWS Lambda, Amazon API Gateway, Amazon S3, and Amazon DynamoDB using AWS CloudFormation. The company rolled out a new release with major upgrades to the Lambda function and deployed the release to production. Subsequently, the application stopped working. Which solution should bring the application back up as quickly as possible?",
            "questionImage": null,
            "options": [
              {
                "text": "Redeploy the application on Amazon EC2 so the Lambda function can resolve dependencies.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Migrate DynamoDB to Amazon RDS and redeploy the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Roll back the Lambda function to the previous version.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Deploy the latest Lambda function in a different Region.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 36,
          "question": {
            "id": 197,
            "questionText": "A company is developing an application that will be accessed through the Amazon API Gateway REST API. Registered users should be the only ones who can access certain resources of this API. The token being used should expire automatically and needs to be refreshed periodically. How can a Developer meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an Amazon Cognito identity pool, configure the Amazon Cognito Authorizer in API Gateway, and use the temporary credentials generated by the identity pool.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create and maintain a database record for each user with a corresponding token and use an AWS Lambda authorizer in API Gateway.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon Cognito user pool, configure the Cognito Authorizer in API Gateway, and use the identity or access token.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an IAM user for each API user, attach an invoke permissions policy to the API, and use an IAM authorizer in API Gateway.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 37,
          "question": {
            "id": 330,
            "questionText": "How should custom libraries be utilized in AWS Lambda?",
            "questionImage": null,
            "options": [
              {
                "text": "Host the library on Amazon S3 and reference to it from the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Install the library locally and upload a `ZIP` file of the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Import the necessary Lambda blueprint when creating the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the function runtime to include the necessary library.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 38,
          "question": {
            "id": 239,
            "questionText": "Which of the following is chosen as the default region when making an API call with an AWS SDK?",
            "questionImage": null,
            "options": [
              {
                "text": "`ap-northeast-1`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`us-west-2`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`us-east-1`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`eu-west-1`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`us-central-1`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 39,
          "question": {
            "id": 104,
            "questionText": "A company is building a stock trading application that requires sub-millisecond latency in processing trading requests. Amazon DynamoDB is used to store all the trading data that is used to process each request. After load testing the application, the development team found that due to data retrieval times, the latency requirement is not satisfied. Because of sudden high spikes in the number of requests, DynamoDB read capacity has to be significantly over-provisioned to avoid throttling. What steps should be taken to meet latency requirements and reduce the cost of running the application?",
            "questionImage": null,
            "options": [
              {
                "text": "Add Global Secondary Indexes for trading data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store trading data in Amazon S3 and use Transfer Acceleration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add retries with exponential back-off for DynamoDB queries.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use DynamoDB Accelerator to cache trading data.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 40,
          "question": {
            "id": 171,
            "questionText": "A Developer is trying to monitor an application's status by running a cron job that returns 1 if the service is up and 0 if the service is down. The Developer created code that uses an AWS CLI `put-metric-alarm` command to publish the custom metrics to Amazon CloudWatch and create an alarm. However, the Developer is unable to create an alarm as the custom metrics do not appear in the CloudWatch console. What is causing this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Sending custom metrics using the CLI is not supported.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The Developer needs to use the `put-metric-data` command.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The Developer must use a unified CloudWatch agent to publish custom metrics.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The code is not running on an Amazon EC2 instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 41,
          "question": {
            "id": 271,
            "questionText": "A team of Developers must migrate an application running inside an AWS Elastic Beanstalk environment from a Classic Load Balancer to an Application Load Balancer. Which steps should be taken to accomplish the task using the AWS Management Console?",
            "questionImage": null,
            "options": [
              {
                "text": "1. Update the application code in the existing deployment. 2. Select a new load balancer type before running the deployment. 3. Deploy the new version of the application code to the environment.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "1. Create a new environment with the same configurations except for the load balancer type. 2. Deploy the same application version as used in the original environment. 3. Run the `swap-environment-cnames` action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1. Clone the existing environment, changing the associated load balancer type. 2. Deploy the same application version as used in the original environment. 3. Run the `swap-environment-cnames` action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1. Edit the environment definitions in the existing deployment. 2. Change the associated load balancer type according to the requirements. 3. Rebuild the environment with the new load balancer type.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 42,
          "question": {
            "id": 202,
            "questionText": "A Developer is working on an AWS Lambda function that accesses Amazon DynamoDB. The Lambda function must retrieve an item and update some of its attributes, or create the item if it does not exist. The Lambda function has access to the primary key. Which IAM permissions should the Developer request for the Lambda function to achieve this functionality?",
            "questionImage": null,
            "options": [
              {
                "text": "`dynamodb:DeleteItem dynamodb:GetItem dynamodb:PutItem`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`dynamodb:UpdateItem dynamodb:GetItem dynamodb:DescribeTable`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`dynamodb:GetRecords dynamodb:PutItem dynamodb:UpdateTable`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`dynamodb:UpdateItem dynamodb:GetItem dynamodb:PutItem`.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 43,
          "question": {
            "id": 261,
            "questionText": "You run an ad-supported photo sharing website using S3 to serve photos to visitors of your site. At some point you find out that other sites have been linking to the photos on your site, causing loss to your business. What is an effective method to mitigate this?",
            "questionImage": null,
            "options": [
              {
                "text": "Store photos on an EBS volume of the web server.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Remove public read access and use signed URLs with expiry dates.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use CloudFront distributions for static content.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Block the IPs of the offending websites in Security Groups.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 44,
          "question": {
            "id": 53,
            "questionText": "A web application is using Amazon Kinesis Streams for clickstream data that may not be consumed for up to 12 hours. How can the Developer implement encryption at rest for data within the Kinesis Streams?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable SSL connections to Kinesis.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Kinesis Consumer Library.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Encrypt the data once it is at rest with a Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable server-side encryption in Kinesis Streams.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 45,
          "question": {
            "id": 340,
            "questionText": "What does an Amazon SQS delay queue accomplish?",
            "questionImage": null,
            "options": [
              {
                "text": "Messages are hidden for a configurable amount of time when they are first added to the queue.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Messages are hidden for a configurable amount of time after they are consumed from the queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The consumer can poll the queue for a configurable amount of time before retrieving a message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Message cannot be deleted for a configurable amount of time after they are consumed from the queue.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 46,
          "question": {
            "id": 192,
            "questionText": "An application ingests a large number of small messages and stores them in a database. The application uses AWS Lambda. A Development team is making changes to the application's processing logic. In testing, it is taking more than 15 minutes to process each message. The team is concerned the current backend may time out. Which changes should be made to the backend system to ensure each message is processed in the MOST scalable way?",
            "questionImage": null,
            "options": [
              {
                "text": "Add the messages to an Amazon SQS queue. Set up and Amazon EC2 instance to poll the queue and process messages as they arrive.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add the messages to an Amazon SQS queue. Set up Amazon EC2 instances in an Auto Scaling group to poll the queue and process the messages as they arrive.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a support ticket to increase the Lambda timeout to 60 minutes to allow for increased processing time.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the application to directly insert the body of the message into an Amazon RDS database.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 47,
          "question": {
            "id": 184,
            "questionText": "A Developer migrated a web application to AWS. As part of the migration, the Developer implemented an automated continuous integration/continuous improvement (CI/CD) process using a blue/green deployment. The deployment provisions new Amazon EC2 instances in an Auto Scaling group behind a new Application Load Balancer. After the migration was completed, the Developer began receiving complaints from users getting booted out of the system. The system also requires users to log in after every new deployment. How can these issues be resolved?",
            "questionImage": null,
            "options": [
              {
                "text": "Use rolling updates instead of a blue/green deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Externalize the user sessions to Amazon ElastiCache.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Turn on sticky sessions in the Application Load Balancer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use multicast to replicate session information.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 48,
          "question": {
            "id": 327,
            "questionText": "A Developer wants to find a list of items in a global secondary index from an Amazon DynamoDB table. Which DynamoDB API call can the Developer use in order to consume the LEAST number of read capacity units?",
            "questionImage": null,
            "options": [
              {
                "text": "Scan operation using `eventually-consistent` reads.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Query operation using `strongly-consistent` reads.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Query operation using `eventually-consistent` reads.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Scan operation using `strongly-consistent` reads.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 49,
          "question": {
            "id": 242,
            "questionText": "Which of the following are valid SNS delivery transports? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "HTTP.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "UDP.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SMS.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Named Pipes.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 50,
          "question": {
            "id": 274,
            "questionText": "A Developer created a new AWS account and must create a scalable AWS Lambda function that meets the following requirements for concurrent execution: Average execution time of 100 seconds 50 requests per second. Which step must be taken prior to deployment to prevent errors?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement dead-letter queues to capture invocation errors.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an event source from Amazon API Gateway to the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement error handling within the application code.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Contact AWS Support to increase the concurrent execution limits.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 51,
          "question": {
            "id": 180,
            "questionText": "A Developer is building an application that needs to store data in Amazon S3. Management requires that the data be encrypted before it is sent to Amazon S3 for storage. The encryption keys need to be managed by the Security team. Which approach should the Developer take to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement server-side encryption using customer-provided encryption keys (SSE-C).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement server-side encryption by using a client-side master key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement client-side encryption using an AWS KMS managed customer master key (CMK).",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Implement client-side encryption using Amazon S3 managed keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 52,
          "question": {
            "id": 384,
            "questionText": "Where should an Elastic Beanstalk configuration file named `healthcheckur1.config` be placed in the application source bundle?",
            "questionImage": null,
            "options": [
              {
                "text": "In the `root` of the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the `bin` folder.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In `healthcheckur1.config.ebextension` under `root`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the `.ebextensions` folder.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 53,
          "question": {
            "id": 370,
            "questionText": "A social media company is using Amazon Cognito in order to synchronize profiles across different mobile devices, to enable end users to have a seamless experience. Which of the following configurations can be used to silently notify users whenever an update is available on all other devices?",
            "questionImage": null,
            "options": [
              {
                "text": "Modify the user pool to include all the devices which keep them in sync.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the SyncCallback interface to receive notifications on the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon Cognito stream to analyze the data and push the notifications.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the push synchronization feature with the appropriate IAM role.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 54,
          "question": {
            "id": 233,
            "questionText": "How can software determine the public and private IP addresses of the Amazon EC2 instance that it is running on?",
            "questionImage": null,
            "options": [
              {
                "text": "Query the appropriate Amazon CloudWatch metric.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use `ipconfig` or `ifconfig` command.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Query the local instance userdata.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Query the local instance metadata.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 55,
          "question": {
            "id": 313,
            "questionText": "In a multi-container Docker environment in AWS Elastic Beanstalk, what is required to configure container instances in the environment?",
            "questionImage": null,
            "options": [
              {
                "text": "An Amazon ECS task definition.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An Amazon ECS cluster.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A Dockerfile in an application package.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A CLI for Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 56,
          "question": {
            "id": 6,
            "questionText": "A Developer wants to encrypt new objects that are being uploaded to an Amazon S3 bucket by an application. There must be an audit trail of who has used the key during this process. There should be no change to the performance of the application. Which type of encryption meets these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Server-side encryption using S3-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client-side encryption with a client-side symmetric master key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Client-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 57,
          "question": {
            "id": 348,
            "questionText": "While developing an application that runs on Amazon EC2 in an Amazon VPC, a Developer identifies the need for centralized storage of application-level logs. Which AWS service can be used to securely store these logs?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon EC2 VPC Flow Logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon CloudWatch Logs.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon CloudSearch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CloudTrail",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 58,
          "question": {
            "id": 361,
            "questionText": "A Developer is creating a Lambda function that will generate and export a file. The function requires 100 MB of temporary storage for temporary files while executing. These files will not be needed after the function is complete. How can the Developer MOST efficiently handle the temporary files?",
            "questionImage": null,
            "options": [
              {
                "text": "Store the files in EBS and delete the files at the end of the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Copy the files to EFS and delete the files at the end of the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the files in the `/tmp` directory and delete the files at the end of the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Copy the files to an S3 bucket with a lifecycle policy to delete the files.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 59,
          "question": {
            "id": 8,
            "questionText": "A company uses a third-party tool to build, bundle, and package rts applications on-premises and store them locally. The company uses Amazon EC2 instances to run its front-end applications. How can an application be deployed from the source control system onto the EC2 instances?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS CodeDeploy and point it to the local storage to directly deploy a bundle m a zip. tar. or tar.gz format.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload the bundle to an Amazon S3 bucket and specify the S3 location when doing a deployment using AWS CodeDeploy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a repository using AWS CodeCommit to automatically trigger a deployment to the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CodeBuild to automatically deploy the latest build to the latest EC2 instances.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 60,
          "question": {
            "id": 347,
            "questionText": "An organization is storing large files in Amazon S3, and is writing a web application to display meta-data about the files to end-users. Based on the metadata a user selects an object to download. The organization needs a mechanism to index the files and provide single-digit millisecond latency retrieval for the metadata. What AWS service should be used to accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon EC2.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon RDS.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 61,
          "question": {
            "id": 210,
            "questionText": "A company wants to implement authentication for its new REST service using Amazon API Gateway. To authenticate the calls, each request must include HTTP headers with a client ID and user ID. These credentials must be compared to authentication data in an Amazon DynamoDB table. What MUST the company do to implement this authentication in API Gateway?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement an AWS Lambda authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a model that requires the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the integration requests to require the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement an Amazon Cognito authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 62,
          "question": {
            "id": 151,
            "questionText": "A developer is writing an application that will process data delivered into an Amazon S3 bucket. The data is delivered approximately 10 times a day, and the developer expects the data will be processed in less than 1 minute, on average. How can the developer deploy and invoke the application with the lowest cost and lowest latency?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an Amazon CloudWatch alarm triggered by an S3 object upload.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an S3 event notification.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Deploy the application as an AWS Lambda function and invoke it with an Amazon CloudWatch scheduled event.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the application onto an Amazon EC2 instance and have it poll the S3 bucket for new objects.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 63,
          "question": {
            "id": 364,
            "questionText": "A company is migrating from a monolithic architecture to a microservices-based architecture. The Developers need to refactor the application so that the many microservices can asynchronously communicate with each other without impacting performance. Use of which managed AWS services will enable asynchronous message passing? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon SQS.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon Cognito.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Kinesis.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SNS.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon ElastiCache.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 64,
          "question": {
            "id": 4,
            "questionText": "A company's ecommerce website is experiencing massive traffic spikes, which are causing performance problems in the company database. Users are reporting that accessing the website takes a long time. A developer wants to implement a caching layer using Amazon ElastiCache. The website is required to be responsive no matter which product a user views, and the updates to product information and prices must be strongly consistent. Which cache writing policy will satisfy these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Write to the cache directly and sync the backend at a later time.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write to the backend first and wait for the cache to expire.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write to the cache and the backend at the same time.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write to the backend first and invalidate the cache.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 65,
          "question": {
            "id": 36,
            "questionText": "A supplier is writing a new RESTful API for customers to query the status of orders. The customers requested the following API endpoint `http://www.supplierdomain.com/status/customerID`. Which of the following application designs meet the requirements? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon SQS; Amazon SNS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Elastic Load Balancing; Amazon EC2.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon ElastiCache; Amazon Elacticsearch Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon API Gateway; AWS Lambda.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3; Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "4"
          ],
          "isCorrect": false
        }
      ]
    },
    {
      "id": "1762892221111",
      "date": "20:17:01 11/11/2025",
      "score": "3.08",
      "results": [
        {
          "qNum": 1,
          "question": {
            "id": 347,
            "questionText": "An organization is storing large files in Amazon S3, and is writing a web application to display meta-data about the files to end-users. Based on the metadata a user selects an object to download. The organization needs a mechanism to index the files and provide single-digit millisecond latency retrieval for the metadata. What AWS service should be used to accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon EC2.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon RDS.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 2,
          "question": {
            "id": 310,
            "questionText": "A company has three different environments: Development, QA, and Production. The company wants to deploy its code first in the Development environment, then QA, and then Production. Which AWS service can be used to meet this requirement?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS CodeCommit to create multiple repositories to deploy the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CodeBuild to create, configure, and deploy multiple build application projects.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Data Pipeline to create multiple data pipeline provisions to deploy the application.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS CodeDeploy to create multiple deployment groups.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 3,
          "question": {
            "id": 70,
            "questionText": "An application is real-time processing millions of events that are received through an API. What service could be used to allow multiple consumers to process the data concurrently and MOST cost-effectively?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon SNS with fanout to an SQS queue for each application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SNS with fanout to an SQS FIFO (first-in, first-out) queue for each application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Kinesis Firehose.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Kinesis Streams.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 4,
          "question": {
            "id": 113,
            "questionText": "A developer is setting up Amazon API Gateway for their company's products. The API will be used by registered developers to query and update their environments. The company wants to limit the amount of requests end users can send for both cost and security reasons. Management wants to offer registered developers the option of buying larger packages that allow for more requests. How can the developer accomplish this with the LEAST amount of overhead management?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable throttling for the API Gateway stage. Set a value for both the rate and burst capacity. If a registered user chooses a larger package, create a stage for them, adjust the values, and share the new URL with them.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set up Amazon CloudWatch API logging in API Gateway. Create a filter based on the user and requestTime fields and create an alarm on this filter. Write an AWS Lambda function to analyze the values and requester information, and respond accordingly. Set up the function as the target for the alarm. If a registered user chooses a larger package, update the Lambda code with the values.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable Amazon CloudWatch metrics for the API Gateway stage. Set up CloudWatch alarms based off the Count metric and the ApiName, Method, Resource, and Stage dimensions to alerts when request rates pass the threshold. Set the alarm action to `Deny`. If a registered user chooses a larger package, create a user-specific alarm and adjust the values.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set up a default usage plan, specify values for the rate and burst capacity, and associate it with a stage. If a registered user chooses a larger package, create a custom plan with the appropriate values and associate the plan with the user.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 5,
          "question": {
            "id": 248,
            "questionText": "An application stores payroll information nightly in DynamoDB for a large number of employees across hundreds of offices. Item attributes consist of individual name, office identifier, and cumulative daily hours. Managers run reports for ranges of names working in their office. One query is: `Return all Items in this office for names starting with A through E`. Which table configuration will result in the lowest impact on provisioned throughput for this query?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure the table to have a hash index on the name attribute, and a range index on the office identifier.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure the table to have a range index on the name attribute, and a hash index on the office identifier.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure a hash index on the name attribute and no range index.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure a hash index on the office identifier attribute and no range index.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": true
        },
        {
          "qNum": 6,
          "question": {
            "id": 223,
            "questionText": "Which of the following are correct statements with policy evaluation logic in AWS Identity and Access Management? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "By default, all requests are denied.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An explicit allow overrides an explicit deny.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An explicit allow overrides default deny.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "An explicit deny does not override an explicit allow.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "By default, all request are allowed.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "1",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 7,
          "question": {
            "id": 369,
            "questionText": "A company is using AWS CodePipeline to deliver one of its applications. The delivery pipeline is triggered by changes to the master branch of an AWS CodeCommit repository and uses AWS CodeBuild to implement the test and build stages of the process and AWS CodeDeploy to deploy the application. The pipeline has been operating successfully for several months and there have been no modifications. Following a recent change to the application's source code, AWS CodeDeploy has not deployed the updates application as expected. What are the possible causes? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "The change was not made in the master branch of the AWS CodeCommit repository.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "One of the earlier stages in the pipeline failed and the pipeline has terminated.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "One of the Amazon EC2 instances in the company's AWS CodePipeline cluster is inactive.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The AWS CodePipeline is incorrectly configured and is not executing AWS CodeDeploy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodePipeline does not have permissions to access AWS CodeCommit.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "1",
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 8,
          "question": {
            "id": 262,
            "questionText": "Which statements about DynamoDB are true? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "DynamoDB uses a pessimistic locking model.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "DynamoDB uses optimistic concurrency control.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "DynamoDB uses conditional writes for consistency.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "DynamoDB restricts item access during reads.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "DynamoDB restricts item access during writes.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 9,
          "question": {
            "id": 135,
            "questionText": "Two containerized microservices are hosted on Amazon EC2 ECS. The first microservice reads an Amazon RDS Aurora database instance, and the second microservice reads an Amazon DynamoDB table. How can each microservice be granted the minimum privileges?",
            "questionImage": null,
            "options": [
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `false` on EC2 instance boot in ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the second microservice with an IAM role for ECS tasks with read-only access to DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `false` on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `true` on EC2 instance boot in the ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the secondmicroservice with an IAM role for ECS tasks with read-only access to DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `true` on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": true
        },
        {
          "qNum": 10,
          "question": {
            "id": 266,
            "questionText": "Which of the following statements about SQS is true?",
            "questionImage": null,
            "options": [
              {
                "text": "Messages will be delivered exactly once and messages will be delivered in First in, First out order.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered exactly once and message delivery order is indeterminate.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered one or more times and messages will be delivered in First in, First out order.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Messages will be delivered one or more times and message delivery order is indeterminate.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 11,
          "question": {
            "id": 280,
            "questionText": "A company needs to ingest terabytes of data each hour from thousands of sources that are delivered almost continually throughout the day. The volume of messages generated varies over the course of the day. Messages must be delivered in real time for fraud detection and live operational dashboards. Which approach will meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Send the messages to an Amazon SQS queue, then process the messages by using a fleet of Amazon EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the Amazon S3 API to write messages to an S3 bucket, then process the messages by using Amazon Redshift.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Data Pipeline to automate the movement and transformation of data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Kinesis Data Streams with Kinesis Client Library to ingest and deliver messages.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 12,
          "question": {
            "id": 129,
            "questionText": "A developer receives the following error message when trying to launch or terminate an Amazon EC2 instance using a boto3 script. What should the developer do to correct this error message?",
            "questionImage": "images/question129.jpg",
            "options": [
              {
                "text": "Assign an IAM role to the EC2 instance to allow necessary API calls on behalf of the client.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement an exponential backoff algorithm for optimizing the number of API requests made to Amazon EC2.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Increase the overall network bandwidth to handle higher API request rates.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upgrade to the latest AWS CLI version so that boto3 can handle higher request rates.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 13,
          "question": {
            "id": 159,
            "questionText": "A company wants to containerize an existing three-tier web application and deploy it to Amazon ECS Fargate. The application is using session data to keep track of user activities. Which approach would provide the BEST user experience?",
            "questionImage": null,
            "options": [
              {
                "text": "Provision a Redis cluster in Amazon ElastiCache and save the session data in the cluster.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a session table in Amazon Redshift and save the session data in the database table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable session stickiness in the existing Network Load Balancer and manage the session data in the container.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon S3 bucket as data store and save the session data in the bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "4"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 14,
          "question": {
            "id": 72,
            "questionText": "An application will ingest data at a very high throughput from many sources and must store the data in an Amazon S3 bucket. Which service would BEST accomplish this task?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon Kinesis Firehose.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3 Acceleration Transfer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SQS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon SNS.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 15,
          "question": {
            "id": 119,
            "questionText": "A company has 25,000 employees and is growing. The company is creating an application that will be accessible to its employees only. A developer is using Amazon S3 to store images and Amazon RDS to store application data. The company requires that all employee information remain in the legacy Security Assertion Markup Language (SAML) employee directory only and is not interested in mirroring any employee information on AWS. How can the developer provide authorized access for the employees who will be using this application so each employee can access their own application data only?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon VPC and keep all resources inside the VPC, and use a VPC link for the S3 bucket with the bucket policy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito user pools, federate with the SAML provider, and use user pool groups with an IAM policy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon Cognito identity pool, federate with the SAML provider, and use an IAM condition key with a value for the `cognito-identity.amazonaws.com:sub` variable to grant access to the employees.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a unique IAM role for each employee and have each employee assume the role to access the application so they can access their personal data only.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 16,
          "question": {
            "id": 102,
            "questionText": "A Developer will be using the AWS CLI on a local development server to manage AWS services. What can be done to ensure that the CLI uses the Developer's IAM permissions when making commands?",
            "questionImage": null,
            "options": [
              {
                "text": "Specify the Developer's IAM access key ID and secret access key as parameters for each CLI command.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Run the `aws configure` CLI command, and provide the Developer's IAM access key ID and secret access key.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Specify the Developer's IAM user name and password as parameters for each CLI command.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the Developer's IAM role when making the CLI command.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 17,
          "question": {
            "id": 127,
            "questionText": "A developer is writing a web application that must share secure documents with end users. The documents are stored in a private Amazon S3 bucket. The application must allow only authenticated users to download specific documents when requested, and only for a duration of 15 minutes. How can the developer meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Copy the documents to a separate S3 bucket that has a lifecycle policy for deletion after 15 minutes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a presigned S3 URL using the AWS SDK with an expiration time of 15 minutes.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use server-side encryption with AWS KMS managed keys (SSE-KMS) and download the documents using HTTPS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the S3 bucket policy to only allow specific users to download the documents. Revert the change after 15 minutes.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 18,
          "question": {
            "id": 76,
            "questionText": "A legacy service has an XML-based SOAP interface. The Developer wants to expose the functionality of the service to external clients with the Amazon API Gateway. Which technique will accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a RESTful API with the API Gateway; transform the incoming JSON into a valid XML message for the SOAP interface using mapping templates.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a RESTful API with the API Gateway; pass the incoming JSON to the SOAP interface through an Application Load Balancer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a RESTful API with the API Gateway; pass the incoming XML to the SOAP interface through an Application Load Balancer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a RESTful API with the API Gateway; transform the incoming XML into a valid message for the SOAP interface using mapping templates.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 19,
          "question": {
            "id": 286,
            "questionText": "A company needs to distribute firmware updates to its customers around the world. Which service will allow easy and secure control of the access to the downloads at the lowest cost?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon CloudFront with signed URLs for Amazon S3.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a dedicated Amazon CloudFront Distribution for each customer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudFront with AWS Lambda@Edge.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon API Gateway and AWS Lambda to control access to an S3 bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 20,
          "question": {
            "id": 92,
            "questionText": "An application takes 40 seconds to process instructions received in an Amazon SQS message. Assuming the SQS queue is configured with the default `VisibilityTimeout` value, what is the BEST way, upon receiving a message, to ensure that no other instances can retrieve a message that has already been processed or is currently being processed?",
            "questionImage": null,
            "options": [
              {
                "text": "Use the `ChangeMessageVisibility` API to increase the `VisibilityTimeout`, then use the `DeleteMessage` API to delete the message.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use the `DeleteMessage` API call to delete the message from the queue, then call `DeleteQueue` API to remove the queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `ChangeMessageVisibility` API to decrease the timeout value, then use the `DeleteMessage` API to delete the message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the `DeleteMessageVisibility` API to cancel the `VisibilityTimeout`, then use the `DeleteMessage` API to delete the message.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 21,
          "question": {
            "id": 49,
            "questionText": "An application on AWS is using third-party APIs. The Developer needs to monitor API errors in the code, and wants to receive notifications if failures go above a set threshold value. How can the Developer achieve these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Publish a custom metric on Amazon CloudWatch and use Amazon Simple Email Service (SES) for notification.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon CloudWatch API-error metric and use Amazon Simple Notification Service (SNS) for notification.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon CloudWatch API-error metric and use Amazon SES for notification.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Publish a custom metric on Amazon CloudWatch and use Amazon SNS for notification.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 22,
          "question": {
            "id": 317,
            "questionText": "A company has a multi-tiered web application on AWS. During a recent spike in traffic, one of the primary relational databases on Amazon RDS could not serve all the traffic. Some read queries for repeatedly accessed items failed, so users received error messages. What can be done to minimize the impact on database read queries MOST efficiently during future traffic spikes?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon S3 to cache database query results.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon RDS as a custom origin for Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use local storage and memory on Amazon EC2 instances to cache data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache in front of the primary database to cache data.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 23,
          "question": {
            "id": 110,
            "questionText": "An application overwrites an object in Amazon S3, and then immediately reads the same object. Why would the application sometimes retrieve the old version of the object?",
            "questionImage": null,
            "options": [
              {
                "text": "S3 overwrite PUTS are eventually consistent, so the application may read the old object.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The application needs to add extra metadata to label the latest version when uploading to Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "All S3 PUTS are eventually consistent, so the application may read the old object.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The application needs to explicitly specify latest version when retrieving the object.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 24,
          "question": {
            "id": 160,
            "questionText": "An application is using a single-node Amazon ElastiCache for Redis instance to improve read performance. Over time, demand for the application has increased exponentially, which has increased the load on the ElastiCache instance. It is critical that this cache layer handles the load and is resilient in case of node failures. What can the Developer do to address the load and resiliency requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Add a read replica instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Migrate to a Memcached cluster.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Migrate to an Amazon Elasticsearch Service cluster.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Vertically scale the ElastiCache instance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 25,
          "question": {
            "id": 346,
            "questionText": "Where can PortMapping be defined when launching containers in Amazon ECS?",
            "questionImage": null,
            "options": [
              {
                "text": "Security groups.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Elastic Container Registry (Amzon ECR).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Container agent.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Task definition.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 26,
          "question": {
            "id": 301,
            "questionText": "A company maintains a REST service using Amazon API Gateway and the API Gateway native API key validation. The company recently launched a new registration page, which allows users to sign up for the service. The registration page creates a new API key using `CreateApiKey` and sends the new key to the user. When the user attempts to call the API using this key, the user receives a `403 Forbidden` error. Existing users are unaffected and can still call the API. What code updates will grant these new users access to the API?",
            "questionImage": null,
            "options": [
              {
                "text": "The `createDeployment` method must be called so the API can be redeployed to include the newly created API key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The `updateAuthorizer` method must be called to update the API's authorizer to include the newly created API key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The `importApiKeys` method must be called to import all newly created API keys into the current stage of the API.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The `createUsagePlanKey` method must be called to associate the newly created API key with the correct usage plan.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 27,
          "question": {
            "id": 109,
            "questionText": "A deployment package uses the AWS CLI to copy files into any S3 bucket in the account, using access keys stored in environment variables. The package is running on EC2 instances, and the instances have been modified to run with an assumed IAM role and a more restrictive policy that allows access to only one bucket. After the change, the Developer logs into the host and still has the ability to write into all of the S3 buckets in that account. What is the MOST likely cause of this situation?",
            "questionImage": null,
            "options": [
              {
                "text": "An IAM inline policy is being used on the IAM role.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An IAM managed policy is being used on the IAM role.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "The AWS CLI is corrupt and needs to be reinstalled.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The AWS credential provider looks for instance profile credentials last.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 28,
          "question": {
            "id": 59,
            "questionText": "Given the source code for an AWS Lambda function in the local `store.py` containing a handler function called `get_store` and the following AWS CloudFormation template. What should be done to prepare the template so that it can be deployed using the AWS CLI command `aws cloudformation deploy`?",
            "questionImage": "images/question59.jpg",
            "options": [
              {
                "text": "Use AWS CloudFormation compile to base64 encode and embed the source file into a modified CloudFormation template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CloudFormation package to upload the source code to an Amazon S3 bucket and produce a modified CloudFormation template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use AWS Lambda zip to package the source file together with the CloudFormation template and deploy the resulting zip archive.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Serverless `create-package` to embed the source file directly into the existing CloudFormation template.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 29,
          "question": {
            "id": 384,
            "questionText": "Where should an Elastic Beanstalk configuration file named `healthcheckur1.config` be placed in the application source bundle?",
            "questionImage": null,
            "options": [
              {
                "text": "In the `root` of the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the `bin` folder.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In `healthcheckur1.config.ebextension` under `root`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the `.ebextensions` folder.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 30,
          "question": {
            "id": 330,
            "questionText": "How should custom libraries be utilized in AWS Lambda?",
            "questionImage": null,
            "options": [
              {
                "text": "Host the library on Amazon S3 and reference to it from the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Install the library locally and upload a `ZIP` file of the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Import the necessary Lambda blueprint when creating the function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the function runtime to include the necessary library.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 31,
          "question": {
            "id": 61,
            "questionText": "A serverless application uses an API Gateway and AWS Lambda. Where should the Lambda function store its session information across function calls?",
            "questionImage": null,
            "options": [
              {
                "text": "In an Amazon DynamoDB table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "In an Amazon SQS queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In the local filesystem.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "In an SQLite session table using `CDSQLITE_ENABLE_SESSION`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 32,
          "question": {
            "id": 6,
            "questionText": "A Developer wants to encrypt new objects that are being uploaded to an Amazon S3 bucket by an application. There must be an audit trail of who has used the key during this process. There should be no change to the performance of the application. Which type of encryption meets these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Server-side encryption using S3-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client-side encryption with a client-side symmetric master key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Client-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 33,
          "question": {
            "id": 367,
            "questionText": "An application needs to use the IP address of the client in its processing. The application has been moved into AWS and has been placed behind an Application Load Balancer (ALB). However, all the client IP addresses now appear to be the same. The application must maintain the ability to scale horizontally. Based on this scenario, what is the MOST cost-effective solution to this problem?",
            "questionImage": null,
            "options": [
              {
                "text": "Remove the application from the ALB. Delete the ALB and change Amazon Route 53 to direct traffic to the instance running the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Remove the application from the ALB. Create a Classic Load Balancer in its place. Direct traffic to the application using the HTTP protocol.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Alter the application code to inspect the `X-Forwarded-For` header. Ensure that the code can work properly if a list of IP addresses is passed in the header.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Alter the application code to inspect a custom header. Alter the client code to pass the IP address in the custom header.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 34,
          "question": {
            "id": 91,
            "questionText": "A company wants to implement a continuous integration for its workloads on AWS. The company wants to trigger unit test in its pipeline for commits-on its code repository, and wants to be notified of failure events in the pipeline. How can these requirements be met?",
            "questionImage": null,
            "options": [
              {
                "text": "Store the source code in AWS CodeCommit. Create a CodePipeline to automate unit testing. Use Amazon SNS to trigger notifications of failure events.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the source code in GitHub. Create a CodePipeline to automate unit testing. Use Amazon SES to trigger notifications of failure events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the source code on GitHub. Create a CodePipeline to automate unit testing. Use Amazon CloudWatch to trigger notifications of failure events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the source code in AWS CodeCommit. Create a CodePipeline to automate unit testing. Use Amazon CloudWatch to trigger notification of failure events.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 35,
          "question": {
            "id": 16,
            "questionText": "The development team is working on an API that will be served from Amazon API gateway. The API will be served from three environments: development, test, and production. The API Gateway is configured to use 237 GB of cache in all three stages. Which is the MOST cost-efficient deployment strategy?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a single API Gateway with all three stages.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create three API Gateways, one for each stage in a single AWS account.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an API Gateway in three separate AWS accounts.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable the cache for development and test environments only when needed.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 36,
          "question": {
            "id": 211,
            "questionText": "A Developer is trying to make API calls using SDK. The IAM user credentials used by the application require multi-factor authentication for all API calls. Which method the Developer use to access the multi-factor authentication protected API?",
            "questionImage": null,
            "options": [
              {
                "text": "GetFederationToken.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "GetCallerIdentity.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "GetSessionToken.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "DecodeAutherizationMessage.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 37,
          "question": {
            "id": 20,
            "questionText": "A software company needs to make sure user-uploaded documents are securely stored in Amazon S3. The documents must be encrypted at rest in Amazon S3. The company does not want to manage the security infrastructure in-house, but the company still needs extra protection to ensure it has control over its encryption keys due to industry regulations. Which encryption strategy should a developer use to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Server-side encryption with Amazon S3 managed keys (SSE-S3).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with customer-provided encryption keys (SSE-C).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Server-side encryption with AWS KMS managed keys (SSE-KMS).",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client-side encryption.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 38,
          "question": {
            "id": 170,
            "questionText": "A Developer needs to create an application that supports Security Assertion Markup Language (SAML) and Facebook authentication. It must also allow access to AWS services, such as Amazon DynamoDB. Which AWS service or feature will meet these requirements with the LEAST amount of additional coding?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS AppSync.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito identity pools.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon Cognito user pools.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Lambda@Edge.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 39,
          "question": {
            "id": 219,
            "questionText": "After launching an instance that you intend to serve as a NAT (Network Address Translation) device in a public subnet you modify your route tables to have the NAT device be the target of internet bound traffic of your private subnet. When you try and make an outbound connection to the Internet from an instance in the private subnet, you are not successful. NAT device be the target of internet bound traffic of your private subnet. Which of the following steps could resolve the issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Attaching a second Elastic Network interface (ENI) to the NAT instance, and placing it in the private subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Attaching a second Elastic Network Interface (ENI) to the instance in the private subnet, and placing it in the public subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disabling the `Source/Destination Check` attribute on the NAT instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Attaching an Elastic IP address to the instance in the private subnet.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 40,
          "question": {
            "id": 334,
            "questionText": "In a move toward using microservices, a company's Management team has asked all Development teams to build their services so that API requests depend only on that service's data store. One team is building a Payments service which has its own database; the service needs data that originates in the Accounts database. Both are using Amazon DynamoDB. What approach will result in the simplest, decoupled, and reliable method to get near-real time updates from the Accounts database?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon Glue to perform frequent ETL updates from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon ElastiCache in Payments, with the cache updated by triggers in the Accounts database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Kinesis Data Firehose to deliver all changes from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon DynamoDB Streams to deliver all changes from the Accounts database to the Payments database.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 41,
          "question": {
            "id": 35,
            "questionText": "An application running on EC2 instances is storing data in an S3 bucket. Security policy mandates that all data must be encrypted in transit. How can the Developer ensure that all traffic to the S3 bucket is encrypted?",
            "questionImage": null,
            "options": [
              {
                "text": "Install certificates on the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a bucket policy that allows traffic where `SecureTransport` is `true`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an HTTPS redirect on the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a bucket policy that denies traffic where `SecureTransport` is `false`.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 42,
          "question": {
            "id": 40,
            "questionText": "A developer is writing an AWS Lambda function. The developer wants to log key events that occur during the Lambda function and include a unique identifier to associate the events with a specific function invocation. Which of the following will help the developer accomplish this objective?",
            "questionImage": null,
            "options": [
              {
                "text": "Obtain the request identifier from the Lambda context object. Architect the application to write logs to the console.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Obtain the request identifier from the Lambda event object. Architect the application to write logs to a file.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Obtain the request identifier from the Lambda event object. Architect the application to write logs to the console.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Obtain the request identifier from the Lambda context object. Architect the application to write logs to a file.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 43,
          "question": {
            "id": 154,
            "questionText": "A company requires that AWS Lambda functions written by Developers log errors so System Administrators can more effectively troubleshoot issues. What should the Developers implement to meet this need?",
            "questionImage": null,
            "options": [
              {
                "text": "Publish errors to a dedicated Amazon SQS queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon CloudWatch Events event trigger based on certain Lambda events.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Report errors through logging statements in Lambda function code.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set up an Amazon SNS topic that sends logging statements upon failure.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 44,
          "question": {
            "id": 320,
            "questionText": "A company is developing an application that will run on several Amazon EC2 instances in an Auto Scaling group and can access a database running on Amazon EC2. The application needs to store secrets required to connect to the database. The application must allow for periodic secret rotation, and there should be no changes to the application when a secret changes. What is the SAFEST way to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Associate an IAM role to the EC2 instance where the application is running with permission to access the database.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Systems Manager Parameter Store with the SecureString data type to store secrets.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Configure the application to store secrets in Amazon S3 object metadata.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Hard code the database secrets in the application code itself.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 45,
          "question": {
            "id": 66,
            "questionText": "A company is developing a new online game that will run on top of Amazon ECS. Four distinct Amazon ECS services will be part of the architecture, each requiring specific permissions to various AWS services. The company wants to optimize the use of the underlying Amazon EC2 instances by bin packing the containers based on memory reservation. Which configuration would allow the Development team to meet these requirements MOST securely?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a new Identity and Access Management (IAM) instance profile containing the required permissions for the various ECS services, then associate that instance role with the underlying EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create four distinct IAM roles, each containing the required permissions for the associated ECS service, then configure each ECS service to reference the associated IAM role.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create four distinct IAM roles, each containing the required permissions for the associated ECS service, then, create an IAM group and configure the ECS cluster to reference that group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create four distinct IAM roles, each containing the required permissions for the associated ECS service, then configure each ECS task definition to referene the associated IAM role.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 46,
          "question": {
            "id": 93,
            "questionText": "A Developer is developing an application that manages financial transactions. To improve security, multi-factor authentication (MFA) will be required as part of the login protocol. What services can the Developer use to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon DynamoDB to store MFA session data, and Amazon SNS to send MFA codes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito with MFA.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Directory Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS IAM with MFA enabled.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 47,
          "question": {
            "id": 250,
            "questionText": "Which of the following services are included at no additional cost with the use of the AWS platform?",
            "questionImage": null,
            "options": [
              {
                "text": "Simple Storage Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Elastic Compute Cloud.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Auto Scaling.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Elastic Load Balancing.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "CloudFormation.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Simple Workflow Service.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 48,
          "question": {
            "id": 233,
            "questionText": "How can software determine the public and private IP addresses of the Amazon EC2 instance that it is running on?",
            "questionImage": null,
            "options": [
              {
                "text": "Query the appropriate Amazon CloudWatch metric.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use `ipconfig` or `ifconfig` command.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Query the local instance userdata.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Query the local instance metadata.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 49,
          "question": {
            "id": 335,
            "questionText": "A company needs a fully-managed source control service that will work in AWS. The service must ensure that revision control synchronizes multiple distributed repositories by exchanging sets of changes peer-to-peer. All users need to work productively even when not connected to a network. Which source control service should be used?",
            "questionImage": null,
            "options": [
              {
                "text": "Subversion.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeBuild.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeCommit.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS CodeStar.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 50,
          "question": {
            "id": 99,
            "questionText": "A Developer executed a AWS CLI command and received the error shown below. What action should the Developer perform to make this error human-readable?",
            "questionImage": "images/question99.jpg",
            "options": [
              {
                "text": "Make a call to AWS KMS to decode the message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS STS `decode-authorization-message` API to decode the message.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use an open source decoding library to decode the message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use the AWS IAM `decode-authorization-message` API to decode this message.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 51,
          "question": {
            "id": 288,
            "questionText": "An e-commerce web application that shares session state on-premises is being migrated to AWS. The application must be fault tolerant, natively highly scalable, and any service interruption should not affect the user experience. What is the best option to store the session state?",
            "questionImage": null,
            "options": [
              {
                "text": "Store the session state in Amazon ElastiCache.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Store the session state in Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the session state in Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable session stickiness using elastic load balancers.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 52,
          "question": {
            "id": 10,
            "questionText": "A global company has an application running on Amazon EC2 instances that serves image files from Amazon S3. User requests from the browser are causing high traffic, which results in degraded performance. Which optimization solution should a Developer implement to increase application performance?",
            "questionImage": null,
            "options": [
              {
                "text": "Create multiple prefix in the S3 bucket to increase the request rate.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon ElastiCache cluster to cache and serve frequently accessed items.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudFront to serve the content of images stored in Amazon S3.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Submit a ticket to AWS support to request a rate limit increase for the S3 bucket.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 53,
          "question": {
            "id": 225,
            "questionText": "If a message is retrieved from a queue in Amazon SQS, how long is the message inaccessible to other users by default?",
            "questionImage": null,
            "options": [
              {
                "text": "0 seconds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1 hour.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "1 day.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "forever.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "30 seconds.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 54,
          "question": {
            "id": 255,
            "questionText": "A meteorological system monitors 600 temperature gauges, obtaining temperature samples every minute and saving each sample to a DynamoDB table Each sample involves writing 1K of data and the writes are evenly distributed over time. How much write throughput is required for the target table?",
            "questionImage": null,
            "options": [
              {
                "text": "1 write capacity unit.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "10 write capacity units.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "60 write capacity units.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "600 write capacity units.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "3600 write capacity units.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 55,
          "question": {
            "id": 198,
            "questionText": "A Developer is working on a serverless project based in Java. Initial testing shows a cold start takes about 8 seconds on average for AWS Lambda functions. What should the Developer do to reduce the cold start time? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Add the Spring Framework to the project and enable dependency injection.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Reduce the deployment package by including only needed modules from the AWS SDK for Java.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Increase the memory allocation setting for the Lambda function.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Increase the timeout setting for the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the Lambda invocation mode from synchronous to asynchronous.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 56,
          "question": {
            "id": 157,
            "questionText": "An application is experiencing performance issues based on increased demand. This increased demand is on read-only historical records pulled from an Amazon RDS-hosted database with custom views and queries. A Developer must improve performance without changing the database structure. Which approach will improve performance and MINIMIZE management overhead?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy Amazon DynamoDB, move all the data, and point to DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy Amazon ElastiCache for Redis and cache the data for the application.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Deploy Memcached on Amazon EC2 and cache the data for the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy Amazon DynamoDB Accelerator (DAX) on Amazon RDS to improve cache performance.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 57,
          "question": {
            "id": 212,
            "questionText": "An application is running on a cluster of Amazon EC2 instances. While trying to read objects stored within a single Amazon S3 bucket that are encrypted with server-side encryption with AWS KMS managed keys (SSE-KMS), the application receives the following error. Which combination of steps should be taken to prevent this failure? (Choose TWO)",
            "questionImage": "images/question212.jpg",
            "options": [
              {
                "text": "Contact AWS Support to request an AWS KMS rate limit increase.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Perform error retries with exponential backoff in the application code.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Contact AWS Support to request a S3 rate limit increase.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Import a customer master key (CMK) with a larger key size.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use more than one customer master key (CMK) to encrypt S3 data.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 58,
          "question": {
            "id": 363,
            "questionText": "An application runs on multiple EC2 instances behind an ELB. Where is the session data best written so that it can be served reliably across multiple requests?",
            "questionImage": null,
            "options": [
              {
                "text": "Write data to Amazon ElastiCache.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Write data to Amazon Elastic Block Store.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write data to Amazon EC2 Instance Store.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write data to the `root` filesystem.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 59,
          "question": {
            "id": 345,
            "questionText": "A Developer is using AWS CLI, but when running list commands on a large number of resources, it is timing out. What can be done to avoid this time-out?",
            "questionImage": null,
            "options": [
              {
                "text": "Use pagination.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use shorthand syntax.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use parameter values.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use quoting strings.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 60,
          "question": {
            "id": 206,
            "questionText": "A Developer is going to deploy an AWS Lambda function that requires significant CPU utilization. Which approach will MINIMIZE the average runtime of the function?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy the function into multiple AWS Regions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the function into multiple Availability Zones.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the function using Lambda layers.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Deploy the function with its memory allocation set to the maximum amount.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 61,
          "question": {
            "id": 341,
            "questionText": "A company has multiple Developers located across the globe who are updating code incrementally for a development project. When Developers upload code concurrently, internet connectivity is slow and it is taking a long time to upload code for deployment in AWS Elastic Beanstalk. Which step will result in minimized upload and deployment time with the LEAST amount of administrative effort?",
            "questionImage": null,
            "options": [
              {
                "text": "Allow the Developers to upload the code to an Amazon S3 bucket, and deploy it directly to Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Allow the Developers to upload the code to a central FTP server to deploy the application to Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an AWS CodeCommit repository, allow the Developers to commit code to it, and then directly deploy the code to Elastic Beanstalk.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a code repository on an Amazon EC2 instance so that all Developers can update the code, and deploy the application from the instance to Elastic Beanstalk.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 62,
          "question": {
            "id": 249,
            "questionText": "What is one key difference between an Amazon EBS-backed and an instance-store backed instance?",
            "questionImage": null,
            "options": [
              {
                "text": "Virtual Private Cloud requires EBS backed instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon EBS-backed instances can be stopped and restarted.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Auto scaling requires using Amazon EBS-backed instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Instance-store backed instances can be stopped and restarted.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 63,
          "question": {
            "id": 289,
            "questionText": "A Developer is creating a template that uses AWS CloudFormation to deploy an application. This application is serverless and uses Amazon API Gateway, Amazon DynamoDB, and AWS Lambda. Which tool should the Developer use to define simplified syntax for expressing serverless resources?",
            "questionImage": null,
            "options": [
              {
                "text": "CloudFormation serverless intrinsic functions.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS serverless express.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An AWS serverless application model.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "A CloudFormation serverless plugin.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 64,
          "question": {
            "id": 121,
            "questionText": "An application needs to encrypt data that is written to Amazon S3 where the keys are managed in an on-premises data center, and the encryption is handled by S3. Which type of encryption should be used?",
            "questionImage": null,
            "options": [
              {
                "text": "Use server-side encryption with Amazon S3-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use server-side encryption with AWS KMS-managed keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use client-side encryption with customer master keys.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use server-side encryption with customer-provided keys.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 65,
          "question": {
            "id": 349,
            "questionText": "A stock market monitoring application uses Amazon Kinesis for data ingestion. During simulated tests of peak data rates, the Kinesis stream cannot keep up with the incoming data. What step will allow Kinesis to accommodate the traffic during peak hours?",
            "questionImage": null,
            "options": [
              {
                "text": "Install the Kinesis Producer Library (KPL) for ingesting data into the stream.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Reduce the data retention period to allow for more data ingestion using `DecreaseStreamRetentionPeriod`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the shard count of the stream using `UpdateShardCount`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Ingest multiple records into the stream in a single call using `PutRecords`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        }
      ]
    },
    {
      "id": "1762893168193",
      "date": "20:32:48 11/11/2025",
      "score": "0.00",
      "results": [
        {
          "qNum": 1,
          "question": {
            "id": 130,
            "questionText": "Given the following AWS CloudFormation template. What is the MOST efficient way to reference the new Amazon S3 bucket from another AWS CloudFormation template?",
            "questionImage": "images/question130.jpg",
            "options": [
              {
                "text": "Add an `Export` declaration to the `Outputs` section of the original template and use `ImportValue` in other templates.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add `Exported: true` to the `Content.Bucket` in the original template and use `ImportResource` in other templates.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a custom AWS CloudFormation resource that gets the bucket name from the `ContentBucket` resource of the first stack.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use `Fn::Include` to include the existing template in other templates and use the `ContentBucket` resource directly.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 2,
          "question": {
            "id": 322,
            "questionText": "An AWS Lambda function must read data from an Amazon RDS MySQL database in a VPC and also reach a public endpoint over the internet to get additional data. Which steps must be taken to allow the function to access both the RDS resource and the public endpoint? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Modify the default configuration for the Lambda function to associate it with an Amazon VPC private subnet.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Modify the default network access control list to allow outbound traffic.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add a NAT Gateway to the VPC.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Modify the default configuration of the Lambda function to associate it with a VPC public subnet.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an environmental variable to the Lambda function to allow outbound internet access.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "1",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 3,
          "question": {
            "id": 374,
            "questionText": "A Developer must trigger an AWS Lambda function based on the item lifecycle activity in an Amazon DynamoDB table. How can the Developer create the solution?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable a DynamoDB stream that publishes an Amazon SNS message. Trigger the Lambda function synchronously from the SNS message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable a DynamoDB stream that publishes an SNS message. Trigger the Lambda function asynchronously from the SNS message.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable a DynamoDB stream, and trigger the Lambda function synchronously from the stream.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Enable a DynamoDB stream, and trigger the Lambda function asynchronously from the stream.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "2"
          ],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 4,
          "question": {
            "id": 86,
            "questionText": "A Developer is creating an Auto Scaling group whose instances need to publish a custom metric to Amazon CloudWatch. Which method would be the MOST secure way to authenticate a CloudWatch PUT request?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM user with `PutMetricData` permission and put the user credentials in a private repository; have applications pull the credentials as needed.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM user with `PutMetricData` permission, and modify the Auto Scaling launch configuration to inject the user credentials into the instance user data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the CloudWatch metric policies to allow the `PutMetricData` permission to instances from the Auto Scaling group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an IAM role with `PutMetricData` permission and modify the Auto Scaling launching configuration to launch instances using that role.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "3"
          ],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 5,
          "question": {
            "id": 187,
            "questionText": "A Developer uses Amazon S3 buckets for static website hosting. The Developer creates one S3 bucket for the code and another S3 bucket for the assets, such as image and video files. Access is denied when a user attempts to access the assets bucket from the code bucket, with the website application showing a `403` error. How should the Developer solve this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an IAM role and apply it to the assets bucket for the code bucket to be granted access.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Edit the bucket policy of the assets bucket to allow access from the code bucket.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Edit the bucket policy of the assets bucket to open access to all principals.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change the code bucket to use AWS Lambda functions instead of static website hosting.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [
            "1"
          ],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 6,
          "question": {
            "id": 290,
            "questionText": "A Developer has a stateful web server on-premises that is being migrated to AWS. The Developer must have greater elasticity in the new design. How should the Developer re-factor the application to make it more elastic? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Use pessimistic concurrency on Amazon DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudFront with an Auto Scaling group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon CloudFront with an AWS Web Application Firewall.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store session state data in an Amazon DynamoDB table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use an ELB with an Auto Scaling group.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "4",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 7,
          "question": {
            "id": 97,
            "questionText": "A company is using AWS CodeBuild to compile a website from source code stored in AWS CodeCommit. A recent change to the source code has resulted in the CodeBuild project being unable to successfully compile the website. How should the Developer identify the cause of the failures?",
            "questionImage": null,
            "options": [
              {
                "text": "Modify the `buildspec.yml` file to include steps to send the output of build commands to Amazon CloudWatch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use a custom Docker image that includes the AWS X-Ray agent in the AWS CodeBuild project configuration.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Check the build logs of the failed phase in the last build attempt in the AWS CodeBuild project build history.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Manually re-run the build process on a local machine so that the output can be visualized.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 8,
          "question": {
            "id": 179,
            "questionText": "A Developer implemented a static website hosted in Amazon S3 that makes web service requests hosted in Amazon API Gateway and AWS Lambda. The site is showing an error that reads: `No Access-Control-Allow-Origin` header is present on the requested resource. Origin `null` is therefore not allowed access.' What should the Developer do to resolve this issue?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable cross-origin resource sharing (CORS) on the S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable cross-origin resource sharing (CORS) for the method in API Gateway.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Add the `Access-Control-Request-Method` header to the request.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add the `Access-Control-Request-Headers` header to the request.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 9,
          "question": {
            "id": 210,
            "questionText": "A company wants to implement authentication for its new REST service using Amazon API Gateway. To authenticate the calls, each request must include HTTP headers with a client ID and user ID. These credentials must be compared to authentication data in an Amazon DynamoDB table. What MUST the company do to implement this authentication in API Gateway?",
            "questionImage": null,
            "options": [
              {
                "text": "Implement an AWS Lambda authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a model that requires the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Modify the integration requests to require the credentials, then grant API Gateway access to the authentication table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Implement an Amazon Cognito authorizer that references the DynamoDB authentication table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 10,
          "question": {
            "id": 329,
            "questionText": "A Developer must deploy a new AWS Lambda function using an AWS CloudFormation template. Which procedures will deploy a Lambda function? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Upload the code to an AWS CodeCommit repository, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an `AWS::Lambda::Function` resource in the template, then write the code directly inside the CloudFormation template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload a `.ZIP` file containing the function code to Amazon S3, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload a `.ZIP` file to AWS CloudFormation containing the function code, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload the function code to a private Git repository, then add a reference to it in an `AWS::Lambda::Function` resource in the template.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "2",
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 11,
          "question": {
            "id": 259,
            "questionText": "You are inserting 1000 new items every second in a DynamoDB table. Once an hour these items are analyzed and then are no longer needed. You need to minimize provisioned throughput, storage, and API calls. Given these requirements, what is the most efficient way to manage these Items after the analysis?",
            "questionImage": null,
            "options": [
              {
                "text": "Retain the items in a single table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Delete items individually over a 24 hour period.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Delete the table and create a new table per hour.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a new table per hour.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 12,
          "question": {
            "id": 307,
            "questionText": "A Developer is creating a serverless website with content that includes HTML files, images, videos, and JavaScript (client-side scripts). Which combination of services should the Developer use to create the website?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon S3 and Amazon CloudFront.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon EC2 and Amazon ElastiCache.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon ECS and Redis.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Lambda and Amazon API Gateway.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 13,
          "question": {
            "id": 52,
            "questionText": "A company has written a Java AWS Lambda function to be triggered whenever a user uploads an image to an Amazon S3 bucket. The function converts the original image to several different formats and then copies the resulting images to another Amazon S3 bucket. The Developers find that no images are being copied to the second Amazon S3 bucket. They have tested the code on an Amazon EC2 instance with 1GB of RAM, and it takes an average of 500 seconds to complete. What is the MOST likely cause of the problem?",
            "questionImage": null,
            "options": [
              {
                "text": "The Lambda function has insufficient memory and needs to be increased to 1 GB to match the Amazon EC2 instance.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Files need to be copied to the same Amazon S3 bucket for processing, so the second bucket needs to be deleted.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Lambda functions have a maximum execution limit of 15 minutes, therefore the function is not completing.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "There is a problem with the Java runtime for Lambda, and the function needs to be converted to node.js.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 14,
          "question": {
            "id": 386,
            "questionText": "A static website is hosted in an Amazon S3 bucket. Several HTML pages on the site use JavaScript to download images from another Amazon S3 bucket. These images are not displayed when users browse the site. What is the possible cause for the issue?",
            "questionImage": null,
            "options": [
              {
                "text": "The referenced Amazon S3 bucket is in another region.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The images must be stored in the same Amazon S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Port 80 must be opened on the security group in which the Amazon S3 bucket is located.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Cross Origin Resource Sharing must be enabled on the Amazon S3 bucket.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 15,
          "question": {
            "id": 90,
            "questionText": "A Developer has created a software package to be deployed on multiple EC2 instances using IAM roles. What actions could be performed to verify IAM access to get records from Amazon Kinesis Streams? (Select TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Use the AWS CLI to retrieve the IAM group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Query Amazon EC2 metadata for in-line IAM policies.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Request a token from AWS STS, and perform a describe action.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Perform a get action using the `--dry-run` argument.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Validate the IAM role policy with the IAM policy simulator.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "4",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 16,
          "question": {
            "id": 333,
            "questionText": "A Developer is designing a fault-tolerant environment where client sessions will be saved. How can the Developer ensure that no sessions are lost if an Amazon EC2 instance fails?",
            "questionImage": null,
            "options": [
              {
                "text": "Use sticky sessions with an Elastic Load Balancer target group.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon SQS to save session data.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon DynamoDB to perform scalable session handling.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use Elastic Load Balancer connection draining to stop sending requests to failing instances.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 17,
          "question": {
            "id": 359,
            "questionText": "An application is using Amazon DynamoDB as its data store, and should be able to read 100 items per second as strongly consistent reads. Each item is 5 KB in size. To what value should the table's provisioned read throughput be set?",
            "questionImage": null,
            "options": [
              {
                "text": "50 read capacity units.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "100 read capacity units.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "200 read capacity units.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "500 read capacity units.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 18,
          "question": {
            "id": 133,
            "questionText": "A developer is creating a script to automate the deployment process for a serverless application. The developer wants to use an existing AWS Serverless Application Model (AWS SAM) template for the application. What should the developer use for the project? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Call `aws cloudformation package` to create the deployment package. Call `aws cloudformation deploy` to deploy the package afterward.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Call `sam package` to create the deployment package. Call `sam deploy` to deploy the package afterward.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Call `aws s3 cp` to upload the AWS SAM template to Amazon S3. Call `aws lambda update-function-code` to create the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a `ZIP` package locally and call `aws serverlessrepo create-application` to create the application.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a `ZIP` package and upload it to Amazon S3. Call `aws cloudformation create-stack` to create the application.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 19,
          "question": {
            "id": 14,
            "questionText": "An application deployed on AWS Elastic Beanstalk experiences increased error rates during deployments of new application versions, resulting in service degradation for users. The Development team believes that this is because of the reduction in capacity during the deployment steps. The team would like to change the deployment policy configuration of the environment to an option that maintains full capacity during deployment while using the existing instances. Which deployment policy will meet these requirements while using the existing instances?",
            "questionImage": null,
            "options": [
              {
                "text": "All at once.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Rolling with additional batch.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Immutable.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 20,
          "question": {
            "id": 234,
            "questionText": "EC2 instances are launched from Amazon Machine images (AMIs). A given public AMI can:",
            "questionImage": null,
            "options": [
              {
                "text": "Be used to launch EC2 Instances in any AWS region.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Only be used to launch EC2 instances in the same country as the AMI is stored.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Only be used to launch EC2 instances in the same AWS region as the AMI is stored.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Only be used to launch EC2 instances in the same AWS availability zone as the AMI is stored.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 21,
          "question": {
            "id": 93,
            "questionText": "A Developer is developing an application that manages financial transactions. To improve security, multi-factor authentication (MFA) will be required as part of the login protocol. What services can the Developer use to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon DynamoDB to store MFA session data, and Amazon SNS to send MFA codes.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon Cognito with MFA.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "AWS Directory Service.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS IAM with MFA enabled.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 22,
          "question": {
            "id": 240,
            "questionText": "Which of the following statements about SWF are true? (Choose THREE)",
            "questionImage": null,
            "options": [
              {
                "text": "SWF tasks are assigned once and never duplicated.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SWF requires an S3 bucket for workflow storage.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SWF workflow executions can last up to a year.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SWF triggers SNS notifications on task assignment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SWF uses deciders and workers to complete tasks.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "SWF requires at least 1 EC2 instance per domain.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "3",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 23,
          "question": {
            "id": 81,
            "questionText": "An application is designed to use Amazon SQS to manage messages from many independent senders. Each sender's messages must be processed in the order they are received. Which SQS feature should be implemented by the Developer?",
            "questionImage": null,
            "options": [
              {
                "text": "Configure each sender with a unique MessageGroupId.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Enable MessageDeduplicationIds on the SQS queue.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure each message with unique MessageGroupIds.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable ContentBasedDeduplication on the SQS queue.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 24,
          "question": {
            "id": 342,
            "questionText": "A company recently migrated its web, application and NoSQL database tiers to AWS. The company is using Auto Scaling to scale the web and application tiers. More than 95 percent of the Amazon DynamoDB requests are repeated read requests. How can the DynamoDB NoSQL tier be scaled up to cache these repeated requests?",
            "questionImage": null,
            "options": [
              {
                "text": "Amazon EMR.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon DynamoDB Accelerator.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon SQS.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon CloudFront.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 25,
          "question": {
            "id": 15,
            "questionText": "A Developer is creating an application that needs to locate the public IPv4 address of the Amazon EC2 instance on which it runs. How can the application locate this information?",
            "questionImage": null,
            "options": [
              {
                "text": "Get the instance metadata by retrieving `http://169.254.169.254/latest/metadata/`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Get the instance user data by retrieving `http://169.254.169.254/latest/userdata/`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Get the application to run `IFCONFIG` to get the public IP address.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Get the application to run `IPCONFIG` to get the public IP address.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 26,
          "question": {
            "id": 381,
            "questionText": "An existing serverless application processes uploaded image files. The process currently uses a single Lambda function that takes an image file, performs the processing, and stores the file in Amazon S3. Users of the application now require thumbnail generation of the images. Users want to avoid any impact to the time it takes to perform the image uploads. How can thumbnail generation be added to the application, meeting user requirements while minimizing changes to existing code?",
            "questionImage": null,
            "options": [
              {
                "text": "Change the existing Lambda function handling the uploads to create thumbnails at the time of upload. Have the function store both the image and thumbnail in Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a second Lambda function that handles thumbnail generation and storage. Change the existing Lambda function to invoke it asynchronously.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an S3 event notification with a Lambda function destination. Create a new Lambda function to generate and store thumbnails.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an S3 event notification to an SQS Queue. Create a scheduled Lambda function that processes the queue, and generates and stores thumbnails.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 27,
          "question": {
            "id": 362,
            "questionText": "A Developer has developed a web application and wants to deploy it quickly on a Tomcat server on AWS. The Developer wants to avoid having to manage the underlying infrastructure. What is the easiest way to deploy the application, based on these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS CloudFormation.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Elastic Beanstalk.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodePipeline",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 28,
          "question": {
            "id": 366,
            "questionText": "An application running on an Amazon Linux EC2 instance needs to manage the AWS infrastructure. How can the EC2 instance be configured to make AWS API calls securely?",
            "questionImage": null,
            "options": [
              {
                "text": "Sign the AWS CLI command using the signature version 4 process.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Run the `aws configure` AWS CLI command and specify the access key id and secret access key.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Specify a role for the EC2 instance with the necessary privileges.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Pass the access key id and secret access key as parameters for each AWS CLI command.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 29,
          "question": {
            "id": 243,
            "questionText": "Company C has recently launched an online commerce site for bicycles on AWS. They have a `Product` DynamoDB table that stores details for each bicycle, such as, manufacturer, color, price, quantity and size to display in the online store. Due to customer demand, they want to include an image for each bicycle along with the existing details. Which approach below provides the least impact to provisioned throughput on the `Product` table?",
            "questionImage": null,
            "options": [
              {
                "text": "Serialize the image and store it in multiple DynamoDB tables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an `Images` DynamoDB table to store the Image with a foreign key constraint to the `Product` table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Add an image data type to the `Product` table to store the images in binary format.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Store the images in Amazon S3 and add an S3 URL pointer to the `Product` table item for each image.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 30,
          "question": {
            "id": 122,
            "questionText": "A development team is working on a mobile app that allows users to upload pictures to Amazon S3. The team expects the app will be used by hundreds of thousands of users during a single event simultaneously. Once the pictures are uploaded, the backend service will scan and parse the pictures for inappropriate content. Which approach is the MOST resilient way to achieve this goal, which also smooths out temporary volume spikes for the backend service?",
            "questionImage": null,
            "options": [
              {
                "text": "Develop an AWS Lambda function to check the upload folder in the S3 bucket. If new uploaded pictures are detected, the Lambda function will scan and parse them.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Once a picture is uploaded to Amazon S3, publish the event to an Amazon SQS queue. Use the queue as an event source to trigger an AWS Lambda function. In the Lambda function, scan and parse the picture.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "When the user uploads a picture, invoke an API hosted in Amazon API Gateway. The API will invoke an AWS Lambda function to scan and parse the picture.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a state machine in AWS Step Functions to check the upload folder in the S3 bucket. If a new picture is detected, invoke an AWS Lambda function to scan and parse it.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 31,
          "question": {
            "id": 184,
            "questionText": "A Developer migrated a web application to AWS. As part of the migration, the Developer implemented an automated continuous integration/continuous improvement (CI/CD) process using a blue/green deployment. The deployment provisions new Amazon EC2 instances in an Auto Scaling group behind a new Application Load Balancer. After the migration was completed, the Developer began receiving complaints from users getting booted out of the system. The system also requires users to log in after every new deployment. How can these issues be resolved?",
            "questionImage": null,
            "options": [
              {
                "text": "Use rolling updates instead of a blue/green deployment.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Externalize the user sessions to Amazon ElastiCache.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Turn on sticky sessions in the Application Load Balancer.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use multicast to replicate session information.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 32,
          "question": {
            "id": 75,
            "questionText": "A large e-commerce site is being designed to deliver static objects from Amazon S3. The Amazon S3 bucket will server more than 300 GET requests per second. What should be done to optimize performance? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Integrate Amazon CloudFront with Amazon S3.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Enable Amazon S3 cross-region replication.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Delete expired Amazon S3 server log files.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure Amazon S3 lifecycle rules.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Randomize Amazon S3 key name prefixes.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "5"
          ],
          "isCorrect": false
        },
        {
          "qNum": 33,
          "question": {
            "id": 50,
            "questionText": "The release process workflow of an application requires a manual approval before the code is deployed into the production environment. What is the BEST way to achieve this using AWS CodePipeline?",
            "questionImage": null,
            "options": [
              {
                "text": "Use multiple pipelines to allow approval.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an approval action in a stage.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Disable the stage transition to allow manual approval.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Disable a stage just prior the deployment stage.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 34,
          "question": {
            "id": 74,
            "questionText": "During non-peak hours, a Developer wants to minimize the execution time of a full Amazon DynamoDB table scan without affecting normal workloads. The workloads average half of the strongly consistent read capacity units during non-peak hours. How would the Developer optimize this scan?",
            "questionImage": null,
            "options": [
              {
                "text": "Use parallel scans while limiting the rate.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use sequential scans.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase read capacity units during the scan operation.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Change consistency to eventually consistent during the scan operation.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 35,
          "question": {
            "id": 265,
            "questionText": "If an application is storing hourly log files from thousands of instances from a high traffic web site, which naming scheme would give optimal performance on S3?",
            "questionImage": null,
            "options": [
              {
                "text": "Sequential.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`instanceID_log-HH-DD-MM-YYYY`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`instanceIDLog-YYYY-MM-DD-HH`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`HH-DD-MM-YYYY-log_instanceID`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`YYYY-MM-DD-HH-logInstanceID`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 36,
          "question": {
            "id": 272,
            "questionText": "A company needs a version control system for collaborative software development. Features of the system must include the following: Support for batches of changes across multiple files. Parallel branching Version tracking. Which AWS service will meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "AWS CodePipeline.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS Code Build.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodeCommit.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 37,
          "question": {
            "id": 42,
            "questionText": "An AWS Lambda function accesses two Amazon DynamoDB tables. A developer wants to improve the performance of the Lambda function by identifying bottlenecks in the function. How can the developer inspect the timing of the DynamoDB API calls?",
            "questionImage": null,
            "options": [
              {
                "text": "Add DynamoDB as an event source to the Lambda function. View the performance with Amazon CloudWatch metrics.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Place an Application Load Balancer (ALB) in front of the two DynamoDB tables. Inspect the ALB logs.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Limit Lambda to no more than five concurrent invocations Monitor from the Lambda console.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable AWS X-Ray tracing for the function. View the traces from the X-Ray service.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 38,
          "question": {
            "id": 237,
            "questionText": "When using a large Scan operation in DynamoDB, what technique can be used to minimize the impact of a scan on a table's provisioned throughput?",
            "questionImage": null,
            "options": [
              {
                "text": "Set a smaller page size for the scan.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use parallel scans.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Define a range index on the table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Prewarm the table by updating all items.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 39,
          "question": {
            "id": 56,
            "questionText": "A Developer has written a serverless application using multiple AWS services. The business logic is written as a Lambda function which has dependencies on third-party libraries. The Lambda function endpoints will be exposed using Amazon API Gateway. The Lambda function will write the information to Amazon DynamoDB. The Developer is ready to deploy the application but must have the ability to rollback. How can this deployment be automated, based on these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Deploy using Amazon Lambda API operations to create the Lambda function by providing a deployment package.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an AWS CloudFormation template and use CloudFormation syntax to define the Lambda function resource in the template.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use syntax conforming to the Serverless Application Model in the AWS CloudFormation template to define the Lambda function resource.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a bash script which uses AWS CLI to package and deploy the application.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 40,
          "question": {
            "id": 168,
            "questionText": "A company provides APIs as a service and commits to a service level agreement (SLA) with all its users. To comply with each SLA, what should the company do?",
            "questionImage": null,
            "options": [
              {
                "text": "Enable throttling limits for each method in Amazon API Gateway.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a usage plan for each user and request API keys to access the APIs.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Enable API rate limiting in Amazon Cognito for each user.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Enable default throttling limits for each stage after deploying the APIs.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 41,
          "question": {
            "id": 349,
            "questionText": "A stock market monitoring application uses Amazon Kinesis for data ingestion. During simulated tests of peak data rates, the Kinesis stream cannot keep up with the incoming data. What step will allow Kinesis to accommodate the traffic during peak hours?",
            "questionImage": null,
            "options": [
              {
                "text": "Install the Kinesis Producer Library (KPL) for ingesting data into the stream.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Reduce the data retention period to allow for more data ingestion using `DecreaseStreamRetentionPeriod`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the shard count of the stream using `UpdateShardCount`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Ingest multiple records into the stream in a single call using `PutRecords`.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 42,
          "question": {
            "id": 55,
            "questionText": "A company wants to migrate its web application to AWS and leverage Auto Scaling to handle peak workloads. The Solutions Architect determined that the best metric for an Auto Scaling event is the number of concurrent users. Based on this information, what should the Developer use to autoscale based on concurrent users?",
            "questionImage": null,
            "options": [
              {
                "text": "An Amazon SNS topic to be triggered when a concurrent user threshold is met.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "An Amazon Cloudwatch NetworkIn metric.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon CloudFront to leverage AWS Edge Locations.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A Custom Amazon CloudWatch metric for concurrent users.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 43,
          "question": {
            "id": 196,
            "questionText": "A Developer has a legacy application that is hosted on-premises. Other applications hosted on AWS depend on the on-premises application for proper functioning. In case of any application errors, the Developer wants to be able to use Amazon CloudWatch to monitor and troubleshoot all applications from one place. How can the Developer accomplish this?",
            "questionImage": null,
            "options": [
              {
                "text": "Install an AWS SDK on the on-premises server to automatically send logs to CloudWatch.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Download the CloudWatch agent to the on-premises server. Configure the agent to use IAM user credentials with permissions for CloudWatch.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Upload log files from the on-premises server to Amazon S3 and have CloudWatch read the files.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload log files from the on-premises server to an Amazon EC2 instance and have the instance forward the logs to CloudWatch.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 44,
          "question": {
            "id": 135,
            "questionText": "Two containerized microservices are hosted on Amazon EC2 ECS. The first microservice reads an Amazon RDS Aurora database instance, and the second microservice reads an Amazon DynamoDB table. How can each microservice be granted the minimum privileges?",
            "questionImage": null,
            "options": [
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `false` on EC2 instance boot in ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the second microservice with an IAM role for ECS tasks with read-only access to DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `false` on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `true` on EC2 instance boot in the ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the secondmicroservice with an IAM role for ECS tasks with read-only access to DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Set `ECS_ENABLE_TASK_IAM_ROLE` to `true` on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 45,
          "question": {
            "id": 350,
            "questionText": "A company has an AWS CloudFormation template that is stored as a single file. The template is able to launch and create a full infrastructure stack. Which best practice would increase the maintainability of the template?",
            "questionImage": null,
            "options": [
              {
                "text": "Use nested stacks for common template patterns.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Embed credentials to prevent typos.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Remove mappings to decrease the number of variables.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use `AWS::Include` to reference publicly-hosted template files.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 46,
          "question": {
            "id": 8,
            "questionText": "A company uses a third-party tool to build, bundle, and package rts applications on-premises and store them locally. The company uses Amazon EC2 instances to run its front-end applications. How can an application be deployed from the source control system onto the EC2 instances?",
            "questionImage": null,
            "options": [
              {
                "text": "Use AWS CodeDeploy and point it to the local storage to directly deploy a bundle m a zip. tar. or tar.gz format.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Upload the bundle to an Amazon S3 bucket and specify the S3 location when doing a deployment using AWS CodeDeploy.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a repository using AWS CodeCommit to automatically trigger a deployment to the EC2 instances.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS CodeBuild to automatically deploy the latest build to the latest EC2 instances.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 47,
          "question": {
            "id": 337,
            "questionText": "A company is building an application to track athlete performance using an Amazon DynamoDB table. Each item in the table is identified by a partition key (`user_id`) and a sort key (`sport_name`). The table design is shown below. (Note: Not all table attributes are shown) A Developer is asked to write a leaderboard application to display the top performers (`user_id`) based on the score for each `sport_name`. What process will allow the Developer to extract results MOST efficiently from the DynamoDB table?",
            "questionImage": "images/question337.jpg",
            "options": [
              {
                "text": "Use a DynamoDB query operation with the key attributes of `user_id` and `sport_name` and order the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a global secondary index with a partition key of `sport_name` and a sort key of score, and get the results.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Use a DynamoDB scan operation to retrieve scores and `user_id` based on `sport_name`, and order the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a local secondary index with a primary key of `sport_name` and a sort key of score and get the results based on the score attribute.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 48,
          "question": {
            "id": 120,
            "questionText": "A company has developed a new serverless application using AWS Lambda functions that will be deployed using the AWS Serverless Application Model (AWS SAM) CLI. Which step should the developer complete prior to deploying the application?",
            "questionImage": null,
            "options": [
              {
                "text": "Compress the application to a `.zip` file and upload it into AWS Lambda.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Test the new AWS Lambda function by first tracing it in AWS X-Ray.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Bundle the serverless application using a SAM package.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create the application environment using the `eb create my-env` command.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 49,
          "question": {
            "id": 162,
            "questionText": "A Company runs continuous integration/continuous delivery (CI/CD) pipelines for its application on AWS CodePipeline. A Developer must write unit tests and run them as part of the pipelines before staging the artifacts for testing. How should the Developer incorporate unit tests as part of CI/CD pipelines?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a separate CodePipeline pipeline to run unit tests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Update the AWS CodeBuild specification to include a phase for running unit tests.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Install the AWS CodeDeploy agent on an Amazon EC2 instance to run unit tests.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a testing branch in AWS CodeCommit to run unit tests.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 50,
          "question": {
            "id": 235,
            "questionText": "Which EC2 API call would you use to retrieve a list of Amazon Machine Images (AMIs)?",
            "questionImage": null,
            "options": [
              {
                "text": "`DescribeInstances`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`DescribeAMIs`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "`DescribeImages`.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "`GetAMIs`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "You cannot retrieve a list of AMIs as there are over 10,000 AMIs.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 51,
          "question": {
            "id": 343,
            "questionText": "A Development team is working on a case management solution that allows medical claims to be processed and reviewed. Users log in to provide information related to their medical and financial situations. As part of the application, sensitive documents such as medical records, medical imaging, bank statements, and receipts are uploaded to Amazon S3. All documents must be securely transmitted and stored. All access to the documents must be recorded for auditing. What is the MOST secure approach?",
            "questionImage": null,
            "options": [
              {
                "text": "Use S3 default encryption using Advanced Encryption Standard-256 (AES-256) on the destination bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito for authorization and authentication to ensure the security of the application and documents.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use AWS Lambda to encrypt and decrypt objects as they are placed into the S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use client-side encryption/decryption with Amazon S3 and AWS KMS.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 52,
          "question": {
            "id": 228,
            "questionText": "Which of the following platforms are supported by Elastic Beanstalk? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "Apache Tomcat.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": ".NET.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "IBM Websphere.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Oracle JBoss.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Jetty.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 53,
          "question": {
            "id": 216,
            "questionText": "A Developer must encrypt a 100-GB object using AWS KMS. What is the BEST approach?",
            "questionImage": null,
            "options": [
              {
                "text": "Make an `Encrypt` API call to encrypt the plaintext data as ciphertext using a customer master key (CMK).",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Make an `Encrypt` API call to encrypt the plaintext data as ciphertext using a customer master key (CMK) with imported key material.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Make an `GenerateDataKey` API call that returns a plaintext key and an encrypted copy of a data key. Use a plaintext key to encrypt the data.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Make an `GenerateDataKeyWithoutPlaintext` API call that returns an encrypted copy of a data key. Use an encrypted key to encrypt the data.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 54,
          "question": {
            "id": 188,
            "questionText": "A company has implemented AWS CodePipeline to automate its release pipelines. The Development team is writing an AWS Lambda function what will send notifications for state changes of each of the actions in the stages. Which steps must be taken to associate the Lambda function with the event source?",
            "questionImage": null,
            "options": [
              {
                "text": "Create a trigger that invokes the Lambda function from the Lambda console by selecting CodePipeline as the event source.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an event trigger and specify the Lambda function from the CodePipeline console.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an Amazon CloudWatch alarm that monitors status changes in Code Pipeline and triggers the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon CloudWatch Events rule that uses CodePipeline as an event source.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 55,
          "question": {
            "id": 139,
            "questionText": "An IAM role is attached to an Amazon EC2 instance that explicitly denies access to all Amazon S3 API actions. The EC2 instance credentials file specifies the IAM access key and secret access key, which allow full administrative access. Given that multiple modes of IAM access are present for this EC2 instance, which of the following is correct?",
            "questionImage": null,
            "options": [
              {
                "text": "The EC2 instance will only be able to list the S3 buckets.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The EC2 instance will only be able to list the contents of one S3 bucket at a time.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The EC2 instance will be able to perform all actions on any S3 bucket.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The EC2 instance will not be able to perform any S3 action on any S3 bucket.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 56,
          "question": {
            "id": 304,
            "questionText": "A nightly batch job loads 1 million new records into a DynamoDB table. The records are only needed for one hour, and the table needs to be empty by the next night's batch job. Which is the MOST efficient and cost-effective method to provide an empty table?",
            "questionImage": null,
            "options": [
              {
                "text": "Use `DeleteItem` using a `ConditionExpression`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use `BatchWriteItem` to empty all of the rows.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Write a recursive function that scans and calls out `DeleteItem`.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create and then delete the table after the task has completed.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 57,
          "question": {
            "id": 298,
            "questionText": "A Developer has created a Lambda function and is finding that the function is taking longer to complete than expected. After some debugging, the Developer has discovered that increasing compute capacity would improve performance. How can the Developer increase the Lambda compute resources?",
            "questionImage": null,
            "options": [
              {
                "text": "Run on a larger instance size with more compute capacity.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the maximum execution time.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Specify a larger compute capacity when calling the Lambda function.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Increase the allocated memory for the Lambda function.",
                "image": null,
                "isCorrect": true
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "4"
          ],
          "isCorrect": false
        },
        {
          "qNum": 58,
          "question": {
            "id": 150,
            "questionText": "A company is managing a NoSQL database on-premises to host a critical component of an application, which is starting to have scaling issues. The company wants to migrate the application to Amazon DynamoDB with the following considerations: Optimize frequent queries. Reduce read latencies. Plan for frequent queries on certain key attributes of the table. Which solution would help achieve these objectives?",
            "questionImage": null,
            "options": [
              {
                "text": "Create global secondary indexes on keys that are frequently queried. Add the necessary attributes into the indexes.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create local secondary indexes on keys that are frequently queried. DynamoDB will fetch needed attributes from the table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create DynamoDB global tables to speed up query responses. Use a scan to fetch data from the table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an AWS Auto Scaling policy for the DynamoDB table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 59,
          "question": {
            "id": 197,
            "questionText": "A company is developing an application that will be accessed through the Amazon API Gateway REST API. Registered users should be the only ones who can access certain resources of this API. The token being used should expire automatically and needs to be refreshed periodically. How can a Developer meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an Amazon Cognito identity pool, configure the Amazon Cognito Authorizer in API Gateway, and use the temporary credentials generated by the identity pool.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create and maintain a database record for each user with a corresponding token and use an AWS Lambda authorizer in API Gateway.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create an Amazon Cognito user pool, configure the Cognito Authorizer in API Gateway, and use the identity or access token.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create an IAM user for each API user, attach an invoke permissions policy to the API, and use an IAM authorizer in API Gateway.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        },
        {
          "qNum": 60,
          "question": {
            "id": 369,
            "questionText": "A company is using AWS CodePipeline to deliver one of its applications. The delivery pipeline is triggered by changes to the master branch of an AWS CodeCommit repository and uses AWS CodeBuild to implement the test and build stages of the process and AWS CodeDeploy to deploy the application. The pipeline has been operating successfully for several months and there have been no modifications. Following a recent change to the application's source code, AWS CodeDeploy has not deployed the updates application as expected. What are the possible causes? (Choose TWO)",
            "questionImage": null,
            "options": [
              {
                "text": "The change was not made in the master branch of the AWS CodeCommit repository.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "One of the earlier stages in the pipeline failed and the pipeline has terminated.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "One of the Amazon EC2 instances in the company's AWS CodePipeline cluster is inactive.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "The AWS CodePipeline is incorrectly configured and is not executing AWS CodeDeploy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS CodePipeline does not have permissions to access AWS CodeCommit.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": true
          },
          "userAns": [],
          "correctOptions": [
            "1",
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 61,
          "question": {
            "id": 255,
            "questionText": "A meteorological system monitors 600 temperature gauges, obtaining temperature samples every minute and saving each sample to a DynamoDB table Each sample involves writing 1K of data and the writes are evenly distributed over time. How much write throughput is required for the target table?",
            "questionImage": null,
            "options": [
              {
                "text": "1 write capacity unit.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "10 write capacity units.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "60 write capacity units.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "600 write capacity units.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "3600 write capacity units.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 62,
          "question": {
            "id": 185,
            "questionText": "A Developer wants to insert a record into an Amazon DynamoDB table as soon as a new file is added to an Amazon S3 bucket. Which set of steps would be necessary to achieve this?",
            "questionImage": null,
            "options": [
              {
                "text": "Create an event with Amazon CloudWatch Events that will monitor the S3 bucket and then insert the records into DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Configure an S3 event to invoke a Lambda function that inserts records into DynamoDB.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a Lambda function that will poll the S3 bucket and then insert the records into DynamoDB.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Create a cron job that will run at a scheduled time and insert the records into DynamoDB.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 63,
          "question": {
            "id": 276,
            "questionText": "An Amazon DynamoDB table uses a Global Secondary Index (GSI) to support read queries. The primary table is write-heavy, whereas the GSI is used for read operations. Looking at Amazon CloudWatch metrics, the Developer notices that write operations to the primary table are throttled frequently under heavy write activity. However, write capacity units to the primary table are available and not fully consumed. Why is the table being throttled?",
            "questionImage": null,
            "options": [
              {
                "text": "The GSI write capacity units are underprovisioned.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "There are not enough read capacity units on the primary table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Amazon DynamoDB Streams is not enabled on the table.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "A large write operation is being performed against another table.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "1"
          ],
          "isCorrect": false
        },
        {
          "qNum": 64,
          "question": {
            "id": 89,
            "questionText": "A company needs to encrypt data at rest, but it wants to leverage an AWS managed service using its own master key. Which of the following AWS service can be used to meet these requirements?",
            "questionImage": null,
            "options": [
              {
                "text": "SSE with Amazon S3.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "SSE with AWS KMS.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Client-side encryption.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "AWS IAM roles and policies.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "2"
          ],
          "isCorrect": false
        },
        {
          "qNum": 65,
          "question": {
            "id": 119,
            "questionText": "A company has 25,000 employees and is growing. The company is creating an application that will be accessible to its employees only. A developer is using Amazon S3 to store images and Amazon RDS to store application data. The company requires that all employee information remain in the legacy Security Assertion Markup Language (SAML) employee directory only and is not interested in mirroring any employee information on AWS. How can the developer provide authorized access for the employees who will be using this application so each employee can access their own application data only?",
            "questionImage": null,
            "options": [
              {
                "text": "Use Amazon VPC and keep all resources inside the VPC, and use a VPC link for the S3 bucket with the bucket policy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use Amazon Cognito user pools, federate with the SAML provider, and use user pool groups with an IAM policy.",
                "image": null,
                "isCorrect": false
              },
              {
                "text": "Use an Amazon Cognito identity pool, federate with the SAML provider, and use an IAM condition key with a value for the `cognito-identity.amazonaws.com:sub` variable to grant access to the employees.",
                "image": null,
                "isCorrect": true
              },
              {
                "text": "Create a unique IAM role for each employee and have each employee assume the role to access the application so they can access their personal data only.",
                "image": null,
                "isCorrect": false
              }
            ],
            "isMultipleChoice": false
          },
          "userAns": [],
          "correctOptions": [
            "3"
          ],
          "isCorrect": false
        }
      ]
    }
  ]
}